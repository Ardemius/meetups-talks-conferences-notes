= Devoxx France 2024
Thomas SCHWENDER <icon:github[] https://github.com/Ardemius/[GitHub] / icon:twitter[role="aqua"] https://twitter.com/thomasschwender[@thomasschwender]>
// Handling GitHub admonition blocks icons
ifndef::env-github[:icons: font]
ifdef::env-github[]
:status:
:outfilesuffix: .adoc
:caution-caption: :fire:
:important-caption: :exclamation:
:note-caption: :paperclip:
:tip-caption: :bulb:
:warning-caption: :warning:
endif::[]
:imagesdir: ./images
:source-highlighter: highlightjs
:highlightjs-languages: asciidoc
// We must enable experimental attribute to display Keyboard, button, and menu macros
:experimental:
// Next 2 ones are to handle line breaks in some particular elements (list, footnotes, etc.)
:lb: pass:[<br> +]
:sb: pass:[<br>]
// check https://github.com/Ardemius/personal-wiki/wiki/AsciiDoctor-tips for tips on table of content in GitHub
:toc: macro
:toclevels: 2
// To number the sections of the table of contents
//:sectnums:
// Add an anchor with hyperlink before the section title
:sectanchors:
// To turn off figure caption labels and numbers
:figure-caption!:
// Same for examples
//:example-caption!:
// To turn off ALL captions
// :caption:

toc::[]

Programme du salon : https://mobile.devoxx.com/events/devoxxfr2024/schedule

== JOUR 1 : MERCREDI 17/04

=== 09:00 -> 09:25 - Keynote - Amphi bleu : Bienvenue √† Devoxx France 2024

image:20240417_Devoxx-France_00.jpg[]

=== 09:35 -> 10:00 - keynote - Amphi bleu : IA en m√©decine : o√π en sommes-nous ?

Pr√©sent√© par Jean-Emmanuel Bibault

.biographie
--
Jean-Emmanuel est m√©decin canc√©rologue et chercheur sp√©cialis√© en Intelligence Artificielle. 
Il a un doctorat en informatique biom√©dicale et a r√©alis√© un post-doctorat √† l'Universit√© de Stanford, dans le laboratoire d'Intelligence Artificielle appliqu√©e √† la Sant√©. 
Il est Professeur des Universit√©s - Praticien Hospitalier √† l'Universit√© de Paris / H√¥pital Europ√©en Georges Pompidou et chercheur √† l'INSERM. Ses recherches portent sur l'apprentissage machine appliqu√© au diagnostic et √† la pr√©diction. 

Il est laur√©at 2019 de l'Acad√©mie Nationale de M√©decine pour ses travaux sur la pr√©diction de la r√©ponse th√©rapeutique par Intelligence Artificielle. Il a par ailleurs d√©velopp√© plusieurs applications iPhone et Android et cofond√© une startup dans ce domaine, revendue en 2014.

En 2023, il a publi√© "2041, L'Odyss√©e de la m√©decine" aux Editions Equateurs, livre qui raconte comment l'IA en m√©decine est n√©e et comment elle a et va changer les soins.
--

.abstract
--
Les techniques de machine learning sont actuellement utilis√©es pour entra√Æner de nombreux mod√®les en m√©decine. Pourquoi connaissons-nous un tel √¢ge d'or de l'IA appliqu√©e √† la m√©decine ? 

Cette pr√©sentation illustrera l'utilisation de l'IA par diff√©rents exemples publi√©s : pr√©diction du risque de d√©velopper un risque 5 ans √† l'avance, interpr√©tation automatis√©e d'image m√©dicale, d√©tection par Deep Learning de m√©lanome, pr√©diction de la survie sur simple scanner, pilotage de robots chirurgicaux, d√©pistage de la d√©pression sur instagram, chaque exemple sera expliqu√© et comment√©. Mais l'IA comporte √©galement des risques li√©s √† la gestion des donn√©es d'entra√Ænement, aux biais ou encore les attaques adversarielles. Les perspectives de d√©veloppement √† 10 √† 15 ans seront enfin abord√©es pour comprendre comment l'IA va changer la sant√© de tous.
--

* "Intelligence" en anglais ne se traduit en fait PAS par "intelligence" en fran√ßais, mais plut√¥t par "capacit√© de renseignement"

.Acc√©l√©ration de l'IA depuis 1940
image:20240417_Devoxx-France_04.jpg[]

.Toutes les donn√©es m√©dicales suivantes sont maintenant digitalis√©es
image:20240417_Devoxx-France_05.jpg[]

* Parmi les frameworks d'IA les plus utilis√©s : 
    1. Pytorch
    2. TensorFlow
    3. Scikit-learn

-> Tous sont am√©ricains...

* Actuellement les donn√©es m√©dicales sont encore TRES mal structur√©es 
    ** Encore BEAUCOUP de travail √† ce niveau    

* *XGBoost* : LE framework pour l'analyse de donn√©es tabulaires

* Quand on parle d'*analyse d'images*, il est tout le temps question de *Deep Learning*

* Algo / papier de Stanford sur un scan de peau (m√©lanome) et l'IA donne de meilleurs r√©sultats que les 21 dermatologues auxquels elle √©tait compar√©e.

* Sous 10 15 ans, on aura des op√©rations m√©dicales, parmi les plus simples, qui seront totalement automatis√©es.

.L'IA g√©n√©rative fait de plus en plus "mieux" que les m√©decins
image:20240417_Devoxx-France_06.jpg[]

* *Y COMPRIS pour l'empathie* que "simule" l'IA (qui est meilleure que son g√©n√©raliste quand on le consulte tard le soir une fois qu'il est crev√© d'avoir vu 50 patients...)

.Generative adversarial networks (GANs)
image:20240417_Devoxx-France_07.jpg[]

* On se retrouve avec l'empoisonnement de donn√©es √† la Glaze, auquel il va falloir faire TRES attention dans le milieu m√©dical -> TOUJOURS v√©rifier ses donn√©es !

* Au Japon, via un r√©seau neuronal, on commence √† arriver √† *"lire dans les pens√©es"* ET CA MARCHE ! ü§Ø
    ** Donc petits probl√®mes √† pr√©voir d'interrogatoire non consentis et tr√®s efficaces...

Donc, pour l'avenir : le m√©decin artificiel

image:20240417_Devoxx-France_08.jpg[]

*Q&A :* 

* Jean-Emmanuel : *le meilleur des tests* (pour √©viter des biais par exemple) est (et restera probablement) l'*essai clinique*.
    ** la FAC d'Emmanuel est la 1ere √† avoir un DU d'IA en sant√©, MAIS ce n'est pas une formation obligatoire
    ** Mais on a un probl√®me sur la formation des √©tudiants en m√©decine aujourd'hui, qui seront m√©decins dans 10 ans, et qui ne seront pas ou pas suffisamment form√©s √† l'IA alors qu'elle sera partout autour d'eux.

* Enorme risque de perte de connaissances en m√™me temps que l'IA va "aider" les m√©decins
    ** Comme pour les pilotes de ligne, il va y avoir des √©preuves o√π ils vont √™tre test√©s SEULS, sans pouvoir √™tre aider par l'IA.

Conclusion : 

    * Jean-Emmanuel est un g√©nie... Comment peut-on r√©ussir √† faire autant de choses
    * sujet ma√Ætris√© techniquement de bout en bout, aucune h√©sitation √† l'oral, des d√©tails, un sans faute, l'un des meilleurs orateurs que j'ai jamais entendu üëç

=== 10:30 -> 12:30 - Hands-on Lab - Neuilly 253 : Hands-on Gemini, the Google DeepMind LLM

* Pr√©sent√© par Google : Mete Atamel, Valentin Deleplace
    ** Le workshop a √©t√© con√ßu par Guillaume LAFORGE
    ** Tous les 3 sont developer advocates chez Google

.abstract
--
In this hands-on workshop, you will get to code using Gemini, the new Large Language Model from Google DeepMind. 

You will first start by familiarizing yourself with the model's capabilities. Then you will use Gemini in different concrete cases, such as extracting data from unstructured text, document classification, but also searching your own documents, or how to supplement the model by integrating the call to external APIs.

The workshop will be conducted using the Java language and the LangChain4j library. Come equipped with a laptop. We will code together in the cloud, no need for any special installation on your machine.
--

.Ressources pour le Hands-on Lab
image:20240417_Devoxx-France_09.jpg[]

    * URL : https://bit.ly/gemini-devoxx-2024
        ** codelab : https://codelabs.developers.google.com/codelabs/gemini-java-developers
        ** repo : https://github.com/glaforge/gemini-workshop-for-java-developers/tree/main
        ** Google Cloud Console : https://console.cloud.google.com/

==== Partie th√©orique

.D√©finition du AI landscape
image:20240417_Devoxx-France_10.jpg[]

* On commence √† diff√©rencier dans l'IA gen "Image Gen" et "LLMs"
    ** Aujourd'hui, on focus sur la partie "LLM"

.Evolution des LLMs depuis l'invention des Transformer par Google en 2017
image:20240417_Devoxx-France_11.jpg[]

-> Encore une fois, on se r√©f√®re aux graphes de *LifeArchitect.ai* pour la comparaison des mod√®les

.Google (Cloud) Lanscape for AI
image:20240417_Devoxx-France_12.jpg[]

* Aujourd'hui : 
    ** Duet AI, Bard -> Gemini
    ** PaLM  (devenu un ancien mod√®le) -> Gemini
    ** MakerSuite -> Google AI Studio

.Gemini is an umbrella brand for Google for all their Gemini products
image:20240417_Devoxx-France_13.jpg[]

* Gemini is a brand AND a model
    ** a multimodal model

.Gemini 1.5 characteristics
image:20240417_Devoxx-France_14.jpg[]

* ET il y a une *version opensource de Gemini* : *Gemma*
    ** qu'on peut utiliser dans son propre cluster Kubernetes
    ** Gemma : open weights model derived from Gemini

* You can use Gemini from *Google AI Studio* or *Vertex AI* in Google Cloud
    ** Google AI Studio and Vertex AI sont 2 produits diff√©rents, bien distincts

* -> Dans ce workshop, nous allons utiliser *Vertex AI* dans Google Cloud.
    ** Et *LangChain4j*

==== Workshop

image:20240417_Devoxx-France_15.jpg[]
image:20240417_Devoxx-France_16.jpg[]

Etape 3 : Preparing your development environment

    * Pas besoin de la version 21 de Java pour ce workshop
    * On va se servir du *Cloud Code Editor* (un VSCode like dans le Cloud)

image:20240417_Devoxx-France_17.jpg[]
image:20240417_Devoxx-France_18.jpg[]

Etape 4 : First call to the Gemini model

image:20240417_Devoxx-France_19.jpg[]

IMPORTANT: les LLMs sont stateless : si on ne fait "rien", par d√©faut les LLMs ne se "souviennent" pas des pr√©c√©dents prompts.

IMPORTANT: M√™me avec une temp√©rature de 0, il n'y a PAS de "vraie" garantie d'avoir le m√™me r√©sultat en appelant 2 fois le m√™me prompt.

Etape 5 : Chat with Gemini

Attention, avec `MessageWindowChatMemory.builder().maxMessages(20)` on peut garder les 20 derniers messages.

Etape 6 : Multimodality with Gemini

Etape 7 : Extract structured information from unstructured text

    * Et l√† on se rend compte d'un des probl√®mes de l'IA gen : +
    Toutes les personnes du workshop ont la m√™me erreur, y compris les speakers : 
+
[source, bash]
----
Exception in thread "main" com.google.gson.JsonSyntaxException: java.lang.IllegalStateException: Expected BEGIN_OBJECT but was STRING at line 1 column 1 path $
        at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:397)
        at com.google.gson.Gson.fromJson(Gson.java:1227)
        at com.google.gson.Gson.fromJson(Gson.java:1137)
        at com.google.gson.Gson.fromJson(Gson.java:1047)
        at com.google.gson.Gson.fromJson(Gson.java:982)
        at dev.langchain4j.internal.GsonJsonCodec.fromJson(GsonJsonCodec.java:66)
        at dev.langchain4j.internal.Json.fromJson(Json.java:79)
        at dev.langchain4j.service.ServiceOutputParser.parse(ServiceOutputParser.java:87)
        at dev.langchain4j.service.DefaultAiServices$1.invoke(DefaultAiServices.java:179)
        at gemini.workshop.$Proxy2.extractPerson(Unknown Source)
        at gemini.workshop.ExtractData.main(ExtractData.java:56)
Caused by: java.lang.IllegalStateException: Expected BEGIN_OBJECT but was STRING at line 1 column 1 path $
        at com.google.gson.stream.JsonReader.beginObject(JsonReader.java:393)
        at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:386)
        ... 10 more

FAILURE: Build failed with an exception.
----

    * -> En fait, le JSON g√©n√©r√© par le LLM doit √™tre "mauvais" depuis aujourd'hui, il doit manquer le tout 1er "{" du doc, d'o√π le "Expected BEGIN_OBJECT but was STRING"
        ** OR, "hier cela marchait" cf les speakers
        ** MAIS il n'y a aucune garantie d'avoir 2 fois le m√™me r√©sultat (completion) avec un LLM, d'o√π le probl√®me

    * "MORALITE" : *importance de la programmation d√©fensive avec un LLM !*
        ** La completion d'hier n'est PAS garantie aujourd'hui, il faut donc S'ASSURER que la completion matche toujours les crit√®res attendus

Etape 8 : Structure prompts with prompt templates

Etape 9 : Text classification with few-shot prompting

Etape 10 : RAG

The document is split in chunks thanks to the DocumentSplitters class. It is going to split the text of the PDF file into snippets of 500 characters, with an overlap of 100 characters (with the following chunk, to avoid cutting words or sentences, in bits and pieces).

Etape 11 : Function calling

=== -------- 12:20 -> 13:30 : LUNCH --------

=== 12:35 -> 12:50 - quickie - Paris 141 : R√©volutionnez votre exp√©rience utilisateur avec les Progressive Web Apps

Pr√©sent√© par Khadija ABDELOUALI de Ippon

.abstract
--
R√©volutionner le monde du web en cr√©ant une nouvelle g√©n√©ration d'applications ¬´ progressives ¬ª et proposer une alternative aux applications natives üì± avec une seule et unique base de code : tel est l'enjeu des PWAs.
Entre l'essor du mobile et l'envol des OS divers et vari√©s, les co√ªts de d√©veloppement pour chaque plateforme üí∂, la consommation des ressources ainsi que la proc√©dure de validation sur les diff√©rents app stores deviennent des challenges primordiaux auxquels il faut apporter une r√©ponse de toute urgenceüö®.
La solution ¬´ Progressive Web App ¬ª apparut ainsi pour la premi√®re fois en 2015 et a depuis √©t√© largement adopt√©e par Starbucks, Pinterest, Uber, ‚Ä¶
Alors, le pari des PWAs a-t-il √©t√© remport√© üèÜ?
üì¢ Pour le savoir, ne manquez surtout pas cette conf√©rence, o√π nous plongerons dans les fondamentaux de cette technologie r√©volutionnaire et d√©couvrirons √©galement comment les PWAs combinent le meilleur des sites web üåê et des applications mobiles üì±, afin d'offrir une exp√©rience utilisateur sans pr√©c√©dent üë®‚Äçüíª.
--

* Les PWA : cr√©√©es par Google en 2015

Avantages : 

    * r√©duction des co√ªts
    * facilit√© de distribution : pas besoin de passer par les stores Google ou Apple
    * disponibilit√©s des ressources : plus de facilit√© √† trouver des devs web (hors mobile)
    * √©conomie d'√©nergie
    * mise √† jour optimis√©es : on ne r√©cup√©re QUE les fichiers mis √† jour, pas la peine de packager une application enti√®re

.Passage de Starbucks d'une application mobile √† une PWA
image:20240417_Devoxx-France_20.jpg[]

image:20240417_Devoxx-France_21.jpg[]

* C'est le *manifest* et le *service worker* de la PWA qui indiquent au navigateur que c'est une "application" qu'il doit installer

.Lighthouse permet d'√©valuer l'ad√©quation de l'application web aux crit√®res techniques pour √™tre une PWA.
image:20240417_Devoxx-France_22.jpg[]
image:20240417_Devoxx-France_23.jpg[]

.Conclusion : l'approche pour savoir si on doit faire une PWA
image:20240417_Devoxx-France_24.jpg[]

=== 13:30 -> 14:15 - conference - Neuilly 252AB : Du Clic √† la Conversation : rempla√ßons boutons et formulaires par un LLM !

Pr√©sent√© par Marie-Alice Blete, Softeam engineer chez Worldline

.abstract
--
Pr√©parez-vous √† voyager dans le domaine de l'interaction homme/machine. 
Vous connaissez la premi√®re r√©volution : la souris et l'interface graphique ? Nous sommes d√©sormais √† l'√®re de la deuxi√®me r√©volution : l'interaction en langage naturel gr√¢ce a l'intelligence artificielle.

Dans cette pr√©sentation, nous allons metamorphoser une application standard en une application bas√©e sur un LLM. Dites adieu aux boutons et formulaires car nous nous appr√™tons √† r√©√©crire les r√®gles de l'interface utilisateur !

Nous d√©buterons par les bases, avec un bref rappel des principes de LLM, suivi d'une premi√®re solution exploitant l'*API OpenAI*. 
Ensuite, nous verrons deux autres solutions plus avanc√©es, dont une comprenant l'utilisation d'agents avec le framework *LangChain*.

√Ä la fin de cette pr√©sentation, vous disposerez de toutes les connaissances n√©cessaires pour vous lancer. Vous aurez √©galement une liste d'astuces, de conseils, ainsi qu'une bonne compr√©hension des √©cueils pour int√©grer des LLM dans vos developpements. Passons du clic √† la conversation !
--

* Les LLMs sont la 2e r√©volution dans l'interaction homme / machine
    ** La 1ere √©tant l'invention de la souris

.LLMs : ceux dispo via une API et ceux √† d√©ployer soi-m√™me
image:20240417_Devoxx-France_25.jpg[]

* Nouveau rappel : les LLMs sont *STATELESS* +
-> Ils ne se "rappellent" les pr√©c√©dentes interactions

.Interaction et conversation
[NOTE]
====
* 1 *interaction* = 1 paire de question / r√©ponse
* 1 *conversation* est un ensemble d'interactions
====

Probl√©matique : remplacer une IHM et toutes ces pop-up nest√©es par un LLM...

NOTE: les demo de Marie-Alice semble √™tre sur "venv" Python

* 1ere solution : *tout remplacer par 1 prompt*

    1. donner le contexte
    2. d√©finir le format de sortie +
    image:20240417_Devoxx-France_26.jpg[]
    image:20240417_Devoxx-France_27.jpg[]
    image:20240417_Devoxx-France_28.jpg[]

    3. donner des instructions pr√©cises
    4. prompt de d√©part

    ** Conclusion : 
        *** pas scalable
        *** confiance ?
        *** maintenance difficile

* 2e solution : *essayer une approche machine √† √©tat*

image:20240417_Devoxx-France_29.jpg[]
image:20240417_Devoxx-France_30.jpg[]

    ** les prompts des transitions vont avoir la partie m√©tier
    ** Et on a DE NOUVEAU un "bug" du LLM o√π le comportement d'aujourd'hui n'est pas celui d'hier, ce qui pose probl√®me

    ** Conclusion : 
        *** XXX
        *** consomme moins de ressources
        *** plus facile √† valider

* 3e solution : *utiliser des agents* (LangChain ici)

image:20240417_Devoxx-France_31.jpg[]

    ** *Gradio* utilis√© ici pour la demo. +
    -> Parfait pour faire de petites demo, MAIS √† ne PAS utiliser en prod...

.Comparaison de ces 3 solutions
image:20240417_Devoxx-France_32.jpg[]

* Dans tous les cas, il FAUT *√©valuer les prompts* !
    ** exemple d'outil : *prompt-foo*

* Autre probl√®me : *ce qui √©tait hier ne sera peut-√™tre plus aujourd'hui...* +
-> Un LLM n'est PAS un syst√®me d√©terministe
    ** Il ne faut pas essayer de le rendre compl√®tement d√©terministe (perte de cr√©ativit√©), mais il faut mettre en place des *process de v√©rification* +
    image:20240417_Devoxx-France_33.jpg[]
    ** Et si √ßa ne marche pas, il faut mettre en place des *strat√©gies de repli* +
    image:20240417_Devoxx-France_34.jpg[]
    ** Exemple de *retry* pour essayer de garantir un "bon" format JSON +
    image:20240417_Devoxx-France_35.jpg[]
    image:20240417_Devoxx-France_36.jpg[]

* Attention au *prompt injection*
    ** mettre un disclaimer car on PEUT se faire "hacker"

* Gestion du *co√ªt*
    ** utiliser un cache pour les questions fr√©quentes
    ** XXX

* Attention √† la confidentialit√© des donn√©es ! 
    ** OpenAI est aux US, voulez-vous, pouvez-vous envoyer les donn√©es de vos clients l√†-bas ?

Conclusion : 

    * de bonnes explications et astuces √† r√©cup√©rer !

.Ressources
image:20240417_Devoxx-France_37.jpg[]

    * Tout le code et les slides sont dispo sur https://github.com/malywut/clicks2conversations

=== 15:40 -> 16:25 - conference - Paris 242AB : Crafting your own RAG system: Leveraging 30+ LLMs for enhanced performance

Pr√©sent√© par Stephan Janssen, cr√©ateur de Devoxx (Belgique, l'original)

.abstract
--
In this talk you'll learn how to set up a RAG (Retrieval-Augmented Generation) system against 30+ different Large Language Models using Java.

We'll show you step-by-step how to ingest documents, choose the best text splitter strategies, find similar documents, answer questions, and create a chatbot.

Then, we'll see how to test and compare different AI models, both from open sources and private ones, and whether they are stored on your own computer or accessed online.
You'll walk away knowing how to setup a well balanced RAG system using Java and the best performing and/or cheapest LLM.
--

* How many talks did Brian Goetz give at Devoxx Belgium ? 
* How many presentation did Brian Goetz give at Devoxx Belgium ? 
    ** eh bien, notre LLM nous donne 2 r√©ponses diff√©rentes...

.Architecture d'un RAG par St√©phane Janssen
image:20240417_Devoxx-France_39.jpg[]

* ReRanker : NON semantic (IA) sort

* LLM providers locally running on your laptop : 
    ** Ollama
    ** LM Studio
    ** GPT4All
    ** Apple MLX

* LLM providers online :
    ** OpenAI
    ** Claude
    ** Groq

image:20240417_Devoxx-France_40.jpg[]

-> Tous sont support√©s par LangChain (√† v√©rifier !)

.St√©phane a d√©velopp√© sa propre BM25 (ReRanker) Java implementation, en 1 we en se faisant aider de ChatGPT et Claude
image:20240417_Devoxx-France_38.jpg[]

* et son impl√©mentation BM25 est gratuite...

.Import Data (Ingestion) : extract data from "content"
image:20240417_Devoxx-France_41.jpg[]

* *To Split or... Not to split* ?!
    ** des contects qui montent maintenant au 1M de tokens...
    ** from 0.10$ to 120$ for 1M tokens
    ** milliseconds to minutes (10 min pour 1M tokens)
    ** Be aware : "context injection" does reduce hallucinations

.Advanced Splitting Strategies
image:20240417_Devoxx-France_42.jpg[]

-> Regarder le talk de *Text Splitting* de *Greg Kamradt* : +
https://www.youtube.com/watch?v=8OJC21T2SL4

* Importance capitale de l'embedding
    ** et plusieurs mod√®les pour faire de l'embedding sont dispo

.Vector Databases
image:20240417_Devoxx-France_43.jpg[]
image:20240417_Devoxx-France_44.jpg[]

* Regarder le tr√®s bon talk sur le Vector DB de *Alexander Chatzizacharias* : +
https://www.youtube.com/watch?v=W-i8bcxkXok

* On ne peut pas utiliser PostgrePG pour de l'embedding avec OpenAI, car il ne supporte que 2000 dimensions quand OpenAI en utilise 3000 (A VERIFIER)

.St√©phane a √©galement d√©velopp√©, car manquant, LangChain4J-cohere (Langchain4J compliant Cohere embedding model)
image:20240417_Devoxx-France_45.jpg[]

    * https://github.com/stephanj/langchain4j-cohere
    * Gemini : "Cohere is a novel approach to representing text data that aims to capture both semantic and syntactic information in a more effective way compared to traditional embedding methods."

.Conclusion and lessons learned
image:20240417_Devoxx-France_46.jpg[]

* Embeddings models have an *input limit*
* the bigger the embedding dimensions the higher the hosting cost
* multi language embedding is a thing
* QUALITY of your embedding influences the QUALITY of your results

* St√©phane a √©crit le plugin "Devoxx Genie" pour IntelliJ

image:20240417_Devoxx-France_47.jpg[]
image:20240417_Devoxx-France_48.jpg[]

-> Et Claude 3 Opus donne apparemment des r√©sultats exceptionnels

image:20240417_Devoxx-France_49.jpg[]

* Ressources GitHub du talk : 
    ** https://github.com/stephanj/rag-genie
    ** https://github.com/devoxx/devoxxgenieIDEAplugin

Conclusion : 

    * Comme Jean-Emmanuel, St√©phane est vraiment impressionnant quand on voit tout ce qu'il arrive √† cr√©er en si peu de temps

=== 17:50 -> 18:20 - tools-in-action - Neuilly 153 : Creating a documentation site for users with AsciiDoc and Antora

Pr√©sent√© par Alexander Schwartz, Principal Software Engineer at Red Hat

.abstract
--
Documentation for a software project is essential for users, administrator and developers alike: Users need to find the right tutorials, reference documentation and answers to their questions, administrators need to know how to install and operator the software, while developers need other documents to get started contributing, and share concepts and architectures for fellow contributors.

The tool Antora simplifies the process by creating documentation websites from AsciiDoc sources stored in Git repositories. Users can browse the generated website and select the version matching the software they use. Navigation outlines, search and cross-references between pages allow users to find answers to their questions. Several open-source software projects like Camel, Debezium and Couchbase use this solution.
For developers it is normal to develop software in collaboration using their IDE and a version control system like Git. The same type of collaboration is possible when all documentation is versioned in a markup-format like AsciiDoc.

This talk presents the basics of an Antora setup and walks through all the steps from editing content in the IDE to updating the documentation site using continuous integration and delivery.
--

URL : https://docs.antora.org

.Sommaire du talk
image:20240417_Devoxx-France_53.jpg[]

1. How users search for informations

    * *Every page is "page one"* : +
    image:20240417_Devoxx-France_50.jpg[]

2. How AsciiDoc and Antora help

    ** Antora provides publishing tools and documentation structure +
    image:20240417_Devoxx-France_51.jpg[]

    ** AsciiDoc is the language, AsciiDoctor is a toolchain 
    image:20240417_Devoxx-France_52.jpg[]

3. Setting up Antora

.Antora structure
image:20240417_Devoxx-France_54.jpg[]

.Antora process
image:20240417_Devoxx-France_55.jpg[]

* Antora va permettre la g√©n√©ration d'un site statique (logique)

1. d√©finition des r√¥les for Antora
2. first steps de configuration d'Antora +
image:20240417_Devoxx-France_56.jpg[]

Conclusion : 

    * Le talk passe pas mal de temps √† pr√©senter AsciiDoc, et je n'arrive pas trop √† voir l'int√©r√™t d'Antora rapport √† AsciiDoc et AsciiDoctor seuls








