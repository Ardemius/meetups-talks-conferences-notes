= Devoxx France 2024
Thomas SCHWENDER <icon:github[] https://github.com/Ardemius/[GitHub] / icon:twitter[role="aqua"] https://twitter.com/thomasschwender[@thomasschwender]>
// Handling GitHub admonition blocks icons
ifndef::env-github[:icons: font]
ifdef::env-github[]
:status:
:outfilesuffix: .adoc
:caution-caption: :fire:
:important-caption: :exclamation:
:note-caption: :paperclip:
:tip-caption: :bulb:
:warning-caption: :warning:
endif::[]
:imagesdir: ./images
:source-highlighter: highlightjs
:highlightjs-languages: asciidoc
// We must enable experimental attribute to display Keyboard, button, and menu macros
:experimental:
// Next 2 ones are to handle line breaks in some particular elements (list, footnotes, etc.)
:lb: pass:[<br> +]
:sb: pass:[<br>]
// check https://github.com/Ardemius/personal-wiki/wiki/AsciiDoctor-tips for tips on table of content in GitHub
:toc: macro
:toclevels: 2
// To number the sections of the table of contents
//:sectnums:
// Add an anchor with hyperlink before the section title
:sectanchors:
// To turn off figure caption labels and numbers
:figure-caption!:
// Same for examples
//:example-caption!:
// To turn off ALL captions
// :caption:

toc::[]

Programme du salon : https://mobile.devoxx.com/events/devoxxfr2024/schedule

== JOUR 1 : MERCREDI 17/04

=== 09:00 -> 09:25 - Keynote - Amphi bleu : Bienvenue √† Devoxx France 2024

image:20240417_Devoxx-France_00.jpg[]

=== 09:35 -> 10:00 - keynote - Amphi bleu : IA en m√©decine : o√π en sommes-nous ?

Pr√©sent√© par Jean-Emmanuel Bibault

.biographie
--
Jean-Emmanuel est m√©decin canc√©rologue et chercheur sp√©cialis√© en Intelligence Artificielle. 
Il a un doctorat en informatique biom√©dicale et a r√©alis√© un post-doctorat √† l'Universit√© de Stanford, dans le laboratoire d'Intelligence Artificielle appliqu√©e √† la Sant√©. 
Il est Professeur des Universit√©s - Praticien Hospitalier √† l'Universit√© de Paris / H√¥pital Europ√©en Georges Pompidou et chercheur √† l'INSERM. Ses recherches portent sur l'apprentissage machine appliqu√© au diagnostic et √† la pr√©diction. 

Il est laur√©at 2019 de l'Acad√©mie Nationale de M√©decine pour ses travaux sur la pr√©diction de la r√©ponse th√©rapeutique par Intelligence Artificielle. Il a par ailleurs d√©velopp√© plusieurs applications iPhone et Android et cofond√© une startup dans ce domaine, revendue en 2014.

En 2023, il a publi√© "2041, L'Odyss√©e de la m√©decine" aux Editions Equateurs, livre qui raconte comment l'IA en m√©decine est n√©e et comment elle a et va changer les soins.
--

.abstract
--
Les techniques de machine learning sont actuellement utilis√©es pour entra√Æner de nombreux mod√®les en m√©decine. Pourquoi connaissons-nous un tel √¢ge d'or de l'IA appliqu√©e √† la m√©decine ? 

Cette pr√©sentation illustrera l'utilisation de l'IA par diff√©rents exemples publi√©s : pr√©diction du risque de d√©velopper un risque 5 ans √† l'avance, interpr√©tation automatis√©e d'image m√©dicale, d√©tection par Deep Learning de m√©lanome, pr√©diction de la survie sur simple scanner, pilotage de robots chirurgicaux, d√©pistage de la d√©pression sur instagram, chaque exemple sera expliqu√© et comment√©. Mais l'IA comporte √©galement des risques li√©s √† la gestion des donn√©es d'entra√Ænement, aux biais ou encore les attaques adversarielles. Les perspectives de d√©veloppement √† 10 √† 15 ans seront enfin abord√©es pour comprendre comment l'IA va changer la sant√© de tous.
--

* "Intelligence" en anglais ne se traduit en fait PAS par "intelligence" en fran√ßais, mais plut√¥t par "capacit√© de renseignement"

.Acc√©l√©ration de l'IA depuis 1940
image:20240417_Devoxx-France_04.jpg[]

.Toutes les donn√©es m√©dicales suivantes sont maintenant digitalis√©es
image:20240417_Devoxx-France_05.jpg[]

* Parmi les frameworks d'IA les plus utilis√©s : 
    1. Pytorch
    2. TensorFlow
    3. Scikit-learn

-> Tous sont am√©ricains...

* Actuellement les donn√©es m√©dicales sont encore TRES mal structur√©es 
    ** Encore BEAUCOUP de travail √† ce niveau    

* *XGBoost* : LE framework pour l'analyse de donn√©es tabulaires

* Quand on parle d'*analyse d'images*, il est tout le temps question de *Deep Learning*

* Algo / papier de Stanford sur un scan de peau (m√©lanome) et l'IA donne de meilleurs r√©sultats que les 21 dermatologues auxquels elle √©tait compar√©e.

* Sous 10 15 ans, on aura des op√©rations m√©dicales, parmi les plus simples, qui seront totalement automatis√©es.

.L'IA g√©n√©rative fait de plus en plus "mieux" que les m√©decins
image:20240417_Devoxx-France_06.jpg[]

* *Y COMPRIS pour l'empathie* que "simule" l'IA (qui est meilleure que son g√©n√©raliste quand on le consulte tard le soir une fois qu'il est crev√© d'avoir vu 50 patients...)

.Generative adversarial networks (GANs)
image:20240417_Devoxx-France_07.jpg[]

* On se retrouve avec l'empoisonnement de donn√©es √† la Glaze, auquel il va falloir faire TRES attention dans le milieu m√©dical -> TOUJOURS v√©rifier ses donn√©es !

* Au Japon, via un r√©seau neuronal, on commence √† arriver √† *"lire dans les pens√©es"* ET CA MARCHE ! ü§Ø
    ** Donc petits probl√®mes √† pr√©voir d'interrogatoire non consentis et tr√®s efficaces...

Donc, pour l'avenir : le m√©decin artificiel

image:20240417_Devoxx-France_08.jpg[]

*Q&A :* 

* Jean-Emmanuel : *le meilleur des tests* (pour √©viter des biais par exemple) est (et restera probablement) l'*essai clinique*.
    ** la FAC d'Emmanuel est la 1ere √† avoir un DU d'IA en sant√©, MAIS ce n'est pas une formation obligatoire
    ** Mais on a un probl√®me sur la formation des √©tudiants en m√©decine aujourd'hui, qui seront m√©decins dans 10 ans, et qui ne seront pas ou pas suffisamment form√©s √† l'IA alors qu'elle sera partout autour d'eux.

* Enorme risque de perte de connaissances en m√™me temps que l'IA va "aider" les m√©decins
    ** Comme pour les pilotes de ligne, il va y avoir des √©preuves o√π ils vont √™tre test√©s SEULS, sans pouvoir √™tre aider par l'IA.

Conclusion : 

    * Jean-Emmanuel est un g√©nie... Comment peut-on r√©ussir √† faire autant de choses
    * sujet ma√Ætris√© techniquement de bout en bout, aucune h√©sitation √† l'oral, des d√©tails, un sans faute, l'un des meilleurs orateurs que j'ai jamais entendu üëç

=== 10:30 -> 12:30 - Hands-on Lab - Neuilly 253 : Hands-on Gemini, the Google DeepMind LLM

* Pr√©sent√© par Google : Mete Atamel, Valentin Deleplace
    ** Le workshop a √©t√© con√ßu par Guillaume LAFORGE
    ** Tous les 3 sont developer advocates chez Google

.abstract
--
In this hands-on workshop, you will get to code using Gemini, the new Large Language Model from Google DeepMind. 

You will first start by familiarizing yourself with the model's capabilities. Then you will use Gemini in different concrete cases, such as extracting data from unstructured text, document classification, but also searching your own documents, or how to supplement the model by integrating the call to external APIs.

The workshop will be conducted using the Java language and the LangChain4j library. Come equipped with a laptop. We will code together in the cloud, no need for any special installation on your machine.
--

.Ressources pour le Hands-on Lab
image:20240417_Devoxx-France_09.jpg[]

    * URL : https://bit.ly/gemini-devoxx-2024
        ** codelab : https://codelabs.developers.google.com/codelabs/gemini-java-developers
        ** repo : https://github.com/glaforge/gemini-workshop-for-java-developers/tree/main
        ** Google Cloud Console : https://console.cloud.google.com/

==== Partie th√©orique

.D√©finition du AI landscape
image:20240417_Devoxx-France_10.jpg[]

* On commence √† diff√©rencier dans l'IA gen "Image Gen" et "LLMs"
    ** Aujourd'hui, on focus sur la partie "LLM"

.Evolution des LLMs depuis l'invention des Transformer par Google en 2017
image:20240417_Devoxx-France_11.jpg[]

-> Encore une fois, on se r√©f√®re aux graphes de *LifeArchitect.ai* pour la comparaison des mod√®les

.Google (Cloud) Lanscape for AI
image:20240417_Devoxx-France_12.jpg[]

* Aujourd'hui : 
    ** Duet AI, Bard -> Gemini
    ** PaLM  (devenu un ancien mod√®le) -> Gemini
    ** MakerSuite -> Google AI Studio

.Gemini is an umbrella brand for Google for all their Gemini products
image:20240417_Devoxx-France_13.jpg[]

* Gemini is a brand AND a model
    ** a multimodal model

.Gemini 1.5 characteristics
image:20240417_Devoxx-France_14.jpg[]

* ET il y a une *version opensource de Gemini* : *Gemma*
    ** qu'on peut utiliser dans son propre cluster Kubernetes
    ** Gemma : open weights model derived from Gemini

* You can use Gemini from *Google AI Studio* or *Vertex AI* in Google Cloud
    ** Google AI Studio and Vertex AI sont 2 produits diff√©rents, bien distincts

* -> Dans ce workshop, nous allons utiliser *Vertex AI* dans Google Cloud.
    ** Et *LangChain4j*

==== Workshop

image:20240417_Devoxx-France_15.jpg[]
image:20240417_Devoxx-France_16.jpg[]

Etape 3 : Preparing your development environment

    * Pas besoin de la version 21 de Java pour ce workshop
    * On va se servir du *Cloud Code Editor* (un VSCode like dans le Cloud)

image:20240417_Devoxx-France_17.jpg[]
image:20240417_Devoxx-France_18.jpg[]

Etape 4 : First call to the Gemini model

image:20240417_Devoxx-France_19.jpg[]

IMPORTANT: les LLMs sont stateless : si on ne fait "rien", par d√©faut les LLMs ne se "souviennent" pas des pr√©c√©dents prompts.

IMPORTANT: M√™me avec une temp√©rature de 0, il n'y a PAS de "vraie" garantie d'avoir le m√™me r√©sultat en appelant 2 fois le m√™me prompt.

Etape 5 : Chat with Gemini

Attention, avec `MessageWindowChatMemory.builder().maxMessages(20)` on peut garder les 20 derniers messages.

Etape 6 : Multimodality with Gemini

Etape 7 : Extract structured information from unstructured text

    * Et l√† on se rend compte d'un des probl√®mes de l'IA gen : +
    Toutes les personnes du workshop ont la m√™me erreur, y compris les speakers : 
+
[source, bash]
----
Exception in thread "main" com.google.gson.JsonSyntaxException: java.lang.IllegalStateException: Expected BEGIN_OBJECT but was STRING at line 1 column 1 path $
        at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:397)
        at com.google.gson.Gson.fromJson(Gson.java:1227)
        at com.google.gson.Gson.fromJson(Gson.java:1137)
        at com.google.gson.Gson.fromJson(Gson.java:1047)
        at com.google.gson.Gson.fromJson(Gson.java:982)
        at dev.langchain4j.internal.GsonJsonCodec.fromJson(GsonJsonCodec.java:66)
        at dev.langchain4j.internal.Json.fromJson(Json.java:79)
        at dev.langchain4j.service.ServiceOutputParser.parse(ServiceOutputParser.java:87)
        at dev.langchain4j.service.DefaultAiServices$1.invoke(DefaultAiServices.java:179)
        at gemini.workshop.$Proxy2.extractPerson(Unknown Source)
        at gemini.workshop.ExtractData.main(ExtractData.java:56)
Caused by: java.lang.IllegalStateException: Expected BEGIN_OBJECT but was STRING at line 1 column 1 path $
        at com.google.gson.stream.JsonReader.beginObject(JsonReader.java:393)
        at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:386)
        ... 10 more

FAILURE: Build failed with an exception.
----

    * -> En fait, le JSON g√©n√©r√© par le LLM doit √™tre "mauvais" depuis aujourd'hui, il doit manquer le tout 1er "{" du doc, d'o√π le "Expected BEGIN_OBJECT but was STRING"
        ** OR, "hier cela marchait" cf les speakers
        ** MAIS il n'y a aucune garantie d'avoir 2 fois le m√™me r√©sultat (completion) avec un LLM, d'o√π le probl√®me

    * "MORALITE" : *importance de la programmation d√©fensive avec un LLM !*
        ** La completion d'hier n'est PAS garantie aujourd'hui, il faut donc S'ASSURER que la completion matche toujours les crit√®res attendus

Etape 8 : Structure prompts with prompt templates

Etape 9 : Text classification with few-shot prompting

Etape 10 : RAG

The document is split in chunks thanks to the DocumentSplitters class. It is going to split the text of the PDF file into snippets of 500 characters, with an overlap of 100 characters (with the following chunk, to avoid cutting words or sentences, in bits and pieces).

Etape 11 : Function calling

=== ------------------------ 12:20 -> 13:30 : LUNCH ------------------------

=== 12:35 -> 12:50 - quickie - Paris 141 : R√©volutionnez votre exp√©rience utilisateur avec les Progressive Web Apps

Pr√©sent√© par Khadija ABDELOUALI de Ippon

.abstract
--
R√©volutionner le monde du web en cr√©ant une nouvelle g√©n√©ration d'applications ¬´ progressives ¬ª et proposer une alternative aux applications natives üì± avec une seule et unique base de code : tel est l'enjeu des PWAs.
Entre l'essor du mobile et l'envol des OS divers et vari√©s, les co√ªts de d√©veloppement pour chaque plateforme üí∂, la consommation des ressources ainsi que la proc√©dure de validation sur les diff√©rents app stores deviennent des challenges primordiaux auxquels il faut apporter une r√©ponse de toute urgenceüö®.
La solution ¬´ Progressive Web App ¬ª apparut ainsi pour la premi√®re fois en 2015 et a depuis √©t√© largement adopt√©e par Starbucks, Pinterest, Uber, ‚Ä¶
Alors, le pari des PWAs a-t-il √©t√© remport√© üèÜ?
üì¢ Pour le savoir, ne manquez surtout pas cette conf√©rence, o√π nous plongerons dans les fondamentaux de cette technologie r√©volutionnaire et d√©couvrirons √©galement comment les PWAs combinent le meilleur des sites web üåê et des applications mobiles üì±, afin d'offrir une exp√©rience utilisateur sans pr√©c√©dent üë®‚Äçüíª.
--

* Les PWA : cr√©√©es par Google en 2015

Avantages : 

    * r√©duction des co√ªts
    * facilit√© de distribution : pas besoin de passer par les stores Google ou Apple
    * disponibilit√©s des ressources : plus de facilit√© √† trouver des devs web (hors mobile)
    * √©conomie d'√©nergie
    * mise √† jour optimis√©es : on ne r√©cup√©re QUE les fichiers mis √† jour, pas la peine de packager une application enti√®re

.Passage de Starbucks d'une application mobile √† une PWA
image:20240417_Devoxx-France_20.jpg[]

image:20240417_Devoxx-France_21.jpg[]

* C'est le *manifest* et le *service worker* de la PWA qui indiquent au navigateur que c'est une "application" qu'il doit installer

.Lighthouse permet d'√©valuer l'ad√©quation de l'application web aux crit√®res techniques pour √™tre une PWA.
image:20240417_Devoxx-France_22.jpg[]
image:20240417_Devoxx-France_23.jpg[]

.Conclusion : l'approche pour savoir si on doit faire une PWA
image:20240417_Devoxx-France_24.jpg[]

=== 13:30 -> 14:15 - conference - Neuilly 252AB : Du Clic √† la Conversation : rempla√ßons boutons et formulaires par un LLM !

Pr√©sent√© par Marie-Alice Blete, Softeam engineer chez Worldline

.abstract
--
Pr√©parez-vous √† voyager dans le domaine de l'interaction homme/machine. 
Vous connaissez la premi√®re r√©volution : la souris et l'interface graphique ? Nous sommes d√©sormais √† l'√®re de la deuxi√®me r√©volution : l'interaction en langage naturel gr√¢ce a l'intelligence artificielle.

Dans cette pr√©sentation, nous allons metamorphoser une application standard en une application bas√©e sur un LLM. Dites adieu aux boutons et formulaires car nous nous appr√™tons √† r√©√©crire les r√®gles de l'interface utilisateur !

Nous d√©buterons par les bases, avec un bref rappel des principes de LLM, suivi d'une premi√®re solution exploitant l'*API OpenAI*. 
Ensuite, nous verrons deux autres solutions plus avanc√©es, dont une comprenant l'utilisation d'agents avec le framework *LangChain*.

√Ä la fin de cette pr√©sentation, vous disposerez de toutes les connaissances n√©cessaires pour vous lancer. Vous aurez √©galement une liste d'astuces, de conseils, ainsi qu'une bonne compr√©hension des √©cueils pour int√©grer des LLM dans vos developpements. Passons du clic √† la conversation !
--

* Les LLMs sont la 2e r√©volution dans l'interaction homme / machine
    ** La 1ere √©tant l'invention de la souris

.LLMs : ceux dispo via une API et ceux √† d√©ployer soi-m√™me
image:20240417_Devoxx-France_25.jpg[]

* Nouveau rappel : les LLMs sont *STATELESS* +
-> Ils ne se "rappellent" les pr√©c√©dentes interactions

.Interaction et conversation
[NOTE]
====
* 1 *interaction* = 1 paire de question / r√©ponse
* 1 *conversation* est un ensemble d'interactions
====

Probl√©matique : remplacer une IHM et toutes ces pop-up nest√©es par un LLM...

NOTE: les demo de Marie-Alice semble √™tre sur "venv" Python

* 1ere solution : *tout remplacer par 1 prompt*

    1. donner le contexte
    2. d√©finir le format de sortie +
    image:20240417_Devoxx-France_26.jpg[]
    image:20240417_Devoxx-France_27.jpg[]
    image:20240417_Devoxx-France_28.jpg[]

    3. donner des instructions pr√©cises
    4. prompt de d√©part

    ** Conclusion : 
        *** pas scalable
        *** confiance ?
        *** maintenance difficile

* 2e solution : *essayer une approche machine √† √©tat*

image:20240417_Devoxx-France_29.jpg[]
image:20240417_Devoxx-France_30.jpg[]

    ** les prompts des transitions vont avoir la partie m√©tier
    ** Et on a DE NOUVEAU un "bug" du LLM o√π le comportement d'aujourd'hui n'est pas celui d'hier, ce qui pose probl√®me

    ** Conclusion : 
        *** XXX
        *** consomme moins de ressources
        *** plus facile √† valider

* 3e solution : *utiliser des agents* (LangChain ici)

image:20240417_Devoxx-France_31.jpg[]

    ** *Gradio* utilis√© ici pour la demo. +
    -> Parfait pour faire de petites demo, MAIS √† ne PAS utiliser en prod...

.Comparaison de ces 3 solutions
image:20240417_Devoxx-France_32.jpg[]

* Dans tous les cas, il FAUT *√©valuer les prompts* !
    ** exemple d'outil : *prompt-foo*

* Autre probl√®me : *ce qui √©tait hier ne sera peut-√™tre plus aujourd'hui...* +
-> Un LLM n'est PAS un syst√®me d√©terministe
    ** Il ne faut pas essayer de le rendre compl√®tement d√©terministe (perte de cr√©ativit√©), mais il faut mettre en place des *process de v√©rification* +
    image:20240417_Devoxx-France_33.jpg[]
    ** Et si √ßa ne marche pas, il faut mettre en place des *strat√©gies de repli* +
    image:20240417_Devoxx-France_34.jpg[]
    ** Exemple de *retry* pour essayer de garantir un "bon" format JSON +
    image:20240417_Devoxx-France_35.jpg[]
    image:20240417_Devoxx-France_36.jpg[]

* Attention au *prompt injection*
    ** mettre un disclaimer car on PEUT se faire "hacker"

* Gestion du *co√ªt*
    ** utiliser un cache pour les questions fr√©quentes
    ** XXX

* Attention √† la confidentialit√© des donn√©es ! 
    ** OpenAI est aux US, voulez-vous, pouvez-vous envoyer les donn√©es de vos clients l√†-bas ?

Conclusion : 

    * de bonnes explications et astuces √† r√©cup√©rer !

.Ressources
image:20240417_Devoxx-France_37.jpg[]

    * Tout le code et les slides sont dispo sur https://github.com/malywut/clicks2conversations

=== 15:40 -> 16:25 - conference - Paris 242AB : Crafting your own RAG system: Leveraging 30+ LLMs for enhanced performance

Pr√©sent√© par Stephan Janssen, cr√©ateur de Devoxx (Belgique, l'original)

.abstract
--
In this talk you'll learn how to set up a RAG (Retrieval-Augmented Generation) system against 30+ different Large Language Models using Java.

We'll show you step-by-step how to ingest documents, choose the best text splitter strategies, find similar documents, answer questions, and create a chatbot.

Then, we'll see how to test and compare different AI models, both from open sources and private ones, and whether they are stored on your own computer or accessed online.
You'll walk away knowing how to setup a well balanced RAG system using Java and the best performing and/or cheapest LLM.
--

* How many talks did Brian Goetz give at Devoxx Belgium ? 
* How many presentation did Brian Goetz give at Devoxx Belgium ? 
    ** eh bien, notre LLM nous donne 2 r√©ponses diff√©rentes...

.Architecture d'un RAG par St√©phane Janssen
image:20240417_Devoxx-France_39.jpg[]

* ReRanker : NON semantic (IA) sort

* LLM providers locally running on your laptop : 
    ** Ollama
    ** LM Studio
    ** GPT4All
    ** Apple MLX

* LLM providers online :
    ** OpenAI
    ** Claude
    ** Groq

image:20240417_Devoxx-France_40.jpg[]

-> Tous sont support√©s par LangChain (√† v√©rifier !)

.St√©phane a d√©velopp√© sa propre BM25 (ReRanker) Java implementation, en 1 we en se faisant aider de ChatGPT et Claude
image:20240417_Devoxx-France_38.jpg[]

* et son impl√©mentation BM25 est gratuite...

.Import Data (Ingestion) : extract data from "content"
image:20240417_Devoxx-France_41.jpg[]

* *To Split or... Not to split* ?!
    ** des contects qui montent maintenant au 1M de tokens...
    ** from 0.10$ to 120$ for 1M tokens
    ** milliseconds to minutes (10 min pour 1M tokens)
    ** Be aware : "context injection" does reduce hallucinations

.Advanced Splitting Strategies
image:20240417_Devoxx-France_42.jpg[]

-> Regarder le talk de *Text Splitting* de *Greg Kamradt* : +
https://www.youtube.com/watch?v=8OJC21T2SL4

* Importance capitale de l'embedding
    ** et plusieurs mod√®les pour faire de l'embedding sont dispo

.Vector Databases
image:20240417_Devoxx-France_43.jpg[]
image:20240417_Devoxx-France_44.jpg[]

* Regarder le tr√®s bon talk sur le Vector DB de *Alexander Chatzizacharias* : +
https://www.youtube.com/watch?v=W-i8bcxkXok

* On ne peut pas utiliser PostgrePG pour de l'embedding avec OpenAI, car il ne supporte que 2000 dimensions quand OpenAI en utilise 3000 (A VERIFIER)

.St√©phane a √©galement d√©velopp√©, car manquant, LangChain4J-cohere (Langchain4J compliant Cohere embedding model)
image:20240417_Devoxx-France_45.jpg[]

    * https://github.com/stephanj/langchain4j-cohere
    * Gemini : "Cohere is a novel approach to representing text data that aims to capture both semantic and syntactic information in a more effective way compared to traditional embedding methods."

.Conclusion and lessons learned
image:20240417_Devoxx-France_46.jpg[]

* Embeddings models have an *input limit*
* the bigger the embedding dimensions the higher the hosting cost
* multi language embedding is a thing
* QUALITY of your embedding influences the QUALITY of your results

* St√©phane a √©crit le plugin "Devoxx Genie" pour IntelliJ

image:20240417_Devoxx-France_47.jpg[]
image:20240417_Devoxx-France_48.jpg[]

-> Et Claude 3 Opus donne apparemment des r√©sultats exceptionnels

image:20240417_Devoxx-France_49.jpg[]

* Ressources GitHub du talk : 
    ** https://github.com/stephanj/rag-genie
    ** https://github.com/devoxx/devoxxgenieIDEAplugin

Conclusion : 

    * Comme Jean-Emmanuel, St√©phane est vraiment impressionnant quand on voit tout ce qu'il arrive √† cr√©er en si peu de temps

=== 17:50 -> 18:20 - tools-in-action - Neuilly 153 : Creating a documentation site for users with AsciiDoc and Antora

Pr√©sent√© par Alexander Schwartz, Principal Software Engineer at Red Hat

.abstract
--
Documentation for a software project is essential for users, administrator and developers alike: Users need to find the right tutorials, reference documentation and answers to their questions, administrators need to know how to install and operator the software, while developers need other documents to get started contributing, and share concepts and architectures for fellow contributors.

The tool Antora simplifies the process by creating documentation websites from AsciiDoc sources stored in Git repositories. Users can browse the generated website and select the version matching the software they use. Navigation outlines, search and cross-references between pages allow users to find answers to their questions. Several open-source software projects like Camel, Debezium and Couchbase use this solution.
For developers it is normal to develop software in collaboration using their IDE and a version control system like Git. The same type of collaboration is possible when all documentation is versioned in a markup-format like AsciiDoc.

This talk presents the basics of an Antora setup and walks through all the steps from editing content in the IDE to updating the documentation site using continuous integration and delivery.
--

URL : https://docs.antora.org

.Sommaire du talk
image:20240417_Devoxx-France_53.jpg[]

1. How users search for informations

    * *Every page is "page one"* : +
    image:20240417_Devoxx-France_50.jpg[]

2. How AsciiDoc and Antora help

    ** Antora provides publishing tools and documentation structure +
    image:20240417_Devoxx-France_51.jpg[]

    ** AsciiDoc is the language, AsciiDoctor is a toolchain 
    image:20240417_Devoxx-France_52.jpg[]

3. Setting up Antora

.Antora structure
image:20240417_Devoxx-France_54.jpg[]

.Antora process
image:20240417_Devoxx-France_55.jpg[]

* Antora va permettre la g√©n√©ration d'un site statique (logique)

1. d√©finition des r√¥les for Antora
2. first steps de configuration d'Antora +
image:20240417_Devoxx-France_56.jpg[]

Conclusion : 

    * Le talk passe pas mal de temps √† pr√©senter AsciiDoc, et je n'arrive pas trop √† voir l'int√©r√™t d'Antora rapport √† AsciiDoc et AsciiDoctor seuls

== JOUR 2 : JEUDI 18/04

=== 09:00 -> 09:25 - Keynote - Amphi bleu : Programming's Greatest Mistakes

Pr√©sent√© par Mark Rendle

.Bio
--
Mark is the founder of RendleLabs, which provides consulting services and workshops to .NET development teams across all industries. His particular obsessions are API design and development, performance, Observability and code-base modernisation. He also uses skills acquired during a few years as a professional stand-up comic to deliver entertaining and informative talks at conferences around the world, and recently learned to play bass so he could join tech parody band The LineBreakers.
--

.abstract
--
Most of the time when we make mistakes in our code, a message gets displayed wrong or an invoice doesn't get sent. But sometimes when people make mistakes in code, things literally explode, or bankrupt companies, or make web development a living hell for millions of programmers for years to come.
 
Join Mark on a tour through some of the worst mistakes in the history of programming. Learn what went wrong, why it went wrong, how much it cost, and how things can be pretty funny when they're not happening to you.
--

* Dans les ann√©es 1950, la m√©moire co√ªtait 1$ pour 1 bit (et pas un byte, bien 1 bit)
    ** dans 1 kilobytes co√ªtait plus de 8 000$...
    ** la m√©moire √©tait "tricot√©e" √† la main par des femmes sur des plaquettes comme la suivante : +
    image:20240418_Devoxx-France_01.jpg[]

=== 09:35 -> 10:00 - Keynote - Amphi bleu : Un monde shoot√© aux m√©taux

Pr√©sent√© par Guillaume Pitron et Agnes Crepet

.Bio
--
* *Guillaume* : √âminent journaliste, auteur et r√©alisateur fran√ßais bas√© √† Paris, Guillaume Pitron est reconnu pour ses essais perspicaces sur les impacts cach√©s des transitions √©nerg√©tique et num√©rique.

* *Agnes* : Agn√®s Crepet est responsable de la long√©vit√© logicielle et de l'informatique chez Fairphone, une entreprise sociale cr√©ant un smartphone √©thique, modulaire et r√©parable.
--

.abstract
--
Dans cette conf√©rence intitul√©e "Un monde shoot√© aux m√©taux", Guillaume Pitron, expert des enjeux g√©opolitiques li√©s aux ressources naturelles, et Agnes Crepet, sp√©cialiste en technologies √©co-responsables, s'unissent pour aborder la d√©pendance croissante de nos soci√©t√©s aux m√©taux rares et ses implications profondes. Ils exploreront comment cette consommation excessive impacte l'environnement, l'√©conomie mondiale et les relations sociales, en d√©voilant les cha√Ænes d'approvisionnement complexes qui relient les mines isol√©es aux technologies quotidiennes. La discussion soulignera les cons√©quences environnementales de l'extraction des m√©taux, les d√©fis √©thiques et les tensions g√©opolitiques qu'elle engendre.
--

* Smartphone : ratio de 1200 / 1 -> si mon t√©l√©phone p√®se 200g, il a fallu 240kg de mati√®res premi√®res pour le fabriquer

* Les m√©taux derri√®re un iPhone, juste les m√©taux, co√ªtent 2‚Ç¨... Juste 2‚Ç¨...
    ** On doit certainement pouvoir faire quelque chose pour mieux exploiter les mines qui sont derri√®re : respect des mineurs, am√©lioration du contexte g√©opolitique (corruption, contrebande, etc.)

* Dur√©e de vie d'un mobile sur la stack Android : 2 √† 3 ans
    ** Ce serait bien si on passait √† 7 √† 8 ans

=== 10:30 -> 11:15 - conference - Paris 143 : Comment Back Market a reconditionn√© sa plateforme en changeant de Cloud Provider

* C'est vrai : BackMarket est bien pass√© de AWS √† GCP
    ** la derni√®re partie de la migration s'√©tant termin√©e hier !

.BackMarket en quelques chiffres
image:20240418_Devoxx-France_02.jpg[]

* infog√©r√©, dans le Cloud, plus de 40 000 containers

*2014 √† 2018*

    * de 5 √† 100 employ√©s en 4 ans
    * infog√©rance totale, qui se passe bien au d√©but, mais au fur et √† mesure de cette croissance rapide, l'infog√©reur n'arrive plus √† suivre +
    -> BackMarket d√©cide donc d'internaliser toute sa plateforme

.Les limites de l'infog√©rance initiale de la plateforme
image:20240418_Devoxx-France_03.jpg[]

* A l'√©poque la bo√Æte va bien, fait de la croissance, mais les OPS s'inqui√®tent...

.La plateforme infog√©r√©e
image:20240418_Devoxx-France_04.jpg[]

    * 2 monolithes, l'un en Django

.La cible sur le Cloud (AWS √† l'√©poque)
image:20240418_Devoxx-France_05.jpg[]

* Strat√©gie : 
    ** internaliser la plateforme (toujours sur AWS, comme l'infog√©reur)
    ** d√©porter sur les edges : CDN + Sec
    ** passage de VMs √† Containers & Kubernetes (K8s)
    ** PAS de make, surtout du *buy*

*Et pourquoi pas GCP alors ???*

* Non, car il faut que la dur√©e de l'internalisation soit de 1 mois MAX
* On veut rester Cloud agnostique

* GCP Engineer : "Vous n'allez pas pouvoir migrer chez nous sans efforts substantiels au niveau de la base de donn√©es"
    ** BackMarket √©tait sur Aurora, dont on devient vite accro √† la latence basse (√† v√©rifier), MAIS qui devient vite gal√®re du c√¥t√© de l'eventual consistency +
    -> A VERIFIER

.Tips pour une migration de ce type
image:20240418_Devoxx-France_06.jpg[]

*De 2018 √† 2023 :*

.Poursuite de la croissance
image:20240418_Devoxx-France_07.jpg[]

.Le c√¥t√© Cloud Agnostic commence √† co√ªter cher, trop cher
image:20240418_Devoxx-France_08.jpg[]

* des K8s clusters self managed -> beaucoup d'op√©rations
* co√ªts de maintenance √©lev√©s
* plateforme d'analytics sur BigQuery, alors que le reste de la plateforme √©tait sur AWS, et on voyait bien que les *co√ªts d'Egress*, acceptables au d√©but allaient devenir un probl√®me

.Architecture en 2023
image:20240418_Devoxx-France_09.jpg[]

    * r√©pliqu√©e sur 3 r√©gions, avec √† chaque fois Prod et NON Prod

*2023* (et l'id√©e de passer chez GCP)

* *Comment changer de trajectoire architecturale et strat√©gique tout en modernisant sa plateforme ?*

* L√† maintenant, on arr√™te d'√™tre Cloud agnostique, et on va adh√©rer au catalogue du Cloud provider
    ** On sait que cela va √™tre davantage un "locked in" chez le Cloud provider choisi

.La strat√©gie et les questions √† se poser pour un changement de Cloud Provider
image:20240418_Devoxx-France_10.jpg[]

    * Strat√©gie : "se d√©cider, convaincre et aligner"

.Une strat√©gie pour la technique ET pour le business (pour v√©rifier la viabilit√© du projet)
image:20240418_Devoxx-France_11.jpg[]

* *Qualification des √©quipes* : on √©tait comp√©tent en AWS, mais pas en GCP
    ** BackMarket a consid√©r√© que ce n'√©tait pas un probl√®me, les concepts du Cloud √©tant consid√©r√© comme similaires
    ** MAIS il est important de ne PAS chercher √† utiliser exactement les m√™mes services d'un Cloud √† l'autre : il faut tenir compte au mieux des sp√©cificit√©s du Cloud Provider et ne pas chercher un matching "1 pour 1"

* Le POC a √©t√© une √©tape cruciale : 
    ** on aurait pas chang√© de Cloud provider sans lui
    ** on aurait pas chang√© sans r√©sultat concluant

.D√©tails du POC
image:20240418_Devoxx-France_12.jpg[]

* Objectif : une PrePROD live sur GCP en *10 jours*
    ** cela semble tellement court vue leur infra !
* Les √©quipes Google ont √©t√© directement sollicit√©es pour ce POC

.Comparaison entre les Cloud Providers AWS et GCP
image:20240418_Devoxx-France_13.jpg[]

* *Engagement durable et √©cologique* : AWS not√© "F" jusqu'en 2020 o√π ils ont arr√™t√© de remplir le questionnaire... Pass√© "B" en 2023
* *Co√ªts* : plus de docs et d'efforts de transparence c√¥t√© Google

.Au final, 8 mois pour la dur√©e totale de la migration
image:20240418_Devoxx-France_14.jpg[]

.La nouvelle plateforme sur GCP (et GCP GKE)
image:20240418_Devoxx-France_15.jpg[]

* plus de MySQL pour le monolithe, passage √† Postgre

.Les conclusions de cette migration
image:20240418_Devoxx-France_16.jpg[]

* Buy buy buy, et make LATER
* Faites un vrai POC, PAS une simple "tech discovery"
* en POC, *TRACEZ* les difficult√©s et d√©cisions, car vous y ferez face plus tard

.C√¥t√© Leadership
image:20240418_Devoxx-France_17.jpg[]

* *Cr√©er une culture du risque !*
* Mettre en place une TPM (Total Productive Maintenance)

*Conclusion* : un REX tr√®s concret, avec beaucoup de bons conseils √† revoir en cas de projet de migration de Cloud Provider üëç

*Q&A*

* *Pourquoi pas Azure ?*
    ** Strat√©gie de "bundleling" de Microsoft
    ** certains outils ne convenaient pas (ne semblaient pas convenir)
    ** utilisateurs de BigQuery depuis 2009, passer sur Azure signifiait conserver les probl√®mes d'Egress ?

* *Pourquoi pas une approche hybride AWS / GCP ?*
    ** De nouveau, pas r√©aliste pour les *co√ªts d'Egress*

* La migration de la partie DB a √©t√© le plus difficile
    
=== 11:35 -> 12:20 - conference - Paris 141 : La recherche √† l'√®re de l'IA

.abstract
--
La recherche ne se contente plus de l'approche maintenant traditionnelle bas√©e sur la fr√©quence des termes (TF/IDF ou BM25) mais plus sur la tendance actuelle du machine learning o√π les nouveaux mod√®les ont ouvert une nouvelle dimension pour la recherche.
Cette conf√©rence donne un aper√ßu de :

    * La recherche "Classique" et ses limitations
    * Qu'est qu'un mod√®le de machine learning et comment vous pouvez l'utiliser
    * Comment utiliser la recherche vectorielle ou la recherche hybride dans Elasticsearch
    * Comment ChatGPT d'OpenAI ou les "large language models" (LLMs) similaires viennent jouer naturellement avec Elastic

Cette session couvre l'√©tat de l'art en mati√®re de recherche de nos jours : BM25, recherche vectorielle, embeddings, recherche hybride, Reciprocal Rank Fusion, int√©gration avec OpenAI... +
La d√©mo principale montre comment g√©n√©rer des embeddings √† partir de musiques puis comment trouver la musique qui s'approche le plus d'une musique que nous fredonnons.
--

.Agenda
image:20240418_Devoxx-France_18.jpg[]

* *Elasticsearch* permet AUSSI de faire de la *recherche vectorielle*

.Qu'est-ce qu'un vecteur ?
image:20240418_Devoxx-France_19.jpg[]
image:20240418_Devoxx-France_20.jpg[]

* L√† on n'a que 2 dimensions, mais on pourrait en avoir plus

.Choice of Embedding Model
image:20240418_Devoxx-France_21.jpg[]

image:20240418_Devoxx-France_22.jpg[]

.Tous les mod√®les support√©s par Elastic
image:20240418_Devoxx-France_23.jpg[]

.Maintenant, comment faire la recherche (Vector Query) ?
image:20240418_Devoxx-France_24.jpg[]

.3 √©tapes pour faire une recherche vectorielle :
image:20240418_Devoxx-France_25.jpg[]

    * search
    * index
    * generate

* Les moyens de trouver les bons vecteurs : 

    ** similarit√© cosinus +
    image:20240418_Devoxx-France_26.jpg[]
    image:20240418_Devoxx-France_27.jpg[]

    ** longueur du vecteur : dot_product +
    image:20240418_Devoxx-France_28.jpg[]

    ** distance euclidienne
    image:20240418_Devoxx-France_29.jpg[]

    ** une approche un peu diff√©rente : HNSW
    image:20240418_Devoxx-France_30.jpg[]

.Filtering KNN Vector Similarity
image:20240418_Devoxx-France_31.jpg[]

* -> Elastic supporte maintenant 4096 dimensions
    ** MAIS cela consomme beaucoup de ressources !

.Les bonnes pratiques de recherche vectorielle
image:20240418_Devoxx-France_32.jpg[]

.Recherche hybride
image:20240418_Devoxx-France_33.jpg[]

.ELSER
image:20240418_Devoxx-France_34.jpg[]
image:20240418_Devoxx-France_35.jpg[]

*Ranking* : RRF (Reciprocal Rank Fusion)

image:20240418_Devoxx-France_36.jpg[]

DEMO

* sur le th√®me de la musique, David adore mixer üòâ

.Architecture de la demo
image:20240418_Devoxx-France_37.jpg[]

* repo GitHub : https://github.com/dadoonet/music-search

.ET ChatGPT et la gen AI sont arriv√©s...
image:20240418_Devoxx-France_38.jpg[]

.ChatGPT et les LLM -> "une" r√©ponse
image:20240418_Devoxx-France_39.jpg[]

.RAG -> "la bonne r√©ponse" (car on va la chercher dans les "bonnes" donn√©es)
image:20240418_Devoxx-France_40.jpg[]

.En conclusion, de quoi avons-nous besoin pour faire de la recherche s√©mantique ?
image:20240418_Devoxx-France_41.jpg[]

-> *Elasticsearch* permet AUSSI de faire de la *recherche s√©mantique*

Ressources : 

    * slides de la pr√©sentation : https://speaker.pilato.fr/WlpZdt

Conclusion : 

    * Super talk, dense avec comme d'habitude un David tr√®s fluide et qui ma√Ætrise le sujet üëç
    * A revoir "calmement" car cela allait vite üòÖ

=== ------------------------ 12:20 -> 13:30 : LUNCH ------------------------

=== 12:35 -> 12:50 - quicky - Paris 242AB : Je d√©l√®gue tous mes tests √† une IA

Pr√©sent√© par Valentin Dumas, craftsman chez Takima.

.abstract
--
Le craftsmanship et nos pratiques de d√©veloppement moderne pl√©biscitent de tester efficacement nos applications. Et heureusement !

Pour autant, le test est rarement ce qu'on pr√©f√®re r√©aliser au quotidien, et cela prend une partie non n√©gligeable de notre temps. +
D'ailleurs, on se dit m√™me que le test, ce n'est pas vraiment la partie avec le meilleur ROI de l'utilisation de nos neurones. +
Alors pourquoi pas faire faire nos tests √† une IA ?

Dans cette conf, je vous pr√©senterai Codium AI √† travers des exemples concrets, et de son utilisation √† la fois pour du Unit Testing que pour des tests plus complexes (e2e). +
On prendra ensemble le temps de regarder ce qui marche bien, et aussi ses limites !
Une chose est sure : vous n'√™tes pas pr√™ts !
--

* Les tests, c'est long... (25% du temps de Romain par jour) +
Comment on pourrait am√©liorer √ßa gr√¢ce √† l'IA ?

* Il sera ici question de tests unitaires et de tests d'int√©gration
    ** avec *CodiumAI*

.Comment marche CodiumAI ?
image:20240418_Devoxx-France_42.jpg[]

* Plugin de CodiumAI ("Codiumate") disponible pour IntelliJ et VSCode

.Interface de Codiumate pour IntelliJ
image:20240418_Devoxx-France_43.jpg[]
image:20240418_Devoxx-France_45.jpg[]

* On peut par exemple demander via le prompt √† Codiumate d'utiliser la librairie AssertJ

.On demande maintenant √† Codiumate de g√©n√©rer cette fois des tests d'int√©gration
image:20240418_Devoxx-France_44.jpg[]

* Codiumate respecte les conventions Java
* En version payante, Codiumate permet d'*it√©rer sur la couverture de code* afin de *g√©n√©rer les tests manquants*

.G√©n√©ration de tests d'int√©gration sur un contr√¥leur
image:20240418_Devoxx-France_46.jpg[]

*Conclusion* : 
    
    * on peut gagner 15 √† 20% de temps de d√©veloppement
    * version VSCode plus avanc√©e
    * "l'Archi c'est pour moi, et le boilerplate, c'est pour l'IA"

.Avantages
image:20240418_Devoxx-France_47.jpg[]

.Limites
image:20240418_Devoxx-France_48.jpg[]

.Use cases
image:20240418_Devoxx-France_49.jpg[]


=== 13:00 -> 13:15 - quicky - Maillot : C4 model, la solution pour standardiser mes sch√©mas d'architecture ?

Pr√©sent√© par J√©r√¥me Gauthier de Sopra Steria

.abstract
--
L'acc√©l√©ration des rythmes d'innovation et de transformation, coupl√©e la diversification des types d'architecture logicielle, entrainent de plus en plus l'abandon des mod√©lisations historiques type UML ou ArchiMate, √† la fois riches mais aussi complexes √† maitriser et maintenir.

Mais comment garder une forme de standardisation dans les repr√©sentations d'architecture, tout en permettant un niveau fin de personnalisation, une bonne collaboration, et une maintenance simple et accessible orient√©e diagram-as-code ?

Durant cette session je vous propose de partir √† la d√©couverte du C4 Model, en explorant ses concepts et ses limites via un cas pratique avec l'outil Structurizr.
--

.C4 model : 4 niveaux d'abstractions
image:20240418_Devoxx-France_50.jpg[]
image:20240418_Devoxx-France_51.jpg[]

    1. context
    2. containers : PAS celui de Docker, bien entendu
    3. components
    4. code

* La sp√©cificit√© du C4 model est le niveau / concept de "zoom" qu'il propose

* On peut faire du C4 model avec un simple papier / crayon
* En diagramme as Code, Structurizr est un bon outil
    ** m√™me cr√©ateur que le C4 model
    ** une extension existe pour VSCode

.Structurizr
image:20240418_Devoxx-France_52.jpg[]
image:20240418_Devoxx-France_53.jpg[]

*Demo*

image:20240418_Devoxx-France_54.jpg[]

* Il existe un image Docker officielle pour g√©n√©rer les diagrammes Structurizr

Conclusion

.Comparaison C4 model √† la main et via Structurizr
image:20240418_Devoxx-France_55.jpg[]

.Plus adapt√© pour du multi-containers que du monolithe
image:20240418_Devoxx-France_56.jpg[]

.Ressources du talk
image:20240418_Devoxx-France_57.jpg[]

* slides de la pr√©sentation : https://github.com/jerga/c4model

=== 13:30 -> 16:30 - Deep Dive - Neuilly 251 : Construire son assistant Intelligent avec Hugging Face et Elasticsearch

Pr√©sent√© par Lucian Precup, Pietro Mele de Adelean

.abstract
--
Nous explorerons comment utiliser Elasticsearch et Hugging Face pour cr√©er un assistant intelligent personnalis√©. 

Nous utiliserons les mod√®les pour le traitement du langage naturel (NLP), les mod√®les open source de langage de grande taille (LLMs) et l'indexation et la recherche vectorielle. 

Elasticsearch, moteur de recherche avanc√© et base de donn√©es NoSQL, permet d'indexer et d'analyser des donn√©es de mani√®re efficace, tandis que Hugging Face offre une plateforme collaborative pour le d√©veloppement et le d√©ploiement de mod√®les de machine learning open source. 

Cette session approfondira la mani√®re d'int√©grer ces deux technologies pour construire des assistants intelligents sur mesure. +
Les participants auront l'occasion d'apprendre √† travers des exemples concrets et des prototypes, de comprendre les subtilit√©s des mod√®les de langage naturel disponibles sur Hugging Face, de revisiter les fonctionnalit√©s d'Elasticsearch et de d√©couvrir comment ces outils peuvent √™tre combin√©s pour cr√©er des versions personnalis√©es d'assistants intelligents comme ChatGPT.
--

.Feuille de route du talk
image:20240418_Devoxx-France_58.jpg[]

.Qu'est-ce qu'un assistant intelligent ?
image:20240418_Devoxx-France_59.jpg[]

.Les capacit√©s d'un assistant intelligent
image:20240418_Devoxx-France_60.jpg[]

* L'assistant doit √™tre capable de comprendre l'utilisateur, et donc le langage humain (NLU Natural Language Understanding, NLP)

.Une d√©fintion du traitement du langage naturel
image:20240418_Devoxx-France_61.jpg[]

    * Traitement Automatique du Langage Naturel : branche de l'IA qui se concentre sur l'interaction entre les ordinateurs et les humains √† travers le langage naturel.
    * capacit√© des ordinateurs √† comprendre, interpr√©ter et g√©n√©rer le langage humain

.L'histoire du traitement du langage naturel
image:20240418_Devoxx-France_62.jpg[]

* introduction de BERT en 2018

.Liste des LLMs, en jaune ceux qui sont "publicly available"
image:20240418_Devoxx-France_63.jpg[]

* Attention ! "Publicy available" ne veut pas forc√©ment dire open

.Ce que font les moteurs de recherche
image:20240418_Devoxx-France_64.jpg[]

.NLP et search : une longue histoire
image:20240418_Devoxx-France_65.jpg[]

* Les moteurs de recherche int√®gre nativement des m√©thodes de NLP : 
    ** analyzers : 
        *** tokenizer
        *** stemmers
        *** synonyms
    ** inverted index
    ** NLP avec ML

* Puis la "r√©volution" de la recherche avec les *ChatGPT like* int√©gr√©s *dans les navigateurs* (comme un LLM dans Bing)
    ** avec du "*Question answering*" proposant au d√©but 1 r√©sultat (le bouton "j'ai de la chance" de Google)
    ** puis permettant de *croiser les r√©sutats*
    ** et qui maintenant peut m√™me *citer ses sources*

.Une vid√©o conseill√©e par Lucian concernant la fonctionnalit√© de pouvoir citer ses sources pour un LLM, remontant √† "avant" que le terme RAG n'apparaisse
image:20240418_Devoxx-France_66.jpg[]

* Les grandes fonctionnalit√©s d'un LLM : 
    ** r√©sum√© de texte
    ** reformulation de texte / correction orthographique / traduction
    ** compr√©hension de texte
    ** g√©n√©ration de code

* Sam Altman se sert principalement de ChatGPT pour ses capacit√©s de *synth√®se*

* On peut dire que le *question answering* est un peu l'*anc√™tre du RAG*

*Traitement de la voix*

.Process du traitement de la voix
image:20240418_Devoxx-France_67.jpg[]

*T√¢ches NLP avec un moteur de recherche*

image:20240418_Devoxx-France_68.jpg[]

    * *Analyse de sentiment*
    * *Named Entity Recognition (NER)* : √™tre capable de reconna√Ætre que l'on parle d'une "entit√©" (personne) dans un texte
    * *Zero-shot classification* : √™tre capable de classifier sans √™tre sp√©cialement entra√Æner pour cela. Il classe des classes / √©tiquettes pr√©c√©demment inconnues.

image:20240418_Devoxx-France_69.jpg[]

*Embeddings ou vecteur s√©mantique dense*

.Exemple de vectorisation dans un vecteur √† 3 dimensions tridimensionnel
image:20240418_Devoxx-France_70.jpg[]
image:20240418_Devoxx-France_71.jpg[]
image:20240418_Devoxx-France_72.jpg[]

.Text embedding et vector search
image:20240418_Devoxx-France_73.jpg[]

.Quelques techniques pour faire cela : KNN (K-Nearest Neighbors) vs ANN (Approximate Nearest Neighbors)
image:20240418_Devoxx-France_74.jpg[]

* Gemini : KNN et ANN sont deux algorithmes populaires utilis√©s dans la recherche vectorielle pour trouver les points les plus proches d'un point de requ√™te dans un espace vectoriel de grande dimension.

* Les vecteurs creux sont plus simples / faciles √† int√©grer dans un index invers√©

* Gemini au sujet des vecteurs creux et denses : 

    ** Les *vecteurs creux* sont des vecteurs de grande dimension o√π la plupart des √©l√©ments sont √©gaux √† z√©ro.
        *** Ils sont donc compacts et √©conomes en m√©moire
        *** Cas d'usage : 
            **** Repr√©sentation de documents textuels dans des mod√®les de *sac de mots* (BoW) ou TF-IDF (Term Frequency-Inverse Document Frequency).
            **** *Indexation invers√©e* pour la recherche rapide de documents pertinents. +
            L'index invers√© utilise des vecteurs creux pour mapper les mots aux documents dans lesquels ils apparaissent.

.Exemple de vecteur creux pour repr√©senter des documents dans un mod√®le de sac de mots (BoW)
--
Soit un vocabulaire de 10 000 mots et un document contenant les mots "chien", "chat", "courir", "jouer".

    * Le vecteur creux pour ce document aura 10 000 dimensions.
    * Les dimensions correspondant aux mots "chien", "chat", "courir" et "jouer" auront des valeurs non nulles √©gales √† la fr√©quence respective de ces mots dans le document.
    * Les 9 996 autres dimensions restantes seront nulles.
--

    ** Les *vecteurs denses* sont des vecteurs de grande dimension o√π tous les √©l√©ments ont une valeur non nulle.
        *** Ils sont souvent utilis√©s dans des mod√®les d'apprentissage automatique o√π toutes les dimensions du vecteur sont importantes.

.Aper√ßu Hugging Face
image:20240418_Devoxx-France_75.jpg[]

* Hugging Face : le "GitHub" de l'IA
    ** mais en plus ils sont des machines, des GPU, ce qui permet de *tester les mod√®les en live*

* Hugging face : de nombreux cours de dispo
    ** Voir cr√©er un assistant vocal : chapter7/voice-assistant

image:20240418_Devoxx-France_76.jpg[]

* On r√©veille l'assistant avec un mot trigger, un wake word ("ok Google")

* Podium des LLM sur hugging face : open_llm_leaderboard
    ** Class√©s suivant plusieurs crit√®res (√† creuser)

*Elasticsearch*

* Certains mod√®les (en provenance de hugging face par exemple) sont d√©ployables directement dans le cluster elastic, d'autres sont non compatibles +
image:20240418_Devoxx-France_77.jpg[]
image:20240418_Devoxx-France_78.jpg[]

* *Eland* est l'outil permettant d'envoyer un mod√®le depuis Hugging Face vers Elastic
image:20240418_Devoxx-France_79.jpg[]

* Conseil et bonne pratique avec elastic : Avoir un 1er index "simple" o√π charger rapidement les data, et pr√©voir un 2nd index utilisant du ML / des calculs plus lourds

* Mod√®le *elser* vient par d√©faut avec elasticsearch depuis la version 8.3.11 (√† v√©rifier)

.Ressources conseill√©es sur le sujet
image:20240418_Devoxx-France_80.jpg[]

IMPORTANT: Une recommandation que Lucian r√©p√™te √† toutes ses conf : il ne faut *PAS* utiliser un LLM pour remplacer un moteur de recherche.

== JOUR 3 : VENDREDI 19/04

=== 09:00 -> 09:25 - Keynote - Amphi bleu : Comment mod√©liser l'√©tat du monde en 2100 ? Le Rapport Meadows

Pr√©sent√© par Anatole Chouard

.bio
--
Je m'appelle Anatole, j'ai 27 ans et je suis vulgarisateur scientifique ! Pour √ßa j'ai 2 casquettes : je suis √† la fois conf√©rencier et sur YouTube. Apr√®s des √©tudes en classe pr√©paratoire PC (Physique-Chimie), j'ai √©tudi√© les math√©matiques appliqu√©es √† l'√âcole Polytechnique, puis la mod√©lisation math√©matique √† la University College de Londres. J'applique maintenant ces enseignements dans ma vulgarisation des sciences !
--

.abstract
--
Comment mod√©liser l'√©tat du monde en 2100 ? Pas la question la plus simple ! Mais en 1972 un groupe de chercheurs du MIT a essay√© de r√©pondre √† cette question : c'est le fameux et fascinant rapport Meadows. Et ils ont compris bien des choses avant tout le monde. Dans cette conf√©rence interactive, je vous fais un r√©sum√© en 20 minutes de la m√©thode et surtout des r√©sultats du rapport Meadows !
--

Dynamique des syst√®mes

    1. identifier les syst√®mes majeurs
    2. identifier leurs interactions
    3. quantifier leurs interactions

image:20240419_Devoxx-France_01.jpg[]
image:20240419_Devoxx-France_05.jpg[]

.identifier les syst√®mes majeurs : 5 syst√®mes
image:20240419_Devoxx-France_02.jpg[]

    * √† l'√©poque, on avait pas encore d√©terminer l'impact de l'homme sur la pollution, il est donc surtout question de pollution des sols.

.identifier leurs interactions
image:20240419_Devoxx-France_03.jpg[]
image:20240419_Devoxx-France_04.jpg[]

.Les r√©sultats du rapport
image:20240419_Devoxx-France_06.jpg[]

* -> Aie aie aie en 2100 ! Plus de ressources ?!!!

Hypoth√®ses : mieux utiliser les ressources ? +
Les r√©sultats sont PIRES encore... (et c'est SANS compter le r√©chauffement climatique)

image:20240419_Devoxx-France_07.jpg[]

* Et si on agit d√®s 1970 ???

image:20240419_Devoxx-France_08.jpg[]

* Et si on agit d√®s 2000 ??? Avec les m√™mes changements qu'en 1970

image:20240419_Devoxx-France_09.jpg[]

.La conclusion du rapport
image:20240419_Devoxx-France_10.jpg[]

Les critiques du rapport : 

.Matthew Simmons 1ere critique
image:20240419_Devoxx-France_11.jpg[]

.Matthew Simmons 30 ans apr√®s : on s'est tromp√©, on a juste gaspill√© 30 ans...
image:20240419_Devoxx-France_12.jpg[]

* Nouveau rapport plus r√©cemment : *"Earth4All"*

image:20240419_Devoxx-France_13.jpg[]

* *Meadows* : nous sommes d√©pass√©s par...
* *Earth4All* : Nous esp√©rons que ce livre sera un guide de survie pour le 21e si√®cle
    ** l√† o√π Meadows donne 12 sc√©narios, Earth4All n'en donne que 2 : le paradis ou l'enfer

-> Anatole : Earth4All cherche plus le "buzz", c'est peut-√™tre dans l'air du temps, mais il cherche aussi peut-√™tre √† alerter en faisant cela. +
Le rapport Meadows reste le plus pr√©cis. 

Voir :  

    * Cha√Æne YouTube : chez Anatole
    * chezanatole.contact@gmail.com

=== 09:35 -> 10:00 - Keynote - Amphi bleu : Cybers√©curit√© et cyberd√©fense : un sujet g√©opolitique

Pr√©sent√© par Guillaume Poupard, Docaposte, Directeur G√©n√©ral Adjoint en charge notamment des domaines data/IA, cyber et cloud. Ancien Directeur G√©n√©ral de l'ANSSI.

.bio
--
Polytechnicien (X92) et docteur en cryptographie, Guillaume Poupard d√©bute sa carri√®re en tant que chef du laboratoire de cryptologie de la Direction Centrale de la S√©curit√© des Syst√®mes d'Information (DCSSI) qui deviendra, en 2009, l'Agence Nationale de la S√©curit√© des Syst√®mes d'Information (ANSSI).
En 2005, il rejoint le minist√®re de la D√©fense o√π il se sp√©cialisera dans la cyberd√©fense, avant d'int√©grer en 2010 la Direction G√©n√©rale de l'Armement (DGA) en tant que responsable des p√¥les s√©curit√© des syst√®mes d'information et cyberd√©fense. En 2014, il est appel√© √† prendre la direction g√©n√©rale de l'ANSSI, fonction qu'il occupera jusqu'√† fin de l'ann√©e 2022.
En janvier 2023, il rejoint Docaposte en tant que Directeur G√©n√©ral Adjoint en charge notamment des domaines data/IA, cyber et cloud.
--

.abstract
--
La cybers√©curit√© est souvent vue, √† juste titre, sous un angle technique, op√©rationnel et r√©glementaire. 
L'incroyable √©volution de la menace informatique nous concerne tous, √† titre individuel, au niveau des organisations mais √©galement √† l'√©chelle des Etats. Dans un contexte g√©n√©ral de fortes tensions g√©opolitiques, le cyber est devenu un ingr√©dient majeur dont l'usage se syst√©matise dans des conflits qualifi√©s ¬´ d'hybrides ¬ª. 
Passionnante et effrayante, cette militarisation de l'espace num√©rique nous concerne toutes et tous !
--

image:20240419_Devoxx-France_14.jpg[]

* Livre blanc "de la cybers√©curit√© de 2008"
    ** Plus grande crainte de l'√©poque : que des syst√®mes soient emp√™ch√©s de fonctionner du fait d'attaques informatiques

* 12 secteurs en France "d'int√©r√™t / d'importance vitale / strat√©gique"

=== 10:30 -> 11:15 - Conf√©rence - Neuilly 252AB : L'IA et qualit√© de code : Construire une synergie avec l'intelligence humaine

Pr√©sent√© par Arthur Magne de Packmind

.Bio
--
D√©veloppeur convaincu de l'importance du partage de connaissances et de bonnes pratiques dans les √©quipes, j'ai co-fond√© Packmind avec deux associ√©s.
Nous d√©veloppons des plugins pour les IDE et les outils de code review qui aident les √©quipes de d√©veloppement √† capitaliser sur l'expertise de tous les membres des √©quipes. J'accompagne des entreprises √† mettre en place des nouveaux formats d'√©changes techniques pour partager ces connaissances rapidement.
L'objectif est de mettre en place et d'animer des communaut√©s de pratiques transverses qui permettrons d'aider au maximum des d√©veloppeurs et d√©veloppeuses √† progresser techniquement sur diff√©rents sujets (architecture, performance, s√©curit√©, clean code, test, DDD, React, etc.).
--

.abstract
--
La qualit√© du code g√©n√©r√© par l'IA est directement influenc√©e par la qualit√© des donn√©es et des standards de d√©veloppement qu'elle re√ßoit.
Dans un contexte o√π l'IA est un copilote de l'√©quipe de d√©veloppement, le code qui est g√©n√©r√© va forc√©ment √™tre lu et maintenu par l'√©quipe elle m√™me. Pour ne pas g√¢cher le temps gagn√© gr√¢ce √† l'IA dans des activit√©s de maintenance laborieuses, ce code doit alors correspondre aux pratiques de d√©veloppement d√©j√† mises en place par l'√©quipe (contraintes de s√©curit√©, design patterns, accessibilit√©, choix techniques, etc.).
Mais pour que l'IA g√©n√®re du code qui ne s'√©loigne pas des pratiques de l'√©quipe, ces pratiques doit d'abord √™tre explicit√©es et partag√©es avec elle.
Nous verrons comment l'√©quipe peut d√©finir ces pratiques et comment l'IA peut aider √† les extraire de la base de code r√©cent. Une fois ces standards de d√©veloppement d√©finis, l'IA peut maintenant nous aider √† les d√©tecter, √† former l'ensemble de l'√©quipe dessus et va g√©n√©rer du code qui correspond √† ce qui a √©t√© valid√© par cette expertise humaine.
Avec quelques exemples concrets nous verrons comment l'IA peut devenir un r√©el copilote de l'√©quipe, qui contribue r√©ellement √† faire progresser le projet et permet d'am√©liorer en continu les pratiques de l'√©quipe.
--

* Il faut voir l'IA comme un mercenaire qui intervient sur votre projet sans en conna√Ætre le contexte
    ** Ce m√™me contexte que l'on met des mois √† communiquer √† un nouveau d√©veloppeur lors de son onboarding

* Pas de question de "junior" ou "senior" : il faut toujours rester critique du code g√©n√©r√© par l'IA

* IA Gen : baisse du code ownership -> ce n'est plus, ou moins, "notre" code

.Etude de Visual Studio Magazine (et non GitClear üòâ) mettant en avant le code churn qui a fortement augment√© avec l'IA Gen
image:20240419_Devoxx-France_15.jpg[]

* L'√©tude en question : https://visualstudiomagazine.com/Articles/2024/01/25/copilot-research.aspx

* -> La question de 2024 : qui va s'occuper de la maintenance de ce code g√©n√©r√© par l'IA ?

.Globalement, le retour sur l'IA gen est bon, on va devoir y passer
image:20240419_Devoxx-France_16.jpg[]

* Contrairement aux chiffres des derni√®res √©tudes, on ne va faire des gains de productivit√© de 50 ou 80%, on est plus sur du 10 √† 20%
    ** En travaillant derni√®rement avec plusieurs grandes entreprises, Arthur a eu confirmation d'un chiffre de l'ordre de ~10% de gain de productivit√©
        *** Nous sommes donc en phase avec nos propres chiffres c√¥t√© Docaposte üòâ

* Par contre, il y a d'autres effets, positifs, pour l'individu / le d√©veloppeur
* MAIS, quand on raisonne maintenant sur l'√©quipe, ces nouvelles pratiques back√©es par l'IA gen donnent lieu √† certains probl√®mes nouveaux

image:20240419_Devoxx-France_17.jpg[]

* Attention √† l'analyse d'une base documentaire par l'IA gen via un RAG ! +
-> La doc qui n'est PLUS √† jour va √©galement √™tre prise en compte
    ** il ne faut pas que l'IA nous propose une information / un process obsol√®te depuis 3 ans...

* Donc, pour pallier ce probl√®me : 
    ** *Capture des pratiques* : "√ßa c'est une bonne mani√®re de faire", la pr√©co donn√©e, "captur√©e" au sein de l'√©quipe
    ** AVEC la *validation des pratiques* : "Oui, mais est-ce que c'est bien la bonne mani√®re de faire ?"

-> La question : l'*IA* ne pourrait-elle pas nous *aider √† capturer et valider ces pratiques* ?

* Information que ne reste que dans ma t√™te -> *information tacite*
    ** Ca ne posait PAS de probl√®me avant l'IA gen, car on √©changeait entre nous via diff√©rentes pratiques et c√©r√©monies "humaines"
    ** MAIS l'information tacite, l'IA gen ne la connaitra√Æt PAS. Un gros *probl√®me vu le fonctionnement de l'IA gen*

* Aujourd'hui, l'IA gen peut nous remonter des suggestions de pratiques
    ** √† l'IA Gen : "tu regardes le code tous les jours, et tu nous remontes des suggestions"

image:20240419_Devoxx-France_18.jpg[]

* -> MAIS il faut dans tous les cas une *validation humaine* de ces suggestions de l'IA Gen
    ** *Packmind* peut nous aider en nous proposant un process (un process "r√©alis√© par des humains") pour valider ces suggestions

* Rappel : une "mauvaise pratique" pour une √©quipe, peut donner de tr√®s bons r√©sultats pour une autre

* Et toutes ces bonnes pratiques √† mettre en place nous rappellent en fait beaucoup le Lean une nouvelle fois : 
    1. mise en place de standards : comme Toyota √† l'√©poque
    2. garder un regard critique sur le code
    3. L'IA Gen n'est pas un silver bullet et plusieurs outils vont permettre d'y avoir acc√®s. +
    Il faudra choisir les meilleurs pour nous, et savoir ne PAS les utiliser par moment / suivant les use cases
        ** Par exemple, Arthur d√©branche Copilot quand il fait des TDDs
    4. on ne va PAS pouvoir se passer de l'IA Gen : il y a des gains dans l'absolu, donc la question est "comment va-t-on faire pour s'en servir"

NOTE: Voir le LeadDev Berlin de cette ann√©e 

.La petite phrase de Kent Beck...
image:20240419_Devoxx-France_19.jpg[]

[quote,Kent Beck]
____
"I've been reluctant to try ChatGPT. Today I got over that reluctance. Now I understand why I was relunctant. +
*The value of 90% of my skills just dropped to 0$*. The leverage for the remaining 10% went up 1000x. I need to recalibrate"
____

=== 11:35 -> 12:20 - Conf√©rence - Paris 141 : L'IA et qualit√© de code : Comment √ßa marche l'IA Generative ? LLM, RAG sous le capot

Pr√©sent√© par Arnaud PICHERY et Aur√©lien COQUARD, tous les 2 VP Engineering chez Dataiku

.abstract
--
45 minutes pour comprendre (un peu) comment ces algorithmes arrivent √† √©crire des po√®mes ou r√©pondre √† des questions mieux que ta grand-m√®re. +
Tout le monde n'a que √ßa √† la bouche : "Generative AI". Parmi les mod√®les les plus captivants de cette sph√®re se trouvent les LLM et RAG (Retrieval-Augmented Generation). Ce talk technique vise √† d√©voiler les m√©canismes et les principes fondamentaux qui animent ces puissantes architectures d'IA. +
Plong√©e dans les Mod√®les de Langage √† Grande Echelle (LLM)

    * Explication des LLM et de leur fonctionnement.
    * Aper√ßu des architectures de r√©seau neuronal, telles que les Transformers, qui soutiennent les LLM.
    * Exploration de cas d'utilisation de LLM : r√©daction de textes, g√©n√©ration de code, traduction de langues, et bien plus.

Les Approches RAG : Fondamentaux et Innovations

    * Introduction au concept de RAG et √† son importance.
    * Comment RAG fusionnent la puissance des LLM avec des techniques de recherche d'informations

La g√©n√©ration d'images

    * Aper√ßu du fonctionnement de DALL-e et Midjourney
--

* Les r√©seaux de neurones existent depuis les ann√©es 60
* Word2vec pour l'embedding d√®s 2013
* 2017 : m√©canisme d'attention

.LLM = Large Language Model
image:20240419_Devoxx-France_20.jpg[]
image:20240419_Devoxx-France_21.jpg[]

* Fonction d'activation qu'on va retrouver dans tous les noeuds du r√©seau

image:20240419_Devoxx-France_22.jpg[]

.LLM : √©normes -> 175 milliards de poids / param√®tres pour GPT-3
image:20240419_Devoxx-France_23.jpg[]

NOTE: un humain dans toute sa vie aura lu ~1 Mds de mots

.Processus de g√©nr√©ation de mots, o√π chacun est pr√©dit √† la suite des autres
image:20240419_Devoxx-France_24.jpg[]

* Transformers : Attention is all your need
    ** C'est ce mod√®le qui a "gagn√©" face √† tous les autres +
    image:20240419_Devoxx-France_25.jpg[]

.Fonctionnement des Transformes
image:20240419_Devoxx-France_26.jpg[]

* 1) *Tokenizer* : voir Tiktokenizer +
image:20240419_Devoxx-France_27.jpg[]

.On va transformer les mots en chiffres : leur position dans le dictionnaire
image:20240419_Devoxx-France_28.jpg[]

NOTE: embedding ou plongement en fran√ßais

* 2) *token embedding* +
image:20240419_Devoxx-France_29.jpg[]

.On va rajouter √† notre vecteur des coordonn√©es qui correspondent √† la position du mot dans la phrase
image:20240419_Devoxx-France_30.jpg[]
image:20240419_Devoxx-France_31.jpg[]

.On va r√©cup√©rer le "positional encoding" pour chaque mot
image:20240419_Devoxx-France_32.jpg[]

.Et tout √ßa on va le r√©p√©ter 12 fois (une mesure compl√®tement empirique)
image:20240419_Devoxx-France_33.jpg[]

* 3) *masked self-attention* : une couche permettant de savoir *comment un mot se rapporte aux autres*
    ** Et on s'arr√™te au mot courant (cad on regarde le pass√© et pas l'avenir)
    image:20240419_Devoxx-France_34.jpg[]

* Comment fait-on cela ? On prend un mot on le r√©p√®te 3 fois
image:20240419_Devoxx-France_35.jpg[]

-> Tout ceci ressemble au final √† une grosse hashtable

* 4) *Feed forward* +
image:20240419_Devoxx-France_36.jpg[]
    ** A chaque couche de niveau on enrichit le mod√®le mais SANS masquer les r√©sultats pr√©c√©dents

* *M√©canisme d'entra√Ænement* +
image:20240419_Devoxx-France_37.jpg[]
image:20240419_Devoxx-France_38.jpg[]

* *Fine-tuning* : on va entra√Æner le mod√®le sur un jeu de donn√©es sp√©cifique
image:20240419_Devoxx-France_39.jpg[]
    ** Sans oublier la phase de validation par des humains (mal pay√©s !)

Et maintenant, le *RAG*

* A quoi les LLMs ne sont-ils pas bons ? 
    ** -> *Training date cutoff*
    ** connaissances non accessibles dans le corpus d'entra√Ænement (connaissances lacunaires et hallucinations)

-> Pour *pallier ces probl√®mes* -> *RAG*, Retrieval Augmented Generation

image:20240419_Devoxx-France_40.jpg[]

* Les √©volutions du RAG : +
image:20240419_Devoxx-France_41.jpg[]

    ** *Naive RAG*
    ** *Advanced RAG* : query routing, query rewriting, query expansion
        *** query routing : orienter l'utilisateur vers la meilleure source de donn√©es
    ** *Modular RAG* : concernent les derni√®res avanc√©es d√©crites dans les papiers de recherche

.Et la suite ? L'apr√®s RAG
image:20240419_Devoxx-France_42.jpg[]

-> On va chercher √† faire √©voluer le RAG vers le fine-tuning

.Multimodal RAG
image:20240419_Devoxx-France_43.jpg[]

*G√©n√©ration d'images*

* auparavant le domaine des *GAN* : *Generative Adversarial Networks* +
image:20240419_Devoxx-France_44.jpg[]

* En 2014 : OpenAI a sorti CLIP

* puis *algo de diffusion* : un algo qui ne sert qu'√† *d√©bruiter une image* +
image:20240419_Devoxx-France_45.jpg[]
image:20240419_Devoxx-France_46.jpg[]
    ** On va ajouter 20% de bruit √† l'image et on va demander au LLM de "trouver ce bruit"
image:20240419_Devoxx-France_47.jpg[]
    ** Et ensuite on va r√©p√©ter l'op√©ration avec cette fois 100% de bruit
image:20240419_Devoxx-France_48.jpg[]
image:20240419_Devoxx-France_49.jpg[]
image:20240419_Devoxx-France_50.jpg[]

Conclusion : 

    * Hyper int√©ressant, plein d'insights pour creuser, √† revoir üëçüëçüëç
    * -> Slides √† r√©cup√©rer absolument !

=== 12:35 -> 12:50 - quicky - Neuilly 153 : C'est une bonne situation √ßa, Staff Engineer ? üòâ

Pr√©sent√© par Fran√ßois Nollen, staff engineer & Dev Rel chez SNCF Connect & Tech

.abstract
--
On parle beaucoup du m√©tier d'Engineering Manager, mais plus rarement de Staff Engineer.
Ils sont pourtant compl√©mentaires dans beaucoup d'organisations.

    * Quelles diff√©rences avec Engineering Manager, Principal Engineer, Architect, Chief of Staff ?
    * En 2024, doit-on (toujours) devenir manager pour √©voluer dans la tech ?
    * "Staff" comme un b√¢ton de sorcier üßô ?

Venez d√©couvrir le m√©tier de Staff Engineer. On vous racontera comment √ßa se d√©cline dans notre entreprise, pourquoi et comment on est arriv√©s l√†, une journ√©e typique de "SE", les sujets qu'on porte, comment on collabore avec les autres √©quipes de SNCF Connect au quotidien.
--

image:20240419_Devoxx-France_51.jpg[]

* De nouveau, on nous pr√©sente la double √©chelle : 
    ** fili√®re du contributeur individuel
    ** fili√®re du manager

.Staff engineer : des d√©finitions pas toujours claires...
image:20240419_Devoxx-France_52.jpg[]

* *Staff engineer* : avoir un *impact global positif √† l'√©chelle de l'organisation*
    ** C'est du *leadership par influence*

image:20240419_Devoxx-France_52.jpg[]

* Ce qui est requis : 
    ** comp√©tences techniques
    ** Soft skills : collaboration, communication

* *Ressources et communaut√©s* : +
image:20240419_Devoxx-France_54.jpg[]
    ** communaut√©s *staff 42*
    ** les articles du *Touilleur Express* de Nicolas Martignole

* SNCF Connect : 
    ** dans le d√©partement, tout le monde est redevenu dev

    ** puis, apr√®s, mise en place des *"r√©f√©rents expertise tech"* +
    image:20240419_Devoxx-France_55.jpg[]
        *** Ces gens ont √©t√© COMPLEMENT sortis des √©quipes
        *** ils sont libres de leurs agendas
        *** ils commencent leur journ√©e de travail par "tout lire et tout voir" autour d'eux
        *** ils sont en charge d'√©laborer les bonnes pratiques de dev
        *** ils contribuent √† la PROD (suivi, rem√©diation, etc.)
        *** etc etc.

* SNCF Connect a donc choisi de *les sortir des √©quipes*, afin qu'ils ne soient PAS sur le chemin critique des projets
* Ils ne sont *PAS manag√©s par les engineering managers*

* C'est plus simple de porter un message en se pr√©sentant comme un petit collectif
* Les staff travaillent √† l'√©chelle de l'organisation

.Les 7 diff√©rences
image:20240419_Devoxx-France_56.jpg[]

.Est-ce fait pour vous ?
image:20240419_Devoxx-France_57.jpg[]

* OUI : si vous aimez aller dans les √©quipes pendant 1 ou 2 mois
* Didier GIRARD : si vous aimez √™tre la personne avec laquelle les autres dev aiment travailler

* On va parler de code toute la journ√©e, mais pas forc√©ment coder toute la journ√©e

.Mais est-ce fait pour votre entreprise ?
image:20240419_Devoxx-France_58.jpg[]

* Plut√¥t pour les grandes / moyennes entreprises

.Pour r√©sumer
image:20240419_Devoxx-France_59.jpg[]

Conclusion : super talk ! üëç

=== 13:00 -> 13:15 - quicky - Paris 143 : Comment orchestrer l'IA g√©n√©rative pour qu'elle code √† votre place le front-end d'une page en moins de 2min.

Pr√©sent√© par S√©bastien Vanson

.abstract
--
Jamais je ne ferai bosser une IA √† ma place !
C'est √† peu pr√®s ce qu'a dit l'homme de Cro-Magnon, trop attach√© √† son m√©tier de chasseur-cueilleur, lorsque l'oracle lui a pr√©dit que quelqu'un se chargerait bient√¥t de tuer le mammouth √† sa place.
C'est aussi ce que m'a dit r√©cemment un coll√®gue d√©veloppeur.
Certains oracles, en 2024, pr√©disent la fin prochaine des d√©veloppeurs.
Si cette pr√©diction est discutable, de nouveaux outils arrivent et le d√©veloppeur qui s'adapte est maintenant dot√© de superpouvoirs. +
Apr√®s une courte introduction d√©di√©e √† l'orchestration d'IA g√©n√©rative, nous g√©n√©rerons ensemble :

    * Un exemple de page front-end pour un formulaire de cr√©ation d'utilisateur.
    * Puis un exemple de dashboard statistique.

Tout cela avec des technologies front-end √† la mode, en une poign√©e de minutes ! +
Cerise sur le g√¢teau, nous plongerons dans le code et je vous montrerai comment chacun d'entre vous peut r√©aliser d√®s lundi ce v√©ritable tour de magie dans votre codebase. +
Avec quelques lignes de configuration, que vous soyez front ou back, vous g√©n√©rerez du code qui r√©pond √† vos propres standards de qualit√©.
--

* St√©phane a cr√©√© *beeker.tech* : *orchestrateur d'IA* +
image:20240419_Devoxx-France_60.jpg[]

* Un LLM seul pour des cas simples OK, mais pour un pb complexe ?
* C'est l√† que l'orchestrateur intervient : il d√©coupe le pb complexe en sous-parties plus simples

.Fonctionnement de Beeker
image:20240419_Devoxx-France_61.jpg[]
image:20240419_Devoxx-France_62.jpg[]

* L'IA Gen c'est un Yeoman +++

DEMO

image:20240419_Devoxx-France_63.jpg[]
image:20240419_Devoxx-France_64.jpg[]
image:20240419_Devoxx-France_65.jpg[]

En 2 min : 2 pages React de cr√©√©es

.Ressources
image:20240419_Devoxx-France_66.jpg[]

    * GitHub : https://github.com/beeker-tech/sample-app
    * site : https://beeker.tech

=== 13:30 -> 14:15 - Conf√©rence - Maillot : Le cauchemar des attaquants : une infrastructure sans secret

Pr√©sent√© par Thibault Lengagne, Head of Cybersecurity √† Padok

.bio
--
Head of Cybersecurity √† Padok, Thibault est en charge de la branche sp√©cialis√©e en s√©curit√© Cloud, en tant que directeur technique. Son but : allier S√©curit√© et DevOps pour trouver des solutions innovantes qui prot√®gent les syst√®mes tout en am√©liorant le quotidien des d√©veloppeurs.
--

.abstract
--
La gestion des secrets a toujours √©t√© un sujet complexe : comment et o√π les stocker, comment les partager,qui les utilise, ont-ils √©t√© vol√©s ? S√©rieusement, quand avez-vous chang√© le mot de passe de votre base de donn√©es pour la derni√®re fois ? Selon les chiffres de Verizon, 49% des attaques informatiques impliquent le vol et l'utilisation de secrets, parfois des mois apr√®s leur exfiltration. +
Est-il possible de construire un √©cosyst√®me sans secret long-terme, en coupant ainsi l'herbe sous le pied des hackers ? Les avanc√©es technologiques r√©centes (SSO, OIDC, Cloud IAM, Workload Identity, Vault credential brokering, Just-in-Time access) rendent ce r√™ve non seulement r√©alisable, mais en prime, elles simplifient la vie des d√©veloppeurs.
A la lumi√®re de plus d'une dizaine de missions dans des √©cosyst√®mes diff√©rents, Thibault se propose de vous montrer par des exemples concrets le chemin vers l'infrastructure ‚ÄúZero-Creds‚Äù :

    * Comment supprimer les secrets utilis√©s par les d√©veloppeurs ? (applicatifs, base de donn√©es, cl√©s SSH‚Ä¶)
    * Quels m√©canismes et outils permettent la rotation automatique des secrets utilis√©s par les machines ?

A la fin du talk, vous connaitrez toutes les bonnes pratiques et outils pour supprimer tout secret long-terme de votre √©cosyst√®me.
--

*Zero-Credentials*

    * Secrets d√©veloppeurs
    * Secrets CI/CD
    * Secrets workload

.Les cyber-attaques impliquent l'utilisation de secrets long terme
image:20240419_Devoxx-France_67.jpg[]

* Et les secrets ne sont *pas rotate assez souvent*

.La philosophie Zero-Credentials supprime le probl√®em √† la source
image:20240419_Devoxx-France_68.jpg[]

.Changement de paradigme : legacy -> Zero-Credentials
image:20240419_Devoxx-France_69.jpg[]

.Avantages du Zero-Credentials
image:20240419_Devoxx-France_70.jpg[]

    * r√©duire le risque d'attaque de 60%
    * forte auditabilit√©

.Les sources des risques
image:20240419_Devoxx-France_71.jpg[]

.La m√©thode Padok : d√©tection et suppression de secrets long-terme
image:20240419_Devoxx-France_72.jpg[]

* Il restera quand m√™me certains secrets au final : *cl√©s d'API de services externes* qui ne proposent pas de rotation

1) *Secrets d√©veloppeurs*

    * Mise en place du SSO +
    image:20240419_Devoxx-France_73.jpg[]
        ** Attention n√©anmoins √† tous les outils qui ne supportent pas le SSO
            *** Tout particuli√®rement BDD on-premise
        ** Mais des solutions existent : *OAuth-proxy* +
        image:20240419_Devoxx-France_74.jpg[]
        ** Autre solution : *Vault / Boundary* +
        image:20240419_Devoxx-France_75.jpg[]

2) *Secrets de CI / CD*

    * 0 secret dans le code source +
    image:20240419_Devoxx-France_76.jpg[]

        ** *TruffleHog* et *GitLeaks* pour trouver les secrets laiss√©s sur les repo Git
        ** SOPS va permettre de g√©rer les secrets chiffr√©s +
        image:20240419_Devoxx-France_77.jpg[]

    * g√©n√©ration de credentials court-terme pour le pipeline

    * L'*autorisation* plut√¥t que l'authentification +
    image:20240419_Devoxx-France_78.jpg[]
    image:20240419_Devoxx-France_79.jpg[]

    * Eviter le stockage en "stockage de CI / CD" +
    image:20240419_Devoxx-France_80.jpg[]

        ** Utilisez les dynamic secret par Vault

3) *Secret de workloads*

    * *Rotation automatique* +
    image:20240419_Devoxx-France_81.jpg[]

    * *External Secret + Vault* +
    image:20240419_Devoxx-France_82.jpg[]
        ** L'external secret est vide √† la base, puis son contenu vient √™tre renseign√© par Vault
            *** Probl√®me : quand le secret change, l'external secret n'est pas mis √† jour, c'est √† nous de le g√©rer

    * *Vault Operator* pour la d√©tection automatique de la rotation d'un secret, avec le rollout automatique des applications associ√©es +
    image:20240419_Devoxx-France_83.jpg[]

    * *Vault-agent + Vault* +
    image:20240419_Devoxx-France_84.jpg[]

NOTE: Article conseign√© par Thibault concernant Vault (les points pr√©c√©dents plus en d√©tails) : +
https://www.hashicorp.com/blog/kubernetes-vault-integration-via-sidecar-agent-injector-vs-csi-provider

*DEMO*

image:20240419_Devoxx-France_85.jpg[]

.En conclusion
image:20240419_Devoxx-France_86.jpg[]
image:20240419_Devoxx-France_87.jpg[]

    * Autorisation
    * G√©n√©ration √† la vol√©e
    * Rotation

image:20240419_Devoxx-France_88.jpg[]

Q&A : 

    * Plut√¥t 1 Vault que plusieurs

=== 15:40 -> 16:25 - Conf√©rence - Maillot : J'ai termin√© les 9 Advents of Code : Le√ßons Apprises

Pr√©sent√© par Teiva Harsanyi, SRE chez Google

.abstract
--
Je ne sais pas pour vous, mais personnellement, les seules fois o√π je travaillais sur des probl√®mes d'algorithmique, c'√©tait pour pr√©parer des entretiens. Du coup, je voyais ces sujets comme contraignants. +
Mais √ßa, c'√©tait avant... avant de conna√Ætre l'Advent of Code. L'Advent of Code, c'est un calendrier de l'Avent de puzzles de programmation. Chaque jour en d√©cembre depuis 2015, on doit r√©soudre un nouveau probl√®me. +
En faisant les Advent of Code, je me suis rendu compte qu'il y avait un bon nombre de le√ßons que j'avais apprises et que je peux appliquer dans mon travail de tous les jours.
Au cours de cette pr√©sentation, nous explorerons ces le√ßons r√©parties en 3 cat√©gories :

    * Sur les algorithmes et les structures de donn√©es
    * Sur la programmation en g√©n√©ral
    * Et sur le r√¥le de d√©veloppeur
--

* *LeetCode* -> contrainte, MAIS *Advent of Code* -> jeu üòÉ
    ** Teiva voulait entrer chez Google, il a commenc√© par "travailler" son LeetCode, mais il le voyait comme une contrainte. +
    -> Tout a chang√© avec *Advent of Code* ("calendrier de l'Avent de challenges de programmation")

Ce talk est un REX de Teiva apr√®s avoir r√©solu les 9 Advents of Code

1) Algo et structures de donn√©es

    * *graphes* : ensembles de *noeuds* et *liens*
        ** Important √† conna√Ætre pour ces graphes, le *topological sort*
            *** mais ne peut √™tre appliqu√© qu'√† un *DAG* (liens avec direction et pas de cycle)
            *** Exemple : 2022 jour 21 : liste de singes hurleurs. +
            Probl√®me : que hurle root ?

    * *Big O* : un mod√®le pour comprendre comment un algorithme va scaler

        ** optimisation de l'ex√©cution, mais √† faire APRES avoir optimis√© notre algorithme
        ** bien penser √† sa structure de donn√©es
        ** Big O pour la space complexity (la quantit√© de m√©moire utilis√©e par l'algorithme)

Conclusion sur cette partie : 

    * Ces notions sont cruciales pour de nombreux entretiens techniques
    * la data est maintenant partout
    * ces notions aident vraiment √† devenir un meilleur d√©veloppeur

2) Coding

TO BE COMPLETED

Ressources : 

    * teivah.dev/devoox

=== 17:00 -> 17:30 - Conf√©rence - Paris 242AB : Apache Lucene : de l'indexation textuelle √† l'intelligence artificielle

Pr√©sent√© par Lucian Precup, CTO de All.site

.bio
--
Lucian Precup est CTO de all.site - le moteur de recherche et assistant intelligent collaboratif d√©velopp√© √† Station F. Avec ses coll√®gues d‚ÄôAdelean, Lucian d√©veloppe des solutions pour l‚Äôindexation, la recherche et l‚Äôanalyse de donn√©es. Lucian participe r√©guli√®rement √† des conf√©rences fran√ßaises et internationales sp√©cialis√©es sur les moteurs de recherche et organise le Meetup Search, Data & AI √† Paris.
--

.abstract
--
Apache Lucene a souffl√© ses vingt-deux bougies en septembre dernier, un voyage qui continue d'impacter profond√©ment le monde des technologies Search et Data. 

Lucene est le moteur derri√®re des g√©ants comme Elasticsearch, OpenSearch, Apache Solr, ou encore le r√©cent Atlas Search de MongoDB. +
Son int√©gration dans de nombreux autres projets Open Source, tels que Apache Nutch - le pionnier des web crawlers et pr√©curseur d'Hadoop, et Apache Cassandra - la base de donn√©es NoSQL la plus scalable, t√©moigne de son influence √©tendue. Utilis√© dans des milliers de projets d'entreprise, y compris par des leaders comme LinkedIn et Twitter, Lucene b√©n√©ficie d'une base d'utilisateurs solide et diversifi√©e.

La conf√©rence se plongera dans l'√©volution de Lucene, depuis son index invers√© essentiel pour le traitement du texte, jusqu'aux innovations r√©centes qui refl√®tent une avanc√©e technologique constante. +
Pour conclure, nous aborderons les derni√®res fonctionnalit√©s de Lucene : l'indexation des vecteurs et la recherche vectorielle, qui cr√©ent une synergie puissante avec l'intelligence artificielle g√©n√©rative, ouvrant des horizons in√©dits pour l'avenir de la recherche de donn√©es.
--

* Lucene a 22 ans et est toujours une technologie maintenue
* Lucene est la technologie qui a trouv√© le plus de bugs dans la JVM
* *Berlin Buzzwords* : la conf√©rence de r√©f√©rence mondiale du Search

image:20240419_Devoxx-France_89.jpg[]

.Index invers√© : ici la toute premi√®re version de Lucene
image:20240419_Devoxx-France_90.jpg[]
image:20240419_Devoxx-France_91.jpg[]

* Les recherches bool√©ennes sont tr√®s rapides sur ce type d'index

.Rappels sur la syntaxe Lucene
image:20240419_Devoxx-France_92.jpg[]

.Auto-compl√©tion avec nGram
image:20240419_Devoxx-France_93.jpg[]

* Un index sp√©cifique, et compress√©, est cr√©√© sp√©cialement pour √ßa

.A partir de la version 4 de Lucene, introduction du stockage colonne
image:20240419_Devoxx-France_94.jpg[]

* ce qui a amen√© √† de nouveaux usages : monitoring, obervabilit√©, etc.

.Base de donn√©es spatiales
image:20240419_Devoxx-France_95.jpg[]

* Un point se trouve-t-il dans un polygone qui est la France ?
* Lucene, base de donn√©es spaciale, peut-√™tre m√™me la meilleure BDD g√©o-localis√©e

Apparition des IA g√©n√©rative et recherche vectorielle

.Apparition de la recherche vectorielle dans Lucene
image:20240419_Devoxx-France_96.jpg[]

* Les vecteurs stock√©s dans Lucene sont multi-dimensionnels (plusieurs 100e de dimensions possibles)

image:20240419_Devoxx-France_97.jpg[]

.Vecteurs creux ou denses ?
image:20240419_Devoxx-France_98.jpg[]
image:20240419_Devoxx-France_99.jpg[]

.L'approche RAG
image:20240419_Devoxx-France_100.jpg[]
image:20240419_Devoxx-France_101.jpg[]

* Je pose maintenant *une question qui n'a plus besoin d'√™tre pr√©cise*
    ** Ce n'est plus du full text search, ce n'est plus du key word search

Ressources : 

    * voir les notes du pr√©c√©dent talk d'Adelean
    * leur blog contient de tr√®s bons articles sur le search et les RAG : +
    https://www.adelean.com/blog/

=== Cloture : les Cast Codeurs

* C'est Midjourney et plus Dall-E qui a √©t√© utilis√© pour toutes les images de ce Devoxx France






