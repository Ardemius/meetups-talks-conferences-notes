= Devoxx France 2024
Thomas SCHWENDER <icon:github[] https://github.com/Ardemius/[GitHub] / icon:twitter[role="aqua"] https://twitter.com/thomasschwender[@thomasschwender]>
// Handling GitHub admonition blocks icons
ifndef::env-github[:icons: font]
ifdef::env-github[]
:status:
:outfilesuffix: .adoc
:caution-caption: :fire:
:important-caption: :exclamation:
:note-caption: :paperclip:
:tip-caption: :bulb:
:warning-caption: :warning:
endif::[]
:imagesdir: ./images
:source-highlighter: highlightjs
:highlightjs-languages: asciidoc
// We must enable experimental attribute to display Keyboard, button, and menu macros
:experimental:
// Next 2 ones are to handle line breaks in some particular elements (list, footnotes, etc.)
:lb: pass:[<br> +]
:sb: pass:[<br>]
// check https://github.com/Ardemius/personal-wiki/wiki/AsciiDoctor-tips for tips on table of content in GitHub
:toc: macro
:toclevels: 2
// To number the sections of the table of contents
//:sectnums:
// Add an anchor with hyperlink before the section title
:sectanchors:
// To turn off figure caption labels and numbers
:figure-caption!:
// Same for examples
//:example-caption!:
// To turn off ALL captions
// :caption:

toc::[]

Programme du salon : https://mobile.devoxx.com/events/devoxxfr2024/schedule

== JOUR 1 : MERCREDI 17/04

=== 09:00 -> 09:25 - Keynote - Amphi bleu : Bienvenue Ã  Devoxx France 2024

image:20240417_Devoxx-France_00.jpg[]

=== 09:35 -> 10:00 - keynote - Amphi bleu : IA en mÃ©decine : oÃ¹ en sommes-nous ?

PrÃ©sentÃ© par Jean-Emmanuel Bibault

.biographie
--
Jean-Emmanuel est mÃ©decin cancÃ©rologue et chercheur spÃ©cialisÃ© en Intelligence Artificielle. 
Il a un doctorat en informatique biomÃ©dicale et a rÃ©alisÃ© un post-doctorat Ã  l'UniversitÃ© de Stanford, dans le laboratoire d'Intelligence Artificielle appliquÃ©e Ã  la SantÃ©. 
Il est Professeur des UniversitÃ©s - Praticien Hospitalier Ã  l'UniversitÃ© de Paris / HÃ´pital EuropÃ©en Georges Pompidou et chercheur Ã  l'INSERM. Ses recherches portent sur l'apprentissage machine appliquÃ© au diagnostic et Ã  la prÃ©diction. 

Il est laurÃ©at 2019 de l'AcadÃ©mie Nationale de MÃ©decine pour ses travaux sur la prÃ©diction de la rÃ©ponse thÃ©rapeutique par Intelligence Artificielle. Il a par ailleurs dÃ©veloppÃ© plusieurs applications iPhone et Android et cofondÃ© une startup dans ce domaine, revendue en 2014.

En 2023, il a publiÃ© "2041, L'OdyssÃ©e de la mÃ©decine" aux Editions Equateurs, livre qui raconte comment l'IA en mÃ©decine est nÃ©e et comment elle a et va changer les soins.
--

.abstract
--
Les techniques de machine learning sont actuellement utilisÃ©es pour entraÃ®ner de nombreux modÃ¨les en mÃ©decine. Pourquoi connaissons-nous un tel Ã¢ge d'or de l'IA appliquÃ©e Ã  la mÃ©decine ? 

Cette prÃ©sentation illustrera l'utilisation de l'IA par diffÃ©rents exemples publiÃ©s : prÃ©diction du risque de dÃ©velopper un risque 5 ans Ã  l'avance, interprÃ©tation automatisÃ©e d'image mÃ©dicale, dÃ©tection par Deep Learning de mÃ©lanome, prÃ©diction de la survie sur simple scanner, pilotage de robots chirurgicaux, dÃ©pistage de la dÃ©pression sur instagram, chaque exemple sera expliquÃ© et commentÃ©. Mais l'IA comporte Ã©galement des risques liÃ©s Ã  la gestion des donnÃ©es d'entraÃ®nement, aux biais ou encore les attaques adversarielles. Les perspectives de dÃ©veloppement Ã  10 Ã  15 ans seront enfin abordÃ©es pour comprendre comment l'IA va changer la santÃ© de tous.
--

* "Intelligence" en anglais ne se traduit en fait PAS par "intelligence" en franÃ§ais, mais plutÃ´t par "capacitÃ© de renseignement"

.AccÃ©lÃ©ration de l'IA depuis 1940
image:20240417_Devoxx-France_04.jpg[]

.Toutes les donnÃ©es mÃ©dicales suivantes sont maintenant digitalisÃ©es
image:20240417_Devoxx-France_05.jpg[]

* Parmi les frameworks d'IA les plus utilisÃ©s : 
    1. Pytorch
    2. TensorFlow
    3. Scikit-learn

-> Tous sont amÃ©ricains...

* Actuellement les donnÃ©es mÃ©dicales sont encore TRES mal structurÃ©es 
    ** Encore BEAUCOUP de travail Ã  ce niveau    

* *XGBoost* : LE framework pour l'analyse de donnÃ©es tabulaires

* Quand on parle d'*analyse d'images*, il est tout le temps question de *Deep Learning*

* Algo / papier de Stanford sur un scan de peau (mÃ©lanome) et l'IA donne de meilleurs rÃ©sultats que les 21 dermatologues auxquels elle Ã©tait comparÃ©e.

* Sous 10 15 ans, on aura des opÃ©rations mÃ©dicales, parmi les plus simples, qui seront totalement automatisÃ©es.

.L'IA gÃ©nÃ©rative fait de plus en plus "mieux" que les mÃ©decins
image:20240417_Devoxx-France_06.jpg[]

* *Y COMPRIS pour l'empathie* que "simule" l'IA (qui est meilleure que son gÃ©nÃ©raliste quand on le consulte tard le soir une fois qu'il est crevÃ© d'avoir vu 50 patients...)

.Generative adversarial networks (GANs)
image:20240417_Devoxx-France_07.jpg[]

* On se retrouve avec l'empoisonnement de donnÃ©es Ã  la Glaze, auquel il va falloir faire TRES attention dans le milieu mÃ©dical -> TOUJOURS vÃ©rifier ses donnÃ©es !

* Au Japon, via un rÃ©seau neuronal, on commence Ã  arriver Ã  *"lire dans les pensÃ©es"* ET CA MARCHE ! ðŸ¤¯
    ** Donc petits problÃ¨mes Ã  prÃ©voir d'interrogatoire non consentis et trÃ¨s efficaces...

Donc, pour l'avenir : le mÃ©decin artificiel

image:20240417_Devoxx-France_08.jpg[]

*Q&A :* 

* Jean-Emmanuel : *le meilleur des tests* (pour Ã©viter des biais par exemple) est (et restera probablement) l'*essai clinique*.
    ** la FAC d'Emmanuel est la 1ere Ã  avoir un DU d'IA en santÃ©, MAIS ce n'est pas une formation obligatoire
    ** Mais on a un problÃ¨me sur la formation des Ã©tudiants en mÃ©decine aujourd'hui, qui seront mÃ©decins dans 10 ans, et qui ne seront pas ou pas suffisamment formÃ©s Ã  l'IA alors qu'elle sera partout autour d'eux.

* Enorme risque de perte de connaissances en mÃªme temps que l'IA va "aider" les mÃ©decins
    ** Comme pour les pilotes de ligne, il va y avoir des Ã©preuves oÃ¹ ils vont Ãªtre testÃ©s SEULS, sans pouvoir Ãªtre aider par l'IA.

Conclusion : 

    * Jean-Emmanuel est un gÃ©nie... Comment peut-on rÃ©ussir Ã  faire autant de choses
    * sujet maÃ®trisÃ© techniquement de bout en bout, aucune hÃ©sitation Ã  l'oral, des dÃ©tails, un sans faute, l'un des meilleurs orateurs que j'ai jamais entendu ðŸ‘

=== 10:30 -> 12:30 - Hands-on Lab - Neuilly 253 : Hands-on Gemini, the Google DeepMind LLM

* PrÃ©sentÃ© par Google : Mete Atamel, Valentin Deleplace
    ** Le workshop a Ã©tÃ© conÃ§u par Guillaume LAFORGE
    ** Tous les 3 sont developer advocates chez Google

.abstract
--
In this hands-on workshop, you will get to code using Gemini, the new Large Language Model from Google DeepMind. 

You will first start by familiarizing yourself with the model's capabilities. Then you will use Gemini in different concrete cases, such as extracting data from unstructured text, document classification, but also searching your own documents, or how to supplement the model by integrating the call to external APIs.

The workshop will be conducted using the Java language and the LangChain4j library. Come equipped with a laptop. We will code together in the cloud, no need for any special installation on your machine.
--

.Ressources pour le Hands-on Lab
image:20240417_Devoxx-France_09.jpg[]

    * URL : https://bit.ly/gemini-devoxx-2024
        ** codelab : https://codelabs.developers.google.com/codelabs/gemini-java-developers
        ** repo : https://github.com/glaforge/gemini-workshop-for-java-developers/tree/main
        ** Google Cloud Console : https://console.cloud.google.com/

==== Partie thÃ©orique

.DÃ©finition du AI landscape
image:20240417_Devoxx-France_10.jpg[]

* On commence Ã  diffÃ©rencier dans l'IA gen "Image Gen" et "LLMs"
    ** Aujourd'hui, on focus sur la partie "LLM"

.Evolution des LLMs depuis l'invention des Transformer par Google en 2017
image:20240417_Devoxx-France_11.jpg[]

-> Encore une fois, on se rÃ©fÃ¨re aux graphes de *LifeArchitect.ai* pour la comparaison des modÃ¨les

.Google (Cloud) Lanscape for AI
image:20240417_Devoxx-France_12.jpg[]

* Aujourd'hui : 
    ** Duet AI, Bard -> Gemini
    ** PaLM  (devenu un ancien modÃ¨le) -> Gemini
    ** MakerSuite -> Google AI Studio

.Gemini is an umbrella brand for Google for all their Gemini products
image:20240417_Devoxx-France_13.jpg[]

* Gemini is a brand AND a model
    ** a multimodal model

.Gemini 1.5 characteristics
image:20240417_Devoxx-France_14.jpg[]

* ET il y a une *version opensource de Gemini* : *Gemma*
    ** qu'on peut utiliser dans son propre cluster Kubernetes
    ** Gemma : open weights model derived from Gemini

* You can use Gemini from *Google AI Studio* or *Vertex AI* in Google Cloud
    ** Google AI Studio and Vertex AI sont 2 produits diffÃ©rents, bien distincts

* -> Dans ce workshop, nous allons utiliser *Vertex AI* dans Google Cloud.
    ** Et *LangChain4j*

==== Workshop

image:20240417_Devoxx-France_15.jpg[]
image:20240417_Devoxx-France_16.jpg[]

Etape 3 : Preparing your development environment

    * Pas besoin de la version 21 de Java pour ce workshop
    * On va se servir du *Cloud Code Editor* (un VSCode like dans le Cloud)

image:20240417_Devoxx-France_17.jpg[]
image:20240417_Devoxx-France_18.jpg[]

Etape 4 : First call to the Gemini model

image:20240417_Devoxx-France_19.jpg[]

IMPORTANT: les LLMs sont stateless : si on ne fait "rien", par dÃ©faut les LLMs ne se "souviennent" pas des prÃ©cÃ©dents prompts.

IMPORTANT: MÃªme avec une tempÃ©rature de 0, il n'y a PAS de "vraie" garantie d'avoir le mÃªme rÃ©sultat en appelant 2 fois le mÃªme prompt.

Etape 5 : Chat with Gemini

Attention, avec `MessageWindowChatMemory.builder().maxMessages(20)` on peut garder les 20 derniers messages.

Etape 6 : Multimodality with Gemini

Etape 7 : Extract structured information from unstructured text

    * Et lÃ  on se rend compte d'un des problÃ¨mes de l'IA gen : +
    Toutes les personnes du workshop ont la mÃªme erreur, y compris les speakers : 
+
[source, bash]
----
Exception in thread "main" com.google.gson.JsonSyntaxException: java.lang.IllegalStateException: Expected BEGIN_OBJECT but was STRING at line 1 column 1 path $
        at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:397)
        at com.google.gson.Gson.fromJson(Gson.java:1227)
        at com.google.gson.Gson.fromJson(Gson.java:1137)
        at com.google.gson.Gson.fromJson(Gson.java:1047)
        at com.google.gson.Gson.fromJson(Gson.java:982)
        at dev.langchain4j.internal.GsonJsonCodec.fromJson(GsonJsonCodec.java:66)
        at dev.langchain4j.internal.Json.fromJson(Json.java:79)
        at dev.langchain4j.service.ServiceOutputParser.parse(ServiceOutputParser.java:87)
        at dev.langchain4j.service.DefaultAiServices$1.invoke(DefaultAiServices.java:179)
        at gemini.workshop.$Proxy2.extractPerson(Unknown Source)
        at gemini.workshop.ExtractData.main(ExtractData.java:56)
Caused by: java.lang.IllegalStateException: Expected BEGIN_OBJECT but was STRING at line 1 column 1 path $
        at com.google.gson.stream.JsonReader.beginObject(JsonReader.java:393)
        at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:386)
        ... 10 more

FAILURE: Build failed with an exception.
----

    * -> En fait, le JSON gÃ©nÃ©rÃ© par le LLM doit Ãªtre "mauvais" depuis aujourd'hui, il doit manquer le tout 1er "{" du doc, d'oÃ¹ le "Expected BEGIN_OBJECT but was STRING"
        ** OR, "hier cela marchait" cf les speakers
        ** MAIS il n'y a aucune garantie d'avoir 2 fois le mÃªme rÃ©sultat (completion) avec un LLM, d'oÃ¹ le problÃ¨me

    * "MORALITE" : *importance de la programmation dÃ©fensive avec un LLM !*
        ** La completion d'hier n'est PAS garantie aujourd'hui, il faut donc S'ASSURER que la completion matche toujours les critÃ¨res attendus

Etape 8 : Structure prompts with prompt templates

Etape 9 : Text classification with few-shot prompting

Etape 10 : RAG

The document is split in chunks thanks to the DocumentSplitters class. It is going to split the text of the PDF file into snippets of 500 characters, with an overlap of 100 characters (with the following chunk, to avoid cutting words or sentences, in bits and pieces).

Etape 11 : Function calling

=== ------------------------ 12:20 -> 13:30 : LUNCH ------------------------

=== 12:35 -> 12:50 - quickie - Paris 141 : RÃ©volutionnez votre expÃ©rience utilisateur avec les Progressive Web Apps

PrÃ©sentÃ© par Khadija ABDELOUALI de Ippon

.abstract
--
RÃ©volutionner le monde du web en crÃ©ant une nouvelle gÃ©nÃ©ration d'applications Â« progressives Â» et proposer une alternative aux applications natives ðŸ“± avec une seule et unique base de code : tel est l'enjeu des PWAs.
Entre l'essor du mobile et l'envol des OS divers et variÃ©s, les coÃ»ts de dÃ©veloppement pour chaque plateforme ðŸ’¶, la consommation des ressources ainsi que la procÃ©dure de validation sur les diffÃ©rents app stores deviennent des challenges primordiaux auxquels il faut apporter une rÃ©ponse de toute urgenceðŸš¨.
La solution Â« Progressive Web App Â» apparut ainsi pour la premiÃ¨re fois en 2015 et a depuis Ã©tÃ© largement adoptÃ©e par Starbucks, Pinterest, Uber, â€¦
Alors, le pari des PWAs a-t-il Ã©tÃ© remportÃ© ðŸ†?
ðŸ“¢ Pour le savoir, ne manquez surtout pas cette confÃ©rence, oÃ¹ nous plongerons dans les fondamentaux de cette technologie rÃ©volutionnaire et dÃ©couvrirons Ã©galement comment les PWAs combinent le meilleur des sites web ðŸŒ et des applications mobiles ðŸ“±, afin d'offrir une expÃ©rience utilisateur sans prÃ©cÃ©dent ðŸ‘¨â€ðŸ’».
--

* Les PWA : crÃ©Ã©es par Google en 2015

Avantages : 

    * rÃ©duction des coÃ»ts
    * facilitÃ© de distribution : pas besoin de passer par les stores Google ou Apple
    * disponibilitÃ©s des ressources : plus de facilitÃ© Ã  trouver des devs web (hors mobile)
    * Ã©conomie d'Ã©nergie
    * mise Ã  jour optimisÃ©es : on ne rÃ©cupÃ©re QUE les fichiers mis Ã  jour, pas la peine de packager une application entiÃ¨re

.Passage de Starbucks d'une application mobile Ã  une PWA
image:20240417_Devoxx-France_20.jpg[]

image:20240417_Devoxx-France_21.jpg[]

* C'est le *manifest* et le *service worker* de la PWA qui indiquent au navigateur que c'est une "application" qu'il doit installer

.Lighthouse permet d'Ã©valuer l'adÃ©quation de l'application web aux critÃ¨res techniques pour Ãªtre une PWA.
image:20240417_Devoxx-France_22.jpg[]
image:20240417_Devoxx-France_23.jpg[]

.Conclusion : l'approche pour savoir si on doit faire une PWA
image:20240417_Devoxx-France_24.jpg[]

=== 13:30 -> 14:15 - conference - Neuilly 252AB : Du Clic Ã  la Conversation : remplaÃ§ons boutons et formulaires par un LLM !

PrÃ©sentÃ© par Marie-Alice Blete, Softeam engineer chez Worldline

.abstract
--
PrÃ©parez-vous Ã  voyager dans le domaine de l'interaction homme/machine. 
Vous connaissez la premiÃ¨re rÃ©volution : la souris et l'interface graphique ? Nous sommes dÃ©sormais Ã  l'Ã¨re de la deuxiÃ¨me rÃ©volution : l'interaction en langage naturel grÃ¢ce a l'intelligence artificielle.

Dans cette prÃ©sentation, nous allons metamorphoser une application standard en une application basÃ©e sur un LLM. Dites adieu aux boutons et formulaires car nous nous apprÃªtons Ã  rÃ©Ã©crire les rÃ¨gles de l'interface utilisateur !

Nous dÃ©buterons par les bases, avec un bref rappel des principes de LLM, suivi d'une premiÃ¨re solution exploitant l'*API OpenAI*. 
Ensuite, nous verrons deux autres solutions plus avancÃ©es, dont une comprenant l'utilisation d'agents avec le framework *LangChain*.

Ã€ la fin de cette prÃ©sentation, vous disposerez de toutes les connaissances nÃ©cessaires pour vous lancer. Vous aurez Ã©galement une liste d'astuces, de conseils, ainsi qu'une bonne comprÃ©hension des Ã©cueils pour intÃ©grer des LLM dans vos developpements. Passons du clic Ã  la conversation !
--

* Les LLMs sont la 2e rÃ©volution dans l'interaction homme / machine
    ** La 1ere Ã©tant l'invention de la souris

.LLMs : ceux dispo via une API et ceux Ã  dÃ©ployer soi-mÃªme
image:20240417_Devoxx-France_25.jpg[]

* Nouveau rappel : les LLMs sont *STATELESS* +
-> Ils ne se "rappellent" les prÃ©cÃ©dentes interactions

.Interaction et conversation
[NOTE]
====
* 1 *interaction* = 1 paire de question / rÃ©ponse
* 1 *conversation* est un ensemble d'interactions
====

ProblÃ©matique : remplacer une IHM et toutes ces pop-up nestÃ©es par un LLM...

NOTE: les demo de Marie-Alice semble Ãªtre sur "venv" Python

* 1ere solution : *tout remplacer par 1 prompt*

    1. donner le contexte
    2. dÃ©finir le format de sortie +
    image:20240417_Devoxx-France_26.jpg[]
    image:20240417_Devoxx-France_27.jpg[]
    image:20240417_Devoxx-France_28.jpg[]

    3. donner des instructions prÃ©cises
    4. prompt de dÃ©part

    ** Conclusion : 
        *** pas scalable
        *** confiance ?
        *** maintenance difficile

* 2e solution : *essayer une approche machine Ã  Ã©tat*

image:20240417_Devoxx-France_29.jpg[]
image:20240417_Devoxx-France_30.jpg[]

    ** les prompts des transitions vont avoir la partie mÃ©tier
    ** Et on a DE NOUVEAU un "bug" du LLM oÃ¹ le comportement d'aujourd'hui n'est pas celui d'hier, ce qui pose problÃ¨me

    ** Conclusion : 
        *** XXX
        *** consomme moins de ressources
        *** plus facile Ã  valider

* 3e solution : *utiliser des agents* (LangChain ici)

image:20240417_Devoxx-France_31.jpg[]

    ** *Gradio* utilisÃ© ici pour la demo. +
    -> Parfait pour faire de petites demo, MAIS Ã  ne PAS utiliser en prod...

.Comparaison de ces 3 solutions
image:20240417_Devoxx-France_32.jpg[]

* Dans tous les cas, il FAUT *Ã©valuer les prompts* !
    ** exemple d'outil : *prompt-foo*

* Autre problÃ¨me : *ce qui Ã©tait hier ne sera peut-Ãªtre plus aujourd'hui...* +
-> Un LLM n'est PAS un systÃ¨me dÃ©terministe
    ** Il ne faut pas essayer de le rendre complÃ¨tement dÃ©terministe (perte de crÃ©ativitÃ©), mais il faut mettre en place des *process de vÃ©rification* +
    image:20240417_Devoxx-France_33.jpg[]
    ** Et si Ã§a ne marche pas, il faut mettre en place des *stratÃ©gies de repli* +
    image:20240417_Devoxx-France_34.jpg[]
    ** Exemple de *retry* pour essayer de garantir un "bon" format JSON +
    image:20240417_Devoxx-France_35.jpg[]
    image:20240417_Devoxx-France_36.jpg[]

* Attention au *prompt injection*
    ** mettre un disclaimer car on PEUT se faire "hacker"

* Gestion du *coÃ»t*
    ** utiliser un cache pour les questions frÃ©quentes
    ** XXX

* Attention Ã  la confidentialitÃ© des donnÃ©es ! 
    ** OpenAI est aux US, voulez-vous, pouvez-vous envoyer les donnÃ©es de vos clients lÃ -bas ?

Conclusion : 

    * de bonnes explications et astuces Ã  rÃ©cupÃ©rer !

.Ressources
image:20240417_Devoxx-France_37.jpg[]

    * Tout le code et les slides sont dispo sur https://github.com/malywut/clicks2conversations

=== 15:40 -> 16:25 - conference - Paris 242AB : Crafting your own RAG system: Leveraging 30+ LLMs for enhanced performance

PrÃ©sentÃ© par Stephan Janssen, crÃ©ateur de Devoxx (Belgique, l'original)

.abstract
--
In this talk you'll learn how to set up a RAG (Retrieval-Augmented Generation) system against 30+ different Large Language Models using Java.

We'll show you step-by-step how to ingest documents, choose the best text splitter strategies, find similar documents, answer questions, and create a chatbot.

Then, we'll see how to test and compare different AI models, both from open sources and private ones, and whether they are stored on your own computer or accessed online.
You'll walk away knowing how to setup a well balanced RAG system using Java and the best performing and/or cheapest LLM.
--

* How many talks did Brian Goetz give at Devoxx Belgium ? 
* How many presentation did Brian Goetz give at Devoxx Belgium ? 
    ** eh bien, notre LLM nous donne 2 rÃ©ponses diffÃ©rentes...

.Architecture d'un RAG par StÃ©phane Janssen
image:20240417_Devoxx-France_39.jpg[]

* ReRanker : NON semantic (IA) sort

* LLM providers locally running on your laptop : 
    ** Ollama
    ** LM Studio
    ** GPT4All
    ** Apple MLX

* LLM providers online :
    ** OpenAI
    ** Claude
    ** Groq

image:20240417_Devoxx-France_40.jpg[]

-> Tous sont supportÃ©s par LangChain (Ã  vÃ©rifier !)

.StÃ©phane a dÃ©veloppÃ© sa propre BM25 (ReRanker) Java implementation, en 1 we en se faisant aider de ChatGPT et Claude
image:20240417_Devoxx-France_38.jpg[]

* et son implÃ©mentation BM25 est gratuite...

.Import Data (Ingestion) : extract data from "content"
image:20240417_Devoxx-France_41.jpg[]

* *To Split or... Not to split* ?!
    ** des contects qui montent maintenant au 1M de tokens...
    ** from 0.10$ to 120$ for 1M tokens
    ** milliseconds to minutes (10 min pour 1M tokens)
    ** Be aware : "context injection" does reduce hallucinations

.Advanced Splitting Strategies
image:20240417_Devoxx-France_42.jpg[]

-> Regarder le talk de *Text Splitting* de *Greg Kamradt* : +
https://www.youtube.com/watch?v=8OJC21T2SL4

* Importance capitale de l'embedding
    ** et plusieurs modÃ¨les pour faire de l'embedding sont dispo

.Vector Databases
image:20240417_Devoxx-France_43.jpg[]
image:20240417_Devoxx-France_44.jpg[]

* Regarder le trÃ¨s bon talk sur le Vector DB de *Alexander Chatzizacharias* : +
https://www.youtube.com/watch?v=W-i8bcxkXok

* On ne peut pas utiliser PostgrePG pour de l'embedding avec OpenAI, car il ne supporte que 2000 dimensions quand OpenAI en utilise 3000 (A VERIFIER)

.StÃ©phane a Ã©galement dÃ©veloppÃ©, car manquant, LangChain4J-cohere (Langchain4J compliant Cohere embedding model)
image:20240417_Devoxx-France_45.jpg[]

    * https://github.com/stephanj/langchain4j-cohere
    * Gemini : "Cohere is a novel approach to representing text data that aims to capture both semantic and syntactic information in a more effective way compared to traditional embedding methods."

.Conclusion and lessons learned
image:20240417_Devoxx-France_46.jpg[]

* Embeddings models have an *input limit*
* the bigger the embedding dimensions the higher the hosting cost
* multi language embedding is a thing
* QUALITY of your embedding influences the QUALITY of your results

* StÃ©phane a Ã©crit le plugin "Devoxx Genie" pour IntelliJ

image:20240417_Devoxx-France_47.jpg[]
image:20240417_Devoxx-France_48.jpg[]

-> Et Claude 3 Opus donne apparemment des rÃ©sultats exceptionnels

image:20240417_Devoxx-France_49.jpg[]

* Ressources GitHub du talk : 
    ** https://github.com/stephanj/rag-genie
    ** https://github.com/devoxx/devoxxgenieIDEAplugin

Conclusion : 

    * Comme Jean-Emmanuel, StÃ©phane est vraiment impressionnant quand on voit tout ce qu'il arrive Ã  crÃ©er en si peu de temps

=== 17:50 -> 18:20 - tools-in-action - Neuilly 153 : Creating a documentation site for users with AsciiDoc and Antora

PrÃ©sentÃ© par Alexander Schwartz, Principal Software Engineer at Red Hat

.abstract
--
Documentation for a software project is essential for users, administrator and developers alike: Users need to find the right tutorials, reference documentation and answers to their questions, administrators need to know how to install and operator the software, while developers need other documents to get started contributing, and share concepts and architectures for fellow contributors.

The tool Antora simplifies the process by creating documentation websites from AsciiDoc sources stored in Git repositories. Users can browse the generated website and select the version matching the software they use. Navigation outlines, search and cross-references between pages allow users to find answers to their questions. Several open-source software projects like Camel, Debezium and Couchbase use this solution.
For developers it is normal to develop software in collaboration using their IDE and a version control system like Git. The same type of collaboration is possible when all documentation is versioned in a markup-format like AsciiDoc.

This talk presents the basics of an Antora setup and walks through all the steps from editing content in the IDE to updating the documentation site using continuous integration and delivery.
--

URL : https://docs.antora.org

.Sommaire du talk
image:20240417_Devoxx-France_53.jpg[]

1. How users search for informations

    * *Every page is "page one"* : +
    image:20240417_Devoxx-France_50.jpg[]

2. How AsciiDoc and Antora help

    ** Antora provides publishing tools and documentation structure +
    image:20240417_Devoxx-France_51.jpg[]

    ** AsciiDoc is the language, AsciiDoctor is a toolchain 
    image:20240417_Devoxx-France_52.jpg[]

3. Setting up Antora

.Antora structure
image:20240417_Devoxx-France_54.jpg[]

.Antora process
image:20240417_Devoxx-France_55.jpg[]

* Antora va permettre la gÃ©nÃ©ration d'un site statique (logique)

1. dÃ©finition des rÃ´les for Antora
2. first steps de configuration d'Antora +
image:20240417_Devoxx-France_56.jpg[]

Conclusion : 

    * Le talk passe pas mal de temps Ã  prÃ©senter AsciiDoc, et je n'arrive pas trop Ã  voir l'intÃ©rÃªt d'Antora rapport Ã  AsciiDoc et AsciiDoctor seuls

== JOUR 2 : JEUDI 18/04

=== 09:00 -> 09:25 - Keynote - Amphi bleu : Programming's Greatest Mistakes

PrÃ©sentÃ© par Mark Rendle

.Bio
--
Mark is the founder of RendleLabs, which provides consulting services and workshops to .NET development teams across all industries. His particular obsessions are API design and development, performance, Observability and code-base modernisation. He also uses skills acquired during a few years as a professional stand-up comic to deliver entertaining and informative talks at conferences around the world, and recently learned to play bass so he could join tech parody band The LineBreakers.
--

.abstract
--
Most of the time when we make mistakes in our code, a message gets displayed wrong or an invoice doesn't get sent. But sometimes when people make mistakes in code, things literally explode, or bankrupt companies, or make web development a living hell for millions of programmers for years to come.
 
Join Mark on a tour through some of the worst mistakes in the history of programming. Learn what went wrong, why it went wrong, how much it cost, and how things can be pretty funny when they're not happening to you.
--

* Dans les annÃ©es 1950, la mÃ©moire coÃ»tait 1$ pour 1 bit (et pas un byte, bien 1 bit)
    ** dans 1 kilobytes coÃ»tait plus de 8 000$...
    ** la mÃ©moire Ã©tait "tricotÃ©e" Ã  la main par des femmes sur des plaquettes comme la suivante : +
    image:20240418_Devoxx-France_01.jpg[]

=== 09:35 -> 10:00 - Keynote - Amphi bleu : Un monde shootÃ© aux mÃ©taux

PrÃ©sentÃ© par Guillaume Pitron et Agnes Crepet

.Bio
--
* *Guillaume* : Ã‰minent journaliste, auteur et rÃ©alisateur franÃ§ais basÃ© Ã  Paris, Guillaume Pitron est reconnu pour ses essais perspicaces sur les impacts cachÃ©s des transitions Ã©nergÃ©tique et numÃ©rique.

* *Agnes* : AgnÃ¨s Crepet est responsable de la longÃ©vitÃ© logicielle et de l'informatique chez Fairphone, une entreprise sociale crÃ©ant un smartphone Ã©thique, modulaire et rÃ©parable.
--

.abstract
--
Dans cette confÃ©rence intitulÃ©e "Un monde shootÃ© aux mÃ©taux", Guillaume Pitron, expert des enjeux gÃ©opolitiques liÃ©s aux ressources naturelles, et Agnes Crepet, spÃ©cialiste en technologies Ã©co-responsables, s'unissent pour aborder la dÃ©pendance croissante de nos sociÃ©tÃ©s aux mÃ©taux rares et ses implications profondes. Ils exploreront comment cette consommation excessive impacte l'environnement, l'Ã©conomie mondiale et les relations sociales, en dÃ©voilant les chaÃ®nes d'approvisionnement complexes qui relient les mines isolÃ©es aux technologies quotidiennes. La discussion soulignera les consÃ©quences environnementales de l'extraction des mÃ©taux, les dÃ©fis Ã©thiques et les tensions gÃ©opolitiques qu'elle engendre.
--

* Smartphone : ratio de 1200 / 1 -> si mon tÃ©lÃ©phone pÃ¨se 200g, il a fallu 240kg de matiÃ¨res premiÃ¨res pour le fabriquer

* Les mÃ©taux derriÃ¨re un iPhone, juste les mÃ©taux, coÃ»tent 2â‚¬... Juste 2â‚¬...
    ** On doit certainement pouvoir faire quelque chose pour mieux exploiter les mines qui sont derriÃ¨re : respect des mineurs, amÃ©lioration du contexte gÃ©opolitique (corruption, contrebande, etc.)

* DurÃ©e de vie d'un mobile sur la stack Android : 2 Ã  3 ans
    ** Ce serait bien si on passait Ã  7 Ã  8 ans

=== 10:30 -> 11:15 - conference - Paris 143 : Comment Back Market a reconditionnÃ© sa plateforme en changeant de Cloud Provider

* C'est vrai : BackMarket est bien passÃ© de AWS Ã  GCP
    ** la derniÃ¨re partie de la migration s'Ã©tant terminÃ©e hier !

.BackMarket en quelques chiffres
image:20240418_Devoxx-France_02.jpg[]

* infogÃ©rÃ©, dans le Cloud, plus de 40 000 containers

*2014 Ã  2018*

    * de 5 Ã  100 employÃ©s en 4 ans
    * infogÃ©rance totale, qui se passe bien au dÃ©but, mais au fur et Ã  mesure de cette croissance rapide, l'infogÃ©reur n'arrive plus Ã  suivre +
    -> BackMarket dÃ©cide donc d'internaliser toute sa plateforme

.Les limites de l'infogÃ©rance initiale de la plateforme
image:20240418_Devoxx-France_03.jpg[]

* A l'Ã©poque la boÃ®te va bien, fait de la croissance, mais les OPS s'inquiÃ¨tent...

.La plateforme infogÃ©rÃ©e
image:20240418_Devoxx-France_04.jpg[]

    * 2 monolithes, l'un en Django

.La cible sur le Cloud (AWS Ã  l'Ã©poque)
image:20240418_Devoxx-France_05.jpg[]

* StratÃ©gie : 
    ** internaliser la plateforme (toujours sur AWS, comme l'infogÃ©reur)
    ** dÃ©porter sur les edges : CDN + Sec
    ** passage de VMs Ã  Containers & Kubernetes (K8s)
    ** PAS de make, surtout du *buy*

*Et pourquoi pas GCP alors ???*

* Non, car il faut que la durÃ©e de l'internalisation soit de 1 mois MAX
* On veut rester Cloud agnostique

* GCP Engineer : "Vous n'allez pas pouvoir migrer chez nous sans efforts substantiels au niveau de la base de donnÃ©es"
    ** BackMarket Ã©tait sur Aurora, dont on devient vite accro Ã  la latence basse (Ã  vÃ©rifier), MAIS qui devient vite galÃ¨re du cÃ´tÃ© de l'eventual consistency +
    -> A VERIFIER

.Tips pour une migration de ce type
image:20240418_Devoxx-France_06.jpg[]

*De 2018 Ã  2023 :*

.Poursuite de la croissance
image:20240418_Devoxx-France_07.jpg[]

.Le cÃ´tÃ© Cloud Agnostic commence Ã  coÃ»ter cher, trop cher
image:20240418_Devoxx-France_08.jpg[]

* des K8s clusters self managed -> beaucoup d'opÃ©rations
* coÃ»ts de maintenance Ã©levÃ©s
* plateforme d'analytics sur BigQuery, alors que le reste de la plateforme Ã©tait sur AWS, et on voyait bien que les *coÃ»ts d'Egress*, acceptables au dÃ©but allaient devenir un problÃ¨me

.Architecture en 2023
image:20240418_Devoxx-France_09.jpg[]

    * rÃ©pliquÃ©e sur 3 rÃ©gions, avec Ã  chaque fois Prod et NON Prod

*2023* (et l'idÃ©e de passer chez GCP)

* *Comment changer de trajectoire architecturale et stratÃ©gique tout en modernisant sa plateforme ?*

* LÃ  maintenant, on arrÃªte d'Ãªtre Cloud agnostique, et on va adhÃ©rer au catalogue du Cloud provider
    ** On sait que cela va Ãªtre davantage un "locked in" chez le Cloud provider choisi

.La stratÃ©gie et les questions Ã  se poser pour un changement de Cloud Provider
image:20240418_Devoxx-France_10.jpg[]

    * StratÃ©gie : "se dÃ©cider, convaincre et aligner"

.Une stratÃ©gie pour la technique ET pour le business (pour vÃ©rifier la viabilitÃ© du projet)
image:20240418_Devoxx-France_11.jpg[]

* *Qualification des Ã©quipes* : on Ã©tait compÃ©tent en AWS, mais pas en GCP
    ** BackMarket a considÃ©rÃ© que ce n'Ã©tait pas un problÃ¨me, les concepts du Cloud Ã©tant considÃ©rÃ© comme similaires
    ** MAIS il est important de ne PAS chercher Ã  utiliser exactement les mÃªmes services d'un Cloud Ã  l'autre : il faut tenir compte au mieux des spÃ©cificitÃ©s du Cloud Provider et ne pas chercher un matching "1 pour 1"

* Le POC a Ã©tÃ© une Ã©tape cruciale : 
    ** on aurait pas changÃ© de Cloud provider sans lui
    ** on aurait pas changÃ© sans rÃ©sultat concluant

.DÃ©tails du POC
image:20240418_Devoxx-France_12.jpg[]

* Objectif : une PrePROD live sur GCP en *10 jours*
    ** cela semble tellement court vue leur infra !
* Les Ã©quipes Google ont Ã©tÃ© directement sollicitÃ©es pour ce POC

.Comparaison entre les Cloud Providers AWS et GCP
image:20240418_Devoxx-France_13.jpg[]

* *Engagement durable et Ã©cologique* : AWS notÃ© "F" jusqu'en 2020 oÃ¹ ils ont arrÃªtÃ© de remplir le questionnaire... PassÃ© "B" en 2023
* *CoÃ»ts* : plus de docs et d'efforts de transparence cÃ´tÃ© Google

.Au final, 8 mois pour la durÃ©e totale de la migration
image:20240418_Devoxx-France_14.jpg[]

.La nouvelle plateforme sur GCP (et GCP GKE)
image:20240418_Devoxx-France_15.jpg[]

* plus de MySQL pour le monolithe, passage Ã  Postgre

.Les conclusions de cette migration
image:20240418_Devoxx-France_16.jpg[]

* Buy buy buy, et make LATER
* Faites un vrai POC, PAS une simple "tech discovery"
* en POC, *TRACEZ* les difficultÃ©s et dÃ©cisions, car vous y ferez face plus tard

.CÃ´tÃ© Leadership
image:20240418_Devoxx-France_17.jpg[]

* *CrÃ©er une culture du risque !*
* Mettre en place une TPM (Total Productive Maintenance)

*Conclusion* : un REX trÃ¨s concret, avec beaucoup de bons conseils Ã  revoir en cas de projet de migration de Cloud Provider ðŸ‘

*Q&A*

* *Pourquoi pas Azure ?*
    ** StratÃ©gie de "bundleling" de Microsoft
    ** certains outils ne convenaient pas (ne semblaient pas convenir)
    ** utilisateurs de BigQuery depuis 2009, passer sur Azure signifiait conserver les problÃ¨mes d'Egress ?

* *Pourquoi pas une approche hybride AWS / GCP ?*
    ** De nouveau, pas rÃ©aliste pour les *coÃ»ts d'Egress*

* La migration de la partie DB a Ã©tÃ© le plus difficile
    
=== 11:35 -> 12:20 - conference - Paris 141 : La recherche Ã  l'Ã¨re de l'IA

.abstract
--
La recherche ne se contente plus de l'approche maintenant traditionnelle basÃ©e sur la frÃ©quence des termes (TF/IDF ou BM25) mais plus sur la tendance actuelle du machine learning oÃ¹ les nouveaux modÃ¨les ont ouvert une nouvelle dimension pour la recherche.
Cette confÃ©rence donne un aperÃ§u de :

    * La recherche "Classique" et ses limitations
    * Qu'est qu'un modÃ¨le de machine learning et comment vous pouvez l'utiliser
    * Comment utiliser la recherche vectorielle ou la recherche hybride dans Elasticsearch
    * Comment ChatGPT d'OpenAI ou les "large language models" (LLMs) similaires viennent jouer naturellement avec Elastic

Cette session couvre l'Ã©tat de l'art en matiÃ¨re de recherche de nos jours : BM25, recherche vectorielle, embeddings, recherche hybride, Reciprocal Rank Fusion, intÃ©gration avec OpenAI... +
La dÃ©mo principale montre comment gÃ©nÃ©rer des embeddings Ã  partir de musiques puis comment trouver la musique qui s'approche le plus d'une musique que nous fredonnons.
--

.Agenda
image:20240418_Devoxx-France_18.jpg[]

* *Elasticsearch* permet AUSSI de faire de la *recherche vectorielle*

.Qu'est-ce qu'un vecteur ?
image:20240418_Devoxx-France_19.jpg[]
image:20240418_Devoxx-France_20.jpg[]

* LÃ  on n'a que 2 dimensions, mais on pourrait en avoir plus

.Choice of Embedding Model
image:20240418_Devoxx-France_21.jpg[]

image:20240418_Devoxx-France_22.jpg[]

.Tous les modÃ¨les supportÃ©s par Elastic
image:20240418_Devoxx-France_23.jpg[]

.Maintenant, comment faire la recherche (Vector Query) ?
image:20240418_Devoxx-France_24.jpg[]

.3 Ã©tapes pour faire une recherche vectorielle :
image:20240418_Devoxx-France_25.jpg[]

    * search
    * index
    * generate

* Les moyens de trouver les bons vecteurs : 

    ** similaritÃ© cosinus +
    image:20240418_Devoxx-France_26.jpg[]
    image:20240418_Devoxx-France_27.jpg[]

    ** longueur du vecteur : dot_product +
    image:20240418_Devoxx-France_28.jpg[]

    ** distance euclidienne
    image:20240418_Devoxx-France_29.jpg[]

    ** une approche un peu diffÃ©rente : HNSW
    image:20240418_Devoxx-France_30.jpg[]

.Filtering KNN Vector Similarity
image:20240418_Devoxx-France_31.jpg[]

* -> Elastic supporte maintenant 4096 dimensions
    ** MAIS cela consomme beaucoup de ressources !

.Les bonnes pratiques de recherche vectorielle
image:20240418_Devoxx-France_32.jpg[]

.Recherche hybride
image:20240418_Devoxx-France_33.jpg[]

.ELSER
image:20240418_Devoxx-France_34.jpg[]
image:20240418_Devoxx-France_35.jpg[]

*Ranking* : RRF (Reciprocal Rank Fusion)

image:20240418_Devoxx-France_36.jpg[]

DEMO

* sur le thÃ¨me de la musique, David adore mixer ðŸ˜‰

.Architecture de la demo
image:20240418_Devoxx-France_37.jpg[]

* repo GitHub : https://github.com/dadoonet/music-search

.ET ChatGPT et la gen AI sont arrivÃ©s...
image:20240418_Devoxx-France_38.jpg[]

.ChatGPT et les LLM -> "une" rÃ©ponse
image:20240418_Devoxx-France_39.jpg[]

.RAG -> "la bonne rÃ©ponse" (car on va la chercher dans les "bonnes" donnÃ©es)
image:20240418_Devoxx-France_40.jpg[]

.En conclusion, de quoi avons-nous besoin pour faire de la recherche sÃ©mantique ?
image:20240418_Devoxx-France_41.jpg[]

-> *Elasticsearch* permet AUSSI de faire de la *recherche sÃ©mantique*

Ressources : 

    * slides de la prÃ©sentation : https://speaker.pilato.fr/WlpZdt

Conclusion : 

    * Super talk, dense avec comme d'habitude un David trÃ¨s fluide et qui maÃ®trise le sujet ðŸ‘
    * A revoir "calmement" car cela allait vite ðŸ˜…

=== ------------------------ 12:20 -> 13:30 : LUNCH ------------------------

=== 12:35 -> 12:50 - quicky - Paris 242AB : Je dÃ©lÃ¨gue tous mes tests Ã  une IA

=== 12:35 -> 12:50 - quicky - Maillot : C4 model, la solution pour standardiser mes schÃ©mas d'architecture ?

=== 13:30 -> 16:30 - Deep Dive - Neuilly 251 : Construire son assistant Intelligent avec Hugging Face et Elasticsearch

=== 17:00 -> 18:30 - other - Neuilly 253 : Toutes et tous les mercenaires de DevOps !









