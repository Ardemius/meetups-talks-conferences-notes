= Devoxx France 2024
Thomas SCHWENDER <icon:github[] https://github.com/Ardemius/[GitHub] / icon:twitter[role="aqua"] https://twitter.com/thomasschwender[@thomasschwender]>
// Handling GitHub admonition blocks icons
ifndef::env-github[:icons: font]
ifdef::env-github[]
:status:
:outfilesuffix: .adoc
:caution-caption: :fire:
:important-caption: :exclamation:
:note-caption: :paperclip:
:tip-caption: :bulb:
:warning-caption: :warning:
endif::[]
:imagesdir: ./images
:source-highlighter: highlightjs
:highlightjs-languages: asciidoc
// We must enable experimental attribute to display Keyboard, button, and menu macros
:experimental:
// Next 2 ones are to handle line breaks in some particular elements (list, footnotes, etc.)
:lb: pass:[<br> +]
:sb: pass:[<br>]
// check https://github.com/Ardemius/personal-wiki/wiki/AsciiDoctor-tips for tips on table of content in GitHub
:toc: macro
:toclevels: 2
// To number the sections of the table of contents
//:sectnums:
// Add an anchor with hyperlink before the section title
:sectanchors:
// To turn off figure caption labels and numbers
:figure-caption!:
// Same for examples
//:example-caption!:
// To turn off ALL captions
// :caption:

toc::[]

Programme du salon : https://mobile.devoxx.com/events/devoxxfr2024/schedule

== JOUR 1 : MERCREDI 17/04

=== 09:00 -> 09:25 - Keynote - Amphi bleu : Bienvenue √† Devoxx France 2024

image:20240417_Devoxx-France_00.jpg[]

=== 09:35 -> 10:00 - keynote - Amphi bleu : IA en m√©decine : o√π en sommes-nous ?

Pr√©sent√© par Jean-Emmanuel Bibault

.biographie
--
Jean-Emmanuel est m√©decin canc√©rologue et chercheur sp√©cialis√© en Intelligence Artificielle. 
Il a un doctorat en informatique biom√©dicale et a r√©alis√© un post-doctorat √† l'Universit√© de Stanford, dans le laboratoire d'Intelligence Artificielle appliqu√©e √† la Sant√©. 
Il est Professeur des Universit√©s - Praticien Hospitalier √† l'Universit√© de Paris / H√¥pital Europ√©en Georges Pompidou et chercheur √† l'INSERM. Ses recherches portent sur l'apprentissage machine appliqu√© au diagnostic et √† la pr√©diction. 

Il est laur√©at 2019 de l'Acad√©mie Nationale de M√©decine pour ses travaux sur la pr√©diction de la r√©ponse th√©rapeutique par Intelligence Artificielle. Il a par ailleurs d√©velopp√© plusieurs applications iPhone et Android et cofond√© une startup dans ce domaine, revendue en 2014.

En 2023, il a publi√© "2041, L'Odyss√©e de la m√©decine" aux Editions Equateurs, livre qui raconte comment l'IA en m√©decine est n√©e et comment elle a et va changer les soins.
--

.abstract
--
Les techniques de machine learning sont actuellement utilis√©es pour entra√Æner de nombreux mod√®les en m√©decine. Pourquoi connaissons-nous un tel √¢ge d'or de l'IA appliqu√©e √† la m√©decine ? 

Cette pr√©sentation illustrera l'utilisation de l'IA par diff√©rents exemples publi√©s : pr√©diction du risque de d√©velopper un risque 5 ans √† l'avance, interpr√©tation automatis√©e d'image m√©dicale, d√©tection par Deep Learning de m√©lanome, pr√©diction de la survie sur simple scanner, pilotage de robots chirurgicaux, d√©pistage de la d√©pression sur instagram, chaque exemple sera expliqu√© et comment√©. Mais l'IA comporte √©galement des risques li√©s √† la gestion des donn√©es d'entra√Ænement, aux biais ou encore les attaques adversarielles. Les perspectives de d√©veloppement √† 10 √† 15 ans seront enfin abord√©es pour comprendre comment l'IA va changer la sant√© de tous.
--

* "Intelligence" en anglais ne se traduit en fait PAS par "intelligence" en fran√ßais, mais plut√¥t par "capacit√© de renseignement"

.Acc√©l√©ration de l'IA depuis 1940
image:20240417_Devoxx-France_04.jpg[]

.Toutes les donn√©es m√©dicales suivantes sont maintenant digitalis√©es
image:20240417_Devoxx-France_05.jpg[]

* Parmi les frameworks d'IA les plus utilis√©s : 
    1. Pytorch
    2. TensorFlow
    3. Scikit-learn

-> Tous sont am√©ricains...

* Actuellement les donn√©es m√©dicales sont encore TRES mal structur√©es 
    ** Encore BEAUCOUP de travail √† ce niveau    

* *XGBoost* : LE framework pour l'analyse de donn√©es tabulaires

* Quand on parle d'*analyse d'images*, il est tout le temps question de *Deep Learning*

* Algo / papier de Stanford sur un scan de peau (m√©lanome) et l'IA donne de meilleurs r√©sultats que les 21 dermatologues auxquels elle √©tait compar√©e.

* Sous 10 15 ans, on aura des op√©rations m√©dicales, parmi les plus simples, qui seront totalement automatis√©es.

.L'IA g√©n√©rative fait de plus en plus "mieux" que les m√©decins
image:20240417_Devoxx-France_06.jpg[]

* *Y COMPRIS pour l'empathie* que "simule" l'IA (qui est meilleure que son g√©n√©raliste quand on le consulte tard le soir une fois qu'il est crev√© d'avoir vu 50 patients...)

.Generative adversarial networks (GANs)
image:20240417_Devoxx-France_07.jpg[]

* On se retrouve avec l'empoisonnement de donn√©es √† la Glaze, auquel il va falloir faire TRES attention dans le milieu m√©dical -> TOUJOURS v√©rifier ses donn√©es !

* Au Japon, via un r√©seau neuronal, on commence √† arriver √† *"lire dans les pens√©es"* ET CA MARCHE ! ü§Ø
    ** Donc petits probl√®mes √† pr√©voir d'interrogatoire non consentis et tr√®s efficaces...

Donc, pour l'avenir : le m√©decin artificiel

image:20240417_Devoxx-France_08.jpg[]

*Q&A :* 

* Jean-Emmanuel : *le meilleur des tests* (pour √©viter des biais par exemple) est (et restera probablement) l'*essai clinique*.
    ** la FAC d'Emmanuel est la 1ere √† avoir un DU d'IA en sant√©, MAIS ce n'est pas une formation obligatoire
    ** Mais on a un probl√®me sur la formation des √©tudiants en m√©decine aujourd'hui, qui seront m√©decins dans 10 ans, et qui ne seront pas ou pas suffisamment form√©s √† l'IA alors qu'elle sera partout autour d'eux.

* Enorme risque de perte de connaissances en m√™me temps que l'IA va "aider" les m√©decins
    ** Comme pour les pilotes de ligne, il va y avoir des √©preuves o√π ils vont √™tre test√©s SEULS, sans pouvoir √™tre aider par l'IA.

Conclusion : 

    * Jean-Emmanuel est un g√©nie... Comment peut-on r√©ussir √† faire autant de choses
    * sujet ma√Ætris√© techniquement de bout en bout, aucune h√©sitation √† l'oral, des d√©tails, un sans faute, l'un des meilleurs orateurs que j'ai jamais entendu üëç

=== 10:30 -> 12:30 - Hands-on Lab - Neuilly 253 : Hands-on Gemini, the Google DeepMind LLM

* Pr√©sent√© par Google : Mete Atamel, Valentin Deleplace
    ** Le workshop a √©t√© con√ßu par Guillaume LAFORGE
    ** Tous les 3 sont developer advocates chez Google

.abstract
--
In this hands-on workshop, you will get to code using Gemini, the new Large Language Model from Google DeepMind. 

You will first start by familiarizing yourself with the model's capabilities. Then you will use Gemini in different concrete cases, such as extracting data from unstructured text, document classification, but also searching your own documents, or how to supplement the model by integrating the call to external APIs.

The workshop will be conducted using the Java language and the LangChain4j library. Come equipped with a laptop. We will code together in the cloud, no need for any special installation on your machine.
--

.Ressources pour le Hands-on Lab
image:20240417_Devoxx-France_09.jpg[]

    * URL : https://bit.ly/gemini-devoxx-2024
        ** codelab : https://codelabs.developers.google.com/codelabs/gemini-java-developers
        ** repo : https://github.com/glaforge/gemini-workshop-for-java-developers/tree/main
        ** Google Cloud Console : https://console.cloud.google.com/

==== Partie th√©orique

.D√©finition du AI landscape
image:20240417_Devoxx-France_10.jpg[]

* On commence √† diff√©rencier dans l'IA gen "Image Gen" et "LLMs"
    ** Aujourd'hui, on focus sur la partie "LLM"

.Evolution des LLMs depuis l'invention des Transformer par Google en 2017
image:20240417_Devoxx-France_11.jpg[]

-> Encore une fois, on se r√©f√®re aux graphes de *LifeArchitect.ai* pour la comparaison des mod√®les

.Google (Cloud) Lanscape for AI
image:20240417_Devoxx-France_12.jpg[]

* Aujourd'hui : 
    ** Duet AI, Bard -> Gemini
    ** PaLM  (devenu un ancien mod√®le) -> Gemini
    ** MakerSuite -> Google AI Studio

.Gemini is an umbrella brand for Google for all their Gemini products
image:20240417_Devoxx-France_13.jpg[]

* Gemini is a brand AND a model
    ** a multimodal model

.Gemini 1.5 characteristics
image:20240417_Devoxx-France_14.jpg[]

* ET il y a une *version opensource de Gemini* : *Gemma*
    ** qu'on peut utiliser dans son propre cluster Kubernetes
    ** Gemma : open weights model derived from Gemini

* You can use Gemini from *Google AI Studio* or *Vertex AI* in Google Cloud
    ** Google AI Studio and Vertex AI sont 2 produits diff√©rents, bien distincts

* -> Dans ce workshop, nous allons utiliser *Vertex AI* dans Google Cloud.
    ** Et *LangChain4j*

==== Workshop

image:20240417_Devoxx-France_15.jpg[]
image:20240417_Devoxx-France_16.jpg[]

Etape 3 : Preparing your development environment

    * Pas besoin de la version 21 de Java pour ce workshop
    * On va se servir du *Cloud Code Editor* (un VSCode like dans le Cloud)

image:20240417_Devoxx-France_17.jpg[]
image:20240417_Devoxx-France_18.jpg[]

Etape 4 : First call to the Gemini model

image:20240417_Devoxx-France_19.jpg[]

IMPORTANT: les LLMs sont stateless : si on ne fait "rien", par d√©faut les LLMs ne se "souviennent" pas des pr√©c√©dents prompts.

IMPORTANT: M√™me avec une temp√©rature de 0, il n'y a PAS de "vraie" garantie d'avoir le m√™me r√©sultat en appelant 2 fois le m√™me prompt.

Etape 5 : Chat with Gemini

Attention, avec `MessageWindowChatMemory.builder().maxMessages(20)` on peut garder les 20 derniers messages.

Etape 6 : Multimodality with Gemini

Etape 7 : Extract structured information from unstructured text

    * Et l√† on se rend compte d'un des probl√®mes de l'IA gen : +
    Toutes les personnes du workshop ont la m√™me erreur, y compris les speakers : 
+
[source, bash]
----
Exception in thread "main" com.google.gson.JsonSyntaxException: java.lang.IllegalStateException: Expected BEGIN_OBJECT but was STRING at line 1 column 1 path $
        at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:397)
        at com.google.gson.Gson.fromJson(Gson.java:1227)
        at com.google.gson.Gson.fromJson(Gson.java:1137)
        at com.google.gson.Gson.fromJson(Gson.java:1047)
        at com.google.gson.Gson.fromJson(Gson.java:982)
        at dev.langchain4j.internal.GsonJsonCodec.fromJson(GsonJsonCodec.java:66)
        at dev.langchain4j.internal.Json.fromJson(Json.java:79)
        at dev.langchain4j.service.ServiceOutputParser.parse(ServiceOutputParser.java:87)
        at dev.langchain4j.service.DefaultAiServices$1.invoke(DefaultAiServices.java:179)
        at gemini.workshop.$Proxy2.extractPerson(Unknown Source)
        at gemini.workshop.ExtractData.main(ExtractData.java:56)
Caused by: java.lang.IllegalStateException: Expected BEGIN_OBJECT but was STRING at line 1 column 1 path $
        at com.google.gson.stream.JsonReader.beginObject(JsonReader.java:393)
        at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:386)
        ... 10 more

FAILURE: Build failed with an exception.
----

    * -> En fait, le JSON g√©n√©r√© par le LLM doit √™tre "mauvais" depuis aujourd'hui, il doit manquer le tout 1er "{" du doc, d'o√π le "Expected BEGIN_OBJECT but was STRING"
        ** OR, "hier cela marchait" cf les speakers
        ** MAIS il n'y a aucune garantie d'avoir 2 fois le m√™me r√©sultat (completion) avec un LLM, d'o√π le probl√®me

    * "MORALITE" : *importance de la programmation d√©fensive avec un LLM !*
        ** La completion d'hier n'est PAS garantie aujourd'hui, il faut donc S'ASSURER que la completion matche toujours les crit√®res attendus

Etape 8 : Structure prompts with prompt templates

Etape 9 : Text classification with few-shot prompting

Etape 10 : RAG

The document is split in chunks thanks to the DocumentSplitters class. It is going to split the text of the PDF file into snippets of 500 characters, with an overlap of 100 characters (with the following chunk, to avoid cutting words or sentences, in bits and pieces).

Etape 11 : Function calling

=== ------------------------ 12:20 -> 13:30 : LUNCH ------------------------

=== 12:35 -> 12:50 - quickie - Paris 141 : R√©volutionnez votre exp√©rience utilisateur avec les Progressive Web Apps

Pr√©sent√© par Khadija ABDELOUALI de Ippon

.abstract
--
R√©volutionner le monde du web en cr√©ant une nouvelle g√©n√©ration d'applications ¬´ progressives ¬ª et proposer une alternative aux applications natives üì± avec une seule et unique base de code : tel est l'enjeu des PWAs.
Entre l'essor du mobile et l'envol des OS divers et vari√©s, les co√ªts de d√©veloppement pour chaque plateforme üí∂, la consommation des ressources ainsi que la proc√©dure de validation sur les diff√©rents app stores deviennent des challenges primordiaux auxquels il faut apporter une r√©ponse de toute urgenceüö®.
La solution ¬´ Progressive Web App ¬ª apparut ainsi pour la premi√®re fois en 2015 et a depuis √©t√© largement adopt√©e par Starbucks, Pinterest, Uber, ‚Ä¶
Alors, le pari des PWAs a-t-il √©t√© remport√© üèÜ?
üì¢ Pour le savoir, ne manquez surtout pas cette conf√©rence, o√π nous plongerons dans les fondamentaux de cette technologie r√©volutionnaire et d√©couvrirons √©galement comment les PWAs combinent le meilleur des sites web üåê et des applications mobiles üì±, afin d'offrir une exp√©rience utilisateur sans pr√©c√©dent üë®‚Äçüíª.
--

* Les PWA : cr√©√©es par Google en 2015

Avantages : 

    * r√©duction des co√ªts
    * facilit√© de distribution : pas besoin de passer par les stores Google ou Apple
    * disponibilit√©s des ressources : plus de facilit√© √† trouver des devs web (hors mobile)
    * √©conomie d'√©nergie
    * mise √† jour optimis√©es : on ne r√©cup√©re QUE les fichiers mis √† jour, pas la peine de packager une application enti√®re

.Passage de Starbucks d'une application mobile √† une PWA
image:20240417_Devoxx-France_20.jpg[]

image:20240417_Devoxx-France_21.jpg[]

* C'est le *manifest* et le *service worker* de la PWA qui indiquent au navigateur que c'est une "application" qu'il doit installer

.Lighthouse permet d'√©valuer l'ad√©quation de l'application web aux crit√®res techniques pour √™tre une PWA.
image:20240417_Devoxx-France_22.jpg[]
image:20240417_Devoxx-France_23.jpg[]

.Conclusion : l'approche pour savoir si on doit faire une PWA
image:20240417_Devoxx-France_24.jpg[]

=== 13:30 -> 14:15 - conference - Neuilly 252AB : Du Clic √† la Conversation : rempla√ßons boutons et formulaires par un LLM !

Pr√©sent√© par Marie-Alice Blete, Softeam engineer chez Worldline

.abstract
--
Pr√©parez-vous √† voyager dans le domaine de l'interaction homme/machine. 
Vous connaissez la premi√®re r√©volution : la souris et l'interface graphique ? Nous sommes d√©sormais √† l'√®re de la deuxi√®me r√©volution : l'interaction en langage naturel gr√¢ce a l'intelligence artificielle.

Dans cette pr√©sentation, nous allons metamorphoser une application standard en une application bas√©e sur un LLM. Dites adieu aux boutons et formulaires car nous nous appr√™tons √† r√©√©crire les r√®gles de l'interface utilisateur !

Nous d√©buterons par les bases, avec un bref rappel des principes de LLM, suivi d'une premi√®re solution exploitant l'*API OpenAI*. 
Ensuite, nous verrons deux autres solutions plus avanc√©es, dont une comprenant l'utilisation d'agents avec le framework *LangChain*.

√Ä la fin de cette pr√©sentation, vous disposerez de toutes les connaissances n√©cessaires pour vous lancer. Vous aurez √©galement une liste d'astuces, de conseils, ainsi qu'une bonne compr√©hension des √©cueils pour int√©grer des LLM dans vos developpements. Passons du clic √† la conversation !
--

* Les LLMs sont la 2e r√©volution dans l'interaction homme / machine
    ** La 1ere √©tant l'invention de la souris

.LLMs : ceux dispo via une API et ceux √† d√©ployer soi-m√™me
image:20240417_Devoxx-France_25.jpg[]

* Nouveau rappel : les LLMs sont *STATELESS* +
-> Ils ne se "rappellent" les pr√©c√©dentes interactions

.Interaction et conversation
[NOTE]
====
* 1 *interaction* = 1 paire de question / r√©ponse
* 1 *conversation* est un ensemble d'interactions
====

Probl√©matique : remplacer une IHM et toutes ces pop-up nest√©es par un LLM...

NOTE: les demo de Marie-Alice semble √™tre sur "venv" Python

* 1ere solution : *tout remplacer par 1 prompt*

    1. donner le contexte
    2. d√©finir le format de sortie +
    image:20240417_Devoxx-France_26.jpg[]
    image:20240417_Devoxx-France_27.jpg[]
    image:20240417_Devoxx-France_28.jpg[]

    3. donner des instructions pr√©cises
    4. prompt de d√©part

    ** Conclusion : 
        *** pas scalable
        *** confiance ?
        *** maintenance difficile

* 2e solution : *essayer une approche machine √† √©tat*

image:20240417_Devoxx-France_29.jpg[]
image:20240417_Devoxx-France_30.jpg[]

    ** les prompts des transitions vont avoir la partie m√©tier
    ** Et on a DE NOUVEAU un "bug" du LLM o√π le comportement d'aujourd'hui n'est pas celui d'hier, ce qui pose probl√®me

    ** Conclusion : 
        *** XXX
        *** consomme moins de ressources
        *** plus facile √† valider

* 3e solution : *utiliser des agents* (LangChain ici)

image:20240417_Devoxx-France_31.jpg[]

    ** *Gradio* utilis√© ici pour la demo. +
    -> Parfait pour faire de petites demo, MAIS √† ne PAS utiliser en prod...

.Comparaison de ces 3 solutions
image:20240417_Devoxx-France_32.jpg[]

* Dans tous les cas, il FAUT *√©valuer les prompts* !
    ** exemple d'outil : *prompt-foo*

* Autre probl√®me : *ce qui √©tait hier ne sera peut-√™tre plus aujourd'hui...* +
-> Un LLM n'est PAS un syst√®me d√©terministe
    ** Il ne faut pas essayer de le rendre compl√®tement d√©terministe (perte de cr√©ativit√©), mais il faut mettre en place des *process de v√©rification* +
    image:20240417_Devoxx-France_33.jpg[]
    ** Et si √ßa ne marche pas, il faut mettre en place des *strat√©gies de repli* +
    image:20240417_Devoxx-France_34.jpg[]
    ** Exemple de *retry* pour essayer de garantir un "bon" format JSON +
    image:20240417_Devoxx-France_35.jpg[]
    image:20240417_Devoxx-France_36.jpg[]

* Attention au *prompt injection*
    ** mettre un disclaimer car on PEUT se faire "hacker"

* Gestion du *co√ªt*
    ** utiliser un cache pour les questions fr√©quentes
    ** XXX

* Attention √† la confidentialit√© des donn√©es ! 
    ** OpenAI est aux US, voulez-vous, pouvez-vous envoyer les donn√©es de vos clients l√†-bas ?

Conclusion : 

    * de bonnes explications et astuces √† r√©cup√©rer !

.Ressources
image:20240417_Devoxx-France_37.jpg[]

    * Tout le code et les slides sont dispo sur https://github.com/malywut/clicks2conversations

=== 15:40 -> 16:25 - conference - Paris 242AB : Crafting your own RAG system: Leveraging 30+ LLMs for enhanced performance

Pr√©sent√© par Stephan Janssen, cr√©ateur de Devoxx (Belgique, l'original)

.abstract
--
In this talk you'll learn how to set up a RAG (Retrieval-Augmented Generation) system against 30+ different Large Language Models using Java.

We'll show you step-by-step how to ingest documents, choose the best text splitter strategies, find similar documents, answer questions, and create a chatbot.

Then, we'll see how to test and compare different AI models, both from open sources and private ones, and whether they are stored on your own computer or accessed online.
You'll walk away knowing how to setup a well balanced RAG system using Java and the best performing and/or cheapest LLM.
--

* How many talks did Brian Goetz give at Devoxx Belgium ? 
* How many presentation did Brian Goetz give at Devoxx Belgium ? 
    ** eh bien, notre LLM nous donne 2 r√©ponses diff√©rentes...

.Architecture d'un RAG par St√©phane Janssen
image:20240417_Devoxx-France_39.jpg[]

* ReRanker : NON semantic (IA) sort

* LLM providers locally running on your laptop : 
    ** Ollama
    ** LM Studio
    ** GPT4All
    ** Apple MLX

* LLM providers online :
    ** OpenAI
    ** Claude
    ** Groq

image:20240417_Devoxx-France_40.jpg[]

-> Tous sont support√©s par LangChain (√† v√©rifier !)

.St√©phane a d√©velopp√© sa propre BM25 (ReRanker) Java implementation, en 1 we en se faisant aider de ChatGPT et Claude
image:20240417_Devoxx-France_38.jpg[]

* et son impl√©mentation BM25 est gratuite...

.Import Data (Ingestion) : extract data from "content"
image:20240417_Devoxx-France_41.jpg[]

* *To Split or... Not to split* ?!
    ** des contects qui montent maintenant au 1M de tokens...
    ** from 0.10$ to 120$ for 1M tokens
    ** milliseconds to minutes (10 min pour 1M tokens)
    ** Be aware : "context injection" does reduce hallucinations

.Advanced Splitting Strategies
image:20240417_Devoxx-France_42.jpg[]

-> Regarder le talk de *Text Splitting* de *Greg Kamradt* : +
https://www.youtube.com/watch?v=8OJC21T2SL4

* Importance capitale de l'embedding
    ** et plusieurs mod√®les pour faire de l'embedding sont dispo

.Vector Databases
image:20240417_Devoxx-France_43.jpg[]
image:20240417_Devoxx-France_44.jpg[]

* Regarder le tr√®s bon talk sur le Vector DB de *Alexander Chatzizacharias* : +
https://www.youtube.com/watch?v=W-i8bcxkXok

* On ne peut pas utiliser PostgrePG pour de l'embedding avec OpenAI, car il ne supporte que 2000 dimensions quand OpenAI en utilise 3000 (A VERIFIER)

.St√©phane a √©galement d√©velopp√©, car manquant, LangChain4J-cohere (Langchain4J compliant Cohere embedding model)
image:20240417_Devoxx-France_45.jpg[]

    * https://github.com/stephanj/langchain4j-cohere
    * Gemini : "Cohere is a novel approach to representing text data that aims to capture both semantic and syntactic information in a more effective way compared to traditional embedding methods."

.Conclusion and lessons learned
image:20240417_Devoxx-France_46.jpg[]

* Embeddings models have an *input limit*
* the bigger the embedding dimensions the higher the hosting cost
* multi language embedding is a thing
* QUALITY of your embedding influences the QUALITY of your results

* St√©phane a √©crit le plugin "Devoxx Genie" pour IntelliJ

image:20240417_Devoxx-France_47.jpg[]
image:20240417_Devoxx-France_48.jpg[]

-> Et Claude 3 Opus donne apparemment des r√©sultats exceptionnels

image:20240417_Devoxx-France_49.jpg[]

* Ressources GitHub du talk : 
    ** https://github.com/stephanj/rag-genie
    ** https://github.com/devoxx/devoxxgenieIDEAplugin

Conclusion : 

    * Comme Jean-Emmanuel, St√©phane est vraiment impressionnant quand on voit tout ce qu'il arrive √† cr√©er en si peu de temps

=== 17:50 -> 18:20 - tools-in-action - Neuilly 153 : Creating a documentation site for users with AsciiDoc and Antora

Pr√©sent√© par Alexander Schwartz, Principal Software Engineer at Red Hat

.abstract
--
Documentation for a software project is essential for users, administrator and developers alike: Users need to find the right tutorials, reference documentation and answers to their questions, administrators need to know how to install and operator the software, while developers need other documents to get started contributing, and share concepts and architectures for fellow contributors.

The tool Antora simplifies the process by creating documentation websites from AsciiDoc sources stored in Git repositories. Users can browse the generated website and select the version matching the software they use. Navigation outlines, search and cross-references between pages allow users to find answers to their questions. Several open-source software projects like Camel, Debezium and Couchbase use this solution.
For developers it is normal to develop software in collaboration using their IDE and a version control system like Git. The same type of collaboration is possible when all documentation is versioned in a markup-format like AsciiDoc.

This talk presents the basics of an Antora setup and walks through all the steps from editing content in the IDE to updating the documentation site using continuous integration and delivery.
--

URL : https://docs.antora.org

.Sommaire du talk
image:20240417_Devoxx-France_53.jpg[]

1. How users search for informations

    * *Every page is "page one"* : +
    image:20240417_Devoxx-France_50.jpg[]

2. How AsciiDoc and Antora help

    ** Antora provides publishing tools and documentation structure +
    image:20240417_Devoxx-France_51.jpg[]

    ** AsciiDoc is the language, AsciiDoctor is a toolchain 
    image:20240417_Devoxx-France_52.jpg[]

3. Setting up Antora

.Antora structure
image:20240417_Devoxx-France_54.jpg[]

.Antora process
image:20240417_Devoxx-France_55.jpg[]

* Antora va permettre la g√©n√©ration d'un site statique (logique)

1. d√©finition des r√¥les for Antora
2. first steps de configuration d'Antora +
image:20240417_Devoxx-France_56.jpg[]

Conclusion : 

    * Le talk passe pas mal de temps √† pr√©senter AsciiDoc, et je n'arrive pas trop √† voir l'int√©r√™t d'Antora rapport √† AsciiDoc et AsciiDoctor seuls

== JOUR 2 : JEUDI 18/04

=== 09:00 -> 09:25 - Keynote - Amphi bleu : Programming's Greatest Mistakes

Pr√©sent√© par Mark Rendle

.Bio
--
Mark is the founder of RendleLabs, which provides consulting services and workshops to .NET development teams across all industries. His particular obsessions are API design and development, performance, Observability and code-base modernisation. He also uses skills acquired during a few years as a professional stand-up comic to deliver entertaining and informative talks at conferences around the world, and recently learned to play bass so he could join tech parody band The LineBreakers.
--

.abstract
--
Most of the time when we make mistakes in our code, a message gets displayed wrong or an invoice doesn't get sent. But sometimes when people make mistakes in code, things literally explode, or bankrupt companies, or make web development a living hell for millions of programmers for years to come.
 
Join Mark on a tour through some of the worst mistakes in the history of programming. Learn what went wrong, why it went wrong, how much it cost, and how things can be pretty funny when they're not happening to you.
--

* Dans les ann√©es 1950, la m√©moire co√ªtait 1$ pour 1 bit (et pas un byte, bien 1 bit)
    ** dans 1 kilobytes co√ªtait plus de 8 000$...
    ** la m√©moire √©tait "tricot√©e" √† la main par des femmes sur des plaquettes comme la suivante : +
    image:20240418_Devoxx-France_01.jpg[]

=== 09:35 -> 10:00 - Keynote - Amphi bleu : Un monde shoot√© aux m√©taux

Pr√©sent√© par Guillaume Pitron et Agnes Crepet

.Bio
--
* *Guillaume* : √âminent journaliste, auteur et r√©alisateur fran√ßais bas√© √† Paris, Guillaume Pitron est reconnu pour ses essais perspicaces sur les impacts cach√©s des transitions √©nerg√©tique et num√©rique.

* *Agnes* : Agn√®s Crepet est responsable de la long√©vit√© logicielle et de l'informatique chez Fairphone, une entreprise sociale cr√©ant un smartphone √©thique, modulaire et r√©parable.
--

.abstract
--
Dans cette conf√©rence intitul√©e "Un monde shoot√© aux m√©taux", Guillaume Pitron, expert des enjeux g√©opolitiques li√©s aux ressources naturelles, et Agnes Crepet, sp√©cialiste en technologies √©co-responsables, s'unissent pour aborder la d√©pendance croissante de nos soci√©t√©s aux m√©taux rares et ses implications profondes. Ils exploreront comment cette consommation excessive impacte l'environnement, l'√©conomie mondiale et les relations sociales, en d√©voilant les cha√Ænes d'approvisionnement complexes qui relient les mines isol√©es aux technologies quotidiennes. La discussion soulignera les cons√©quences environnementales de l'extraction des m√©taux, les d√©fis √©thiques et les tensions g√©opolitiques qu'elle engendre.
--

* Smartphone : ratio de 1200 / 1 -> si mon t√©l√©phone p√®se 200g, il a fallu 240kg de mati√®res premi√®res pour le fabriquer

* Les m√©taux derri√®re un iPhone, juste les m√©taux, co√ªtent 2‚Ç¨... Juste 2‚Ç¨...
    ** On doit certainement pouvoir faire quelque chose pour mieux exploiter les mines qui sont derri√®re : respect des mineurs, am√©lioration du contexte g√©opolitique (corruption, contrebande, etc.)

* Dur√©e de vie d'un mobile sur la stack Android : 2 √† 3 ans
    ** Ce serait bien si on passait √† 7 √† 8 ans

=== 10:30 -> 11:15 - conference - Paris 143 : Comment Back Market a reconditionn√© sa plateforme en changeant de Cloud Provider

* C'est vrai : BackMarket est bien pass√© de AWS √† GCP
    ** la derni√®re partie de la migration s'√©tant termin√©e hier !

.BackMarket en quelques chiffres
image:20240418_Devoxx-France_02.jpg[]

* infog√©r√©, dans le Cloud, plus de 40 000 containers

*2014 √† 2018*

    * de 5 √† 100 employ√©s en 4 ans
    * infog√©rance totale, qui se passe bien au d√©but, mais au fur et √† mesure de cette croissance rapide, l'infog√©reur n'arrive plus √† suivre +
    -> BackMarket d√©cide donc d'internaliser toute sa plateforme

.Les limites de l'infog√©rance initiale de la plateforme
image:20240418_Devoxx-France_03.jpg[]

* A l'√©poque la bo√Æte va bien, fait de la croissance, mais les OPS s'inqui√®tent...

.La plateforme infog√©r√©e
image:20240418_Devoxx-France_04.jpg[]

    * 2 monolithes, l'un en Django

.La cible sur le Cloud (AWS √† l'√©poque)
image:20240418_Devoxx-France_05.jpg[]

* Strat√©gie : 
    ** internaliser la plateforme (toujours sur AWS, comme l'infog√©reur)
    ** d√©porter sur les edges : CDN + Sec
    ** passage de VMs √† Containers & Kubernetes (K8s)
    ** PAS de make, surtout du *buy*

*Et pourquoi pas GCP alors ???*

* Non, car il faut que la dur√©e de l'internalisation soit de 1 mois MAX
* On veut rester Cloud agnostique

* GCP Engineer : "Vous n'allez pas pouvoir migrer chez nous sans efforts substantiels au niveau de la base de donn√©es"
    ** BackMarket √©tait sur Aurora, dont on devient vite accro √† la latence basse (√† v√©rifier), MAIS qui devient vite gal√®re du c√¥t√© de l'eventual consistency +
    -> A VERIFIER

.Tips pour une migration de ce type
image:20240418_Devoxx-France_06.jpg[]

*De 2018 √† 2023 :*

.Poursuite de la croissance
image:20240418_Devoxx-France_07.jpg[]

.Le c√¥t√© Cloud Agnostic commence √† co√ªter cher, trop cher
image:20240418_Devoxx-France_08.jpg[]

* des K8s clusters self managed -> beaucoup d'op√©rations
* co√ªts de maintenance √©lev√©s
* plateforme d'analytics sur BigQuery, alors que le reste de la plateforme √©tait sur AWS, et on voyait bien que les *co√ªts d'Egress*, acceptables au d√©but allaient devenir un probl√®me

.Architecture en 2023
image:20240418_Devoxx-France_09.jpg[]

    * r√©pliqu√©e sur 3 r√©gions, avec √† chaque fois Prod et NON Prod

*2023* (et l'id√©e de passer chez GCP)

* *Comment changer de trajectoire architecturale et strat√©gique tout en modernisant sa plateforme ?*

* L√† maintenant, on arr√™te d'√™tre Cloud agnostique, et on va adh√©rer au catalogue du Cloud provider
    ** On sait que cela va √™tre davantage un "locked in" chez le Cloud provider choisi

.La strat√©gie et les questions √† se poser pour un changement de Cloud Provider
image:20240418_Devoxx-France_10.jpg[]

    * Strat√©gie : "se d√©cider, convaincre et aligner"

.Une strat√©gie pour la technique ET pour le business (pour v√©rifier la viabilit√© du projet)
image:20240418_Devoxx-France_11.jpg[]

* *Qualification des √©quipes* : on √©tait comp√©tent en AWS, mais pas en GCP
    ** BackMarket a consid√©r√© que ce n'√©tait pas un probl√®me, les concepts du Cloud √©tant consid√©r√© comme similaires
    ** MAIS il est important de ne PAS chercher √† utiliser exactement les m√™mes services d'un Cloud √† l'autre : il faut tenir compte au mieux des sp√©cificit√©s du Cloud Provider et ne pas chercher un matching "1 pour 1"

* Le POC a √©t√© une √©tape cruciale : 
    ** on aurait pas chang√© de Cloud provider sans lui
    ** on aurait pas chang√© sans r√©sultat concluant

.D√©tails du POC
image:20240418_Devoxx-France_12.jpg[]

* Objectif : une PrePROD live sur GCP en *10 jours*
    ** cela semble tellement court vue leur infra !
* Les √©quipes Google ont √©t√© directement sollicit√©es pour ce POC

.Comparaison entre les Cloud Providers AWS et GCP
image:20240418_Devoxx-France_13.jpg[]

* *Engagement durable et √©cologique* : AWS not√© "F" jusqu'en 2020 o√π ils ont arr√™t√© de remplir le questionnaire... Pass√© "B" en 2023
* *Co√ªts* : plus de docs et d'efforts de transparence c√¥t√© Google

.Au final, 8 mois pour la dur√©e totale de la migration
image:20240418_Devoxx-France_14.jpg[]

.La nouvelle plateforme sur GCP (et GCP GKE)
image:20240418_Devoxx-France_15.jpg[]

* plus de MySQL pour le monolithe, passage √† Postgre

.Les conclusions de cette migration
image:20240418_Devoxx-France_16.jpg[]

* Buy buy buy, et make LATER
* Faites un vrai POC, PAS une simple "tech discovery"
* en POC, *TRACEZ* les difficult√©s et d√©cisions, car vous y ferez face plus tard

.C√¥t√© Leadership
image:20240418_Devoxx-France_17.jpg[]

* *Cr√©er une culture du risque !*
* Mettre en place une TPM (Total Productive Maintenance)

*Conclusion* : un REX tr√®s concret, avec beaucoup de bons conseils √† revoir en cas de projet de migration de Cloud Provider üëç

*Q&A*

* *Pourquoi pas Azure ?*
    ** Strat√©gie de "bundleling" de Microsoft
    ** certains outils ne convenaient pas (ne semblaient pas convenir)
    ** utilisateurs de BigQuery depuis 2009, passer sur Azure signifiait conserver les probl√®mes d'Egress ?

* *Pourquoi pas une approche hybride AWS / GCP ?*
    ** De nouveau, pas r√©aliste pour les *co√ªts d'Egress*

* La migration de la partie DB a √©t√© le plus difficile
    
=== 11:35 -> 12:20 - conference - Paris 141 : La recherche √† l'√®re de l'IA

.abstract
--
La recherche ne se contente plus de l'approche maintenant traditionnelle bas√©e sur la fr√©quence des termes (TF/IDF ou BM25) mais plus sur la tendance actuelle du machine learning o√π les nouveaux mod√®les ont ouvert une nouvelle dimension pour la recherche.
Cette conf√©rence donne un aper√ßu de :

    * La recherche "Classique" et ses limitations
    * Qu'est qu'un mod√®le de machine learning et comment vous pouvez l'utiliser
    * Comment utiliser la recherche vectorielle ou la recherche hybride dans Elasticsearch
    * Comment ChatGPT d'OpenAI ou les "large language models" (LLMs) similaires viennent jouer naturellement avec Elastic

Cette session couvre l'√©tat de l'art en mati√®re de recherche de nos jours : BM25, recherche vectorielle, embeddings, recherche hybride, Reciprocal Rank Fusion, int√©gration avec OpenAI... +
La d√©mo principale montre comment g√©n√©rer des embeddings √† partir de musiques puis comment trouver la musique qui s'approche le plus d'une musique que nous fredonnons.
--

.Agenda
image:20240418_Devoxx-France_18.jpg[]

* *Elasticsearch* permet AUSSI de faire de la *recherche vectorielle*

.Qu'est-ce qu'un vecteur ?
image:20240418_Devoxx-France_19.jpg[]
image:20240418_Devoxx-France_20.jpg[]

* L√† on n'a que 2 dimensions, mais on pourrait en avoir plus

.Choice of Embedding Model
image:20240418_Devoxx-France_21.jpg[]

image:20240418_Devoxx-France_22.jpg[]

.Tous les mod√®les support√©s par Elastic
image:20240418_Devoxx-France_23.jpg[]

.Maintenant, comment faire la recherche (Vector Query) ?
image:20240418_Devoxx-France_24.jpg[]

.3 √©tapes pour faire une recherche vectorielle :
image:20240418_Devoxx-France_25.jpg[]

    * search
    * index
    * generate

* Les moyens de trouver les bons vecteurs : 

    ** similarit√© cosinus +
    image:20240418_Devoxx-France_26.jpg[]
    image:20240418_Devoxx-France_27.jpg[]

    ** longueur du vecteur : dot_product +
    image:20240418_Devoxx-France_28.jpg[]

    ** distance euclidienne
    image:20240418_Devoxx-France_29.jpg[]

    ** une approche un peu diff√©rente : HNSW
    image:20240418_Devoxx-France_30.jpg[]

.Filtering KNN Vector Similarity
image:20240418_Devoxx-France_31.jpg[]

* -> Elastic supporte maintenant 4096 dimensions
    ** MAIS cela consomme beaucoup de ressources !

.Les bonnes pratiques de recherche vectorielle
image:20240418_Devoxx-France_32.jpg[]

.Recherche hybride
image:20240418_Devoxx-France_33.jpg[]

.ELSER
image:20240418_Devoxx-France_34.jpg[]
image:20240418_Devoxx-France_35.jpg[]

*Ranking* : RRF (Reciprocal Rank Fusion)

image:20240418_Devoxx-France_36.jpg[]

DEMO

* sur le th√®me de la musique, David adore mixer üòâ

.Architecture de la demo
image:20240418_Devoxx-France_37.jpg[]

* repo GitHub : https://github.com/dadoonet/music-search

.ET ChatGPT et la gen AI sont arriv√©s...
image:20240418_Devoxx-France_38.jpg[]

.ChatGPT et les LLM -> "une" r√©ponse
image:20240418_Devoxx-France_39.jpg[]

.RAG -> "la bonne r√©ponse" (car on va la chercher dans les "bonnes" donn√©es)
image:20240418_Devoxx-France_40.jpg[]

.En conclusion, de quoi avons-nous besoin pour faire de la recherche s√©mantique ?
image:20240418_Devoxx-France_41.jpg[]

-> *Elasticsearch* permet AUSSI de faire de la *recherche s√©mantique*

Ressources : 

    * slides de la pr√©sentation : https://speaker.pilato.fr/WlpZdt

Conclusion : 

    * Super talk, dense avec comme d'habitude un David tr√®s fluide et qui ma√Ætrise le sujet üëç
    * A revoir "calmement" car cela allait vite üòÖ

=== ------------------------ 12:20 -> 13:30 : LUNCH ------------------------

=== 12:35 -> 12:50 - quicky - Paris 242AB : Je d√©l√®gue tous mes tests √† une IA

=== 12:35 -> 12:50 - quicky - Maillot : C4 model, la solution pour standardiser mes sch√©mas d'architecture ?

=== 13:30 -> 16:30 - Deep Dive - Neuilly 251 : Construire son assistant Intelligent avec Hugging Face et Elasticsearch

=== 17:00 -> 18:30 - other - Neuilly 253 : Toutes et tous les mercenaires de DevOps !









