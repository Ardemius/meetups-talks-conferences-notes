= Devoxx France 2024
Thomas SCHWENDER <icon:github[] https://github.com/Ardemius/[GitHub] / icon:twitter[role="aqua"] https://twitter.com/thomasschwender[@thomasschwender]>
// Handling GitHub admonition blocks icons
ifndef::env-github[:icons: font]
ifdef::env-github[]
:status:
:outfilesuffix: .adoc
:caution-caption: :fire:
:important-caption: :exclamation:
:note-caption: :paperclip:
:tip-caption: :bulb:
:warning-caption: :warning:
endif::[]
:imagesdir: ./images
:source-highlighter: highlightjs
:highlightjs-languages: asciidoc
// We must enable experimental attribute to display Keyboard, button, and menu macros
:experimental:
// Next 2 ones are to handle line breaks in some particular elements (list, footnotes, etc.)
:lb: pass:[<br> +]
:sb: pass:[<br>]
// check https://github.com/Ardemius/personal-wiki/wiki/AsciiDoctor-tips for tips on table of content in GitHub
:toc: macro
:toclevels: 2
// To number the sections of the table of contents
//:sectnums:
// Add an anchor with hyperlink before the section title
:sectanchors:
// To turn off figure caption labels and numbers
:figure-caption!:
// Same for examples
//:example-caption!:
// To turn off ALL captions
// :caption:

toc::[]

Programme du salon : https://mobile.devoxx.com/events/devoxxfr2024/schedule

== JOUR 1 : MERCREDI 17/04

=== 09:00 -> 09:25 - Keynote - Amphi bleu : Bienvenue Ã  Devoxx France 2024

image:20240417_Devoxx-France_00.jpg[]

=== 09:35 -> 10:00 - keynote - Amphi bleu : IA en mÃ©decine : oÃ¹ en sommes-nous ?

PrÃ©sentÃ© par Jean-Emmanuel Bibault

.biographie
--
Jean-Emmanuel est mÃ©decin cancÃ©rologue et chercheur spÃ©cialisÃ© en Intelligence Artificielle. 
Il a un doctorat en informatique biomÃ©dicale et a rÃ©alisÃ© un post-doctorat Ã  l'UniversitÃ© de Stanford, dans le laboratoire d'Intelligence Artificielle appliquÃ©e Ã  la SantÃ©. 
Il est Professeur des UniversitÃ©s - Praticien Hospitalier Ã  l'UniversitÃ© de Paris / HÃ´pital EuropÃ©en Georges Pompidou et chercheur Ã  l'INSERM. Ses recherches portent sur l'apprentissage machine appliquÃ© au diagnostic et Ã  la prÃ©diction. 

Il est laurÃ©at 2019 de l'AcadÃ©mie Nationale de MÃ©decine pour ses travaux sur la prÃ©diction de la rÃ©ponse thÃ©rapeutique par Intelligence Artificielle. Il a par ailleurs dÃ©veloppÃ© plusieurs applications iPhone et Android et cofondÃ© une startup dans ce domaine, revendue en 2014.

En 2023, il a publiÃ© "2041, L'OdyssÃ©e de la mÃ©decine" aux Editions Equateurs, livre qui raconte comment l'IA en mÃ©decine est nÃ©e et comment elle a et va changer les soins.
--

.abstract
--
Les techniques de machine learning sont actuellement utilisÃ©es pour entraÃ®ner de nombreux modÃ¨les en mÃ©decine. Pourquoi connaissons-nous un tel Ã¢ge d'or de l'IA appliquÃ©e Ã  la mÃ©decine ? 

Cette prÃ©sentation illustrera l'utilisation de l'IA par diffÃ©rents exemples publiÃ©s : prÃ©diction du risque de dÃ©velopper un risque 5 ans Ã  l'avance, interprÃ©tation automatisÃ©e d'image mÃ©dicale, dÃ©tection par Deep Learning de mÃ©lanome, prÃ©diction de la survie sur simple scanner, pilotage de robots chirurgicaux, dÃ©pistage de la dÃ©pression sur instagram, chaque exemple sera expliquÃ© et commentÃ©. Mais l'IA comporte Ã©galement des risques liÃ©s Ã  la gestion des donnÃ©es d'entraÃ®nement, aux biais ou encore les attaques adversarielles. Les perspectives de dÃ©veloppement Ã  10 Ã  15 ans seront enfin abordÃ©es pour comprendre comment l'IA va changer la santÃ© de tous.
--

* "Intelligence" en anglais ne se traduit en fait PAS par "intelligence" en franÃ§ais, mais plutÃ´t par "capacitÃ© de renseignement"

.AccÃ©lÃ©ration de l'IA depuis 1940
image:20240417_Devoxx-France_04.jpg[]

.Toutes les donnÃ©es mÃ©dicales suivantes sont maintenant digitalisÃ©es
image:20240417_Devoxx-France_05.jpg[]

* Parmi les frameworks d'IA les plus utilisÃ©s : 
    1. Pytorch
    2. TensorFlow
    3. Scikit-learn

-> Tous sont amÃ©ricains...

* Actuellement les donnÃ©es mÃ©dicales sont encore TRES mal structurÃ©es 
    ** Encore BEAUCOUP de travail Ã  ce niveau    

* *XGBoost* : LE framework pour l'analyse de donnÃ©es tabulaires

* Quand on parle d'*analyse d'images*, il est tout le temps question de *Deep Learning*

* Algo / papier de Stanford sur un scan de peau (mÃ©lanome) et l'IA donne de meilleurs rÃ©sultats que les 21 dermatologues auxquels elle Ã©tait comparÃ©e.

* Sous 10 15 ans, on aura des opÃ©rations mÃ©dicales, parmi les plus simples, qui seront totalement automatisÃ©es.

.L'IA gÃ©nÃ©rative fait de plus en plus "mieux" que les mÃ©decins
image:20240417_Devoxx-France_06.jpg[]

* *Y COMPRIS pour l'empathie* que "simule" l'IA (qui est meilleure que son gÃ©nÃ©raliste quand on le consulte tard le soir une fois qu'il est crevÃ© d'avoir vu 50 patients...)

.Generative adversarial networks (GANs)
image:20240417_Devoxx-France_07.jpg[]

* On se retrouve avec l'empoisonnement de donnÃ©es Ã  la Glaze, auquel il va falloir faire TRES attention dans le milieu mÃ©dical -> TOUJOURS vÃ©rifier ses donnÃ©es !

* Au Japon, via un rÃ©seau neuronal, on commence Ã  arriver Ã  *"lire dans les pensÃ©es"* ET CA MARCHE ! ðŸ¤¯
    ** Donc petits problÃ¨mes Ã  prÃ©voir d'interrogatoire non consentis et trÃ¨s efficaces...

Donc, pour l'avenir : le mÃ©decin artificiel

image:20240417_Devoxx-France_08.jpg[]

*Q&A :* 

* Jean-Emmanuel : *le meilleur des tests* (pour Ã©viter des biais par exemple) est (et restera probablement) l'*essai clinique*.
    ** la FAC d'Emmanuel est la 1ere Ã  avoir un DU d'IA en santÃ©, MAIS ce n'est pas une formation obligatoire
    ** Mais on a un problÃ¨me sur la formation des Ã©tudiants en mÃ©decine aujourd'hui, qui seront mÃ©decins dans 10 ans, et qui ne seront pas ou pas suffisamment formÃ©s Ã  l'IA alors qu'elle sera partout autour d'eux.

* Enorme risque de perte de connaissances en mÃªme temps que l'IA va "aider" les mÃ©decins
    ** Comme pour les pilotes de ligne, il va y avoir des Ã©preuves oÃ¹ ils vont Ãªtre testÃ©s SEULS, sans pouvoir Ãªtre aider par l'IA.

Conclusion : 

    * Jean-Emmanuel est un gÃ©nie... Comment peut-on rÃ©ussir Ã  faire autant de choses
    * sujet maÃ®trisÃ© techniquement de bout en bout, aucune hÃ©sitation Ã  l'oral, des dÃ©tails, un sans faute, l'un des meilleurs orateurs que j'ai jamais entendu ðŸ‘

=== 10:30 -> 12:30 - Hands-on Lab - Neuilly 253 : Hands-on Gemini, the Google DeepMind LLM

* PrÃ©sentÃ© par Google : Mete Atamel, Valentin Deleplace
    ** Le workshop a Ã©tÃ© conÃ§u par Guillaume LAFORGE
    ** Tous les 3 sont developer advocates chez Google

.abstract
--
In this hands-on workshop, you will get to code using Gemini, the new Large Language Model from Google DeepMind. 

You will first start by familiarizing yourself with the model's capabilities. Then you will use Gemini in different concrete cases, such as extracting data from unstructured text, document classification, but also searching your own documents, or how to supplement the model by integrating the call to external APIs.

The workshop will be conducted using the Java language and the LangChain4j library. Come equipped with a laptop. We will code together in the cloud, no need for any special installation on your machine.
--

.Ressources pour le Hands-on Lab
image:20240417_Devoxx-France_09.jpg[]

    * URL : https://bit.ly/gemini-devoxx-2024
        ** codelab : https://codelabs.developers.google.com/codelabs/gemini-java-developers
        ** repo : https://github.com/glaforge/gemini-workshop-for-java-developers/tree/main
        ** Google Cloud Console : https://console.cloud.google.com/

==== Partie thÃ©orique

.DÃ©finition du AI landscape
image:20240417_Devoxx-France_10.jpg[]

* On commence Ã  diffÃ©rencier dans l'IA gen "Image Gen" et "LLMs"
    ** Aujourd'hui, on focus sur la partie "LLM"

.Evolution des LLMs depuis l'invention des Transformer par Google en 2017
image:20240417_Devoxx-France_11.jpg[]

-> Encore une fois, on se rÃ©fÃ¨re aux graphes de *LifeArchitect.ai* pour la comparaison des modÃ¨les

.Google (Cloud) Lanscape for AI
image:20240417_Devoxx-France_12.jpg[]

* Aujourd'hui : 
    ** Duet AI, Bard -> Gemini
    ** PaLM  (devenu un ancien modÃ¨le) -> Gemini
    ** MakerSuite -> Google AI Studio

.Gemini is an umbrella brand for Google for all their Gemini products
image:20240417_Devoxx-France_13.jpg[]

* Gemini is a brand AND a model
    ** a multimodal model

.Gemini 1.5 characteristics
image:20240417_Devoxx-France_14.jpg[]

* ET il y a une *version opensource de Gemini* : *Gemma*
    ** qu'on peut utiliser dans son propre cluster Kubernetes
    ** Gemma : open weights model derived from Gemini

* You can use Gemini from *Google AI Studio* or *Vertex AI* in Google Cloud
    ** Google AI Studio and Vertex AI sont 2 produits diffÃ©rents, bien distincts

* -> Dans ce workshop, nous allons utiliser *Vertex AI* dans Google Cloud.
    ** Et *LangChain4j*

==== Workshop

image:20240417_Devoxx-France_15.jpg[]
image:20240417_Devoxx-France_16.jpg[]

Etape 3 : Preparing your development environment

    * Pas besoin de la version 21 de Java pour ce workshop
    * On va se servir du *Cloud Code Editor* (un VSCode like dans le Cloud)

image:20240417_Devoxx-France_17.jpg[]
image:20240417_Devoxx-France_18.jpg[]

Etape 4 : First call to the Gemini model

image:20240417_Devoxx-France_19.jpg[]

IMPORTANT: les LLMs sont stateless : si on ne fait "rien", par dÃ©faut les LLMs ne se "souviennent" pas des prÃ©cÃ©dents prompts.

IMPORTANT: MÃªme avec une tempÃ©rature de 0, il n'y a PAS de "vraie" garantie d'avoir le mÃªme rÃ©sultat en appelant 2 fois le mÃªme prompt.

Etape 5 : Chat with Gemini

Attention, avec `MessageWindowChatMemory.builder().maxMessages(20)` on peut garder les 20 derniers messages.

Etape 6 : Multimodality with Gemini

Etape 7 : Extract structured information from unstructured text

    * Et lÃ  on se rend compte d'un des problÃ¨mes de l'IA gen : +
    Toutes les personnes du workshop ont la mÃªme erreur, y compris les speakers : 
+
[source, bash]
----
Exception in thread "main" com.google.gson.JsonSyntaxException: java.lang.IllegalStateException: Expected BEGIN_OBJECT but was STRING at line 1 column 1 path $
        at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:397)
        at com.google.gson.Gson.fromJson(Gson.java:1227)
        at com.google.gson.Gson.fromJson(Gson.java:1137)
        at com.google.gson.Gson.fromJson(Gson.java:1047)
        at com.google.gson.Gson.fromJson(Gson.java:982)
        at dev.langchain4j.internal.GsonJsonCodec.fromJson(GsonJsonCodec.java:66)
        at dev.langchain4j.internal.Json.fromJson(Json.java:79)
        at dev.langchain4j.service.ServiceOutputParser.parse(ServiceOutputParser.java:87)
        at dev.langchain4j.service.DefaultAiServices$1.invoke(DefaultAiServices.java:179)
        at gemini.workshop.$Proxy2.extractPerson(Unknown Source)
        at gemini.workshop.ExtractData.main(ExtractData.java:56)
Caused by: java.lang.IllegalStateException: Expected BEGIN_OBJECT but was STRING at line 1 column 1 path $
        at com.google.gson.stream.JsonReader.beginObject(JsonReader.java:393)
        at com.google.gson.internal.bind.ReflectiveTypeAdapterFactory$Adapter.read(ReflectiveTypeAdapterFactory.java:386)
        ... 10 more

FAILURE: Build failed with an exception.
----

    * -> En fait, le JSON gÃ©nÃ©rÃ© par le LLM doit Ãªtre "mauvais" depuis aujourd'hui, il doit manquer le tout 1er "{" du doc, d'oÃ¹ le "Expected BEGIN_OBJECT but was STRING"
        ** OR, "hier cela marchait" cf les speakers
        ** MAIS il n'y a aucune garantie d'avoir 2 fois le mÃªme rÃ©sultat (completion) avec un LLM, d'oÃ¹ le problÃ¨me

    * "MORALITE" : *importance de la programmation dÃ©fensive avec un LLM !*
        ** La completion d'hier n'est PAS garantie aujourd'hui, il faut donc S'ASSURER que la completion matche toujours les critÃ¨res attendus

Etape 8 : Structure prompts with prompt templates

Etape 9 : Text classification with few-shot prompting

Etape 10 : RAG

The document is split in chunks thanks to the DocumentSplitters class. It is going to split the text of the PDF file into snippets of 500 characters, with an overlap of 100 characters (with the following chunk, to avoid cutting words or sentences, in bits and pieces).

Etape 11 : Function calling

=== -------- 12:20 -> 13:30 : LUNCH --------

=== 12:35 -> 12:50 - quickie - Paris 141 : RÃ©volutionnez votre expÃ©rience utilisateur avec les Progressive Web Apps

PrÃ©sentÃ© par Khadija ABDELOUALI de Ippon

.abstract
--
RÃ©volutionner le monde du web en crÃ©ant une nouvelle gÃ©nÃ©ration d'applications Â« progressives Â» et proposer une alternative aux applications natives ðŸ“± avec une seule et unique base de code : tel est l'enjeu des PWAs.
Entre l'essor du mobile et l'envol des OS divers et variÃ©s, les coÃ»ts de dÃ©veloppement pour chaque plateforme ðŸ’¶, la consommation des ressources ainsi que la procÃ©dure de validation sur les diffÃ©rents app stores deviennent des challenges primordiaux auxquels il faut apporter une rÃ©ponse de toute urgenceðŸš¨.
La solution Â« Progressive Web App Â» apparut ainsi pour la premiÃ¨re fois en 2015 et a depuis Ã©tÃ© largement adoptÃ©e par Starbucks, Pinterest, Uber, â€¦
Alors, le pari des PWAs a-t-il Ã©tÃ© remportÃ© ðŸ†?
ðŸ“¢ Pour le savoir, ne manquez surtout pas cette confÃ©rence, oÃ¹ nous plongerons dans les fondamentaux de cette technologie rÃ©volutionnaire et dÃ©couvrirons Ã©galement comment les PWAs combinent le meilleur des sites web ðŸŒ et des applications mobiles ðŸ“±, afin d'offrir une expÃ©rience utilisateur sans prÃ©cÃ©dent ðŸ‘¨â€ðŸ’».
--

* Les PWA : crÃ©Ã©es par Google en 2015

Avantages : 

    * rÃ©duction des coÃ»ts
    * facilitÃ© de distribution : pas besoin de passer par les stores Google ou Apple
    * disponibilitÃ©s des ressources : plus de facilitÃ© Ã  trouver des devs web (hors mobile)
    * Ã©conomie d'Ã©nergie
    * mise Ã  jour optimisÃ©es : on ne rÃ©cupÃ©re QUE les fichiers mis Ã  jour, pas la peine de packager une application entiÃ¨re

.Passage de Starbucks d'une application mobile Ã  une PWA
image:20240417_Devoxx-France_20.jpg[]

image:20240417_Devoxx-France_21.jpg[]

* C'est le *manifest* et le *service worker* de la PWA qui indiquent au navigateur que c'est une "application" qu'il doit installer

.Lighthouse permet d'Ã©valuer l'adÃ©quation de l'application web aux critÃ¨res techniques pour Ãªtre une PWA.
image:20240417_Devoxx-France_22.jpg[]
image:20240417_Devoxx-France_23.jpg[]

.Conclusion : l'approche pour savoir si on doit faire une PWA
image:20240417_Devoxx-France_24.jpg[]

=== 13:30 -> 14:15 - conference - Neuilly 252AB : Du Clic Ã  la Conversation : remplaÃ§ons boutons et formulaires par un LLM !

PrÃ©sentÃ© par Marie-Alice Blete, Softeam engineer chez Worldline

.abstract
--
PrÃ©parez-vous Ã  voyager dans le domaine de l'interaction homme/machine. 
Vous connaissez la premiÃ¨re rÃ©volution : la souris et l'interface graphique ? Nous sommes dÃ©sormais Ã  l'Ã¨re de la deuxiÃ¨me rÃ©volution : l'interaction en langage naturel grÃ¢ce a l'intelligence artificielle.

Dans cette prÃ©sentation, nous allons metamorphoser une application standard en une application basÃ©e sur un LLM. Dites adieu aux boutons et formulaires car nous nous apprÃªtons Ã  rÃ©Ã©crire les rÃ¨gles de l'interface utilisateur !

Nous dÃ©buterons par les bases, avec un bref rappel des principes de LLM, suivi d'une premiÃ¨re solution exploitant l'*API OpenAI*. 
Ensuite, nous verrons deux autres solutions plus avancÃ©es, dont une comprenant l'utilisation d'agents avec le framework *LangChain*.

Ã€ la fin de cette prÃ©sentation, vous disposerez de toutes les connaissances nÃ©cessaires pour vous lancer. Vous aurez Ã©galement une liste d'astuces, de conseils, ainsi qu'une bonne comprÃ©hension des Ã©cueils pour intÃ©grer des LLM dans vos developpements. Passons du clic Ã  la conversation !
--

* Les LLMs sont la 2e rÃ©volution dans l'interaction homme / machine
    ** La 1ere Ã©tant l'invention de la souris

.LLMs : ceux dispo via une API et ceux Ã  dÃ©ployer soi-mÃªme
image:20240417_Devoxx-France_25.jpg[]

* Nouveau rappel : les LLMs sont *STATELESS* +
-> Ils ne se "rappellent" les prÃ©cÃ©dentes interactions

.Interaction et conversation
[NOTE]
====
* 1 *interaction* = 1 paire de question / rÃ©ponse
* 1 *conversation* est un ensemble d'interactions
====

ProblÃ©matique : remplacer une IHM et toutes ces pop-up nestÃ©es par un LLM...

NOTE: les demo de Marie-Alice semble Ãªtre sur "venv" Python

* 1ere solution : *tout remplacer par 1 prompt*

    1. donner le contexte
    2. dÃ©finir le format de sortie +
    image:20240417_Devoxx-France_26.jpg[]
    image:20240417_Devoxx-France_27.jpg[]
    image:20240417_Devoxx-France_28.jpg[]

    3. donner des instructions prÃ©cises
    4. prompt de dÃ©part

    ** Conclusion : 
        *** pas scalable
        *** confiance ?
        *** maintenance difficile

* 2e solution : *essayer une approche machine Ã  Ã©tat*

image:20240417_Devoxx-France_29.jpg[]
image:20240417_Devoxx-France_30.jpg[]

    ** les prompts des transitions vont avoir la partie mÃ©tier
    ** Et on a DE NOUVEAU un "bug" du LLM oÃ¹ le comportement d'aujourd'hui n'est pas celui d'hier, ce qui pose problÃ¨me

    ** Conclusion : 
        *** XXX
        *** consomme moins de ressources
        *** plus facile Ã  valider

* 3e solution : *utiliser des agents* (LangChain ici)

image:20240417_Devoxx-France_31.jpg[]

    ** *Gradio* utilisÃ© ici pour la demo. +
    -> Parfait pour faire de petites demo, MAIS Ã  ne PAS utiliser en prod...

.Comparaison de ces 3 solutions
image:20240417_Devoxx-France_32.jpg[]

* Dans tous les cas, il FAUT *Ã©valuer les prompts* !
    ** exemple d'outil : *prompt-foo*

* Autre problÃ¨me : *ce qui Ã©tait hier ne sera peut-Ãªtre plus aujourd'hui...* +
-> Un LLM n'est PAS un systÃ¨me dÃ©terministe
    ** Il ne faut pas essayer de le rendre complÃ¨tement dÃ©terministe (perte de crÃ©ativitÃ©), mais il faut mettre en place des *process de vÃ©rification* +
    image:20240417_Devoxx-France_33.jpg[]
    ** Et si Ã§a ne marche pas, il faut mettre en place des *stratÃ©gies de repli* +
    image:20240417_Devoxx-France_34.jpg[]
    ** Exemple de *retry* pour essayer de garantir un "bon" format JSON +
    image:20240417_Devoxx-France_35.jpg[]
    image:20240417_Devoxx-France_36.jpg[]

* Attention au *prompt injection*
    ** mettre un disclaimer car on PEUT se faire "hacker"

* Gestion du *coÃ»t*
    ** utiliser un cache pour les questions frÃ©quentes
    ** XXX

* Attention Ã  la confidentialitÃ© des donnÃ©es ! 
    ** OpenAI est aux US, voulez-vous, pouvez-vous envoyer les donnÃ©es de vos clients lÃ -bas ?

Conclusion : 

    * de bonnes explications et astuces Ã  rÃ©cupÃ©rer !

.Ressources
image:20240417_Devoxx-France_37.jpg[]

    * Tout le code et les slides sont dispo sur https://github.com/malywut/clicks2conversations

=== 15:40 -> 16:25 - conference - Paris 242AB : Crafting your own RAG system: Leveraging 30+ LLMs for enhanced performance



=== 17:00 -> 17:30 - tools-in-action


==== Notes













