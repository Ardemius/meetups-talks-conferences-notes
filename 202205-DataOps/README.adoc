= DataOps.Rocks by Saagie 2022/05/24
Thomas SCHWENDER <icon:github[] https://github.com/Ardemius/[GitHub] / icon:twitter[role="aqua"] https://twitter.com/thomasschwender[@thomasschwender]>
// Handling GitHub admonition blocks icons
ifndef::env-github[:icons: font]
ifdef::env-github[]
:status:
:outfilesuffix: .adoc
:caution-caption: :fire:
:important-caption: :exclamation:
:note-caption: :paperclip:
:tip-caption: :bulb:
:warning-caption: :warning:
endif::[]
:imagesdir: ./images
:source-highlighter: highlightjs
:highlightjs-languages: asciidoc
// We must enable experimental attribute to display Keyboard, button, and menu macros
:experimental:
// Next 2 ones are to handle line breaks in some particular elements (list, footnotes, etc.)
:lb: pass:[<br> +]
:sb: pass:[<br>]
// check https://github.com/Ardemius/personal-wiki/wiki/AsciiDoctor-tips for tips on table of content in GitHub
:toc: macro
:toclevels: 2
// To number the sections of the table of contents
//:sectnums:
// Add an anchor with hyperlink before the section title
:sectanchors:
// To turn off figure caption labels and numbers
:figure-caption!:
// Same for examples
//:example-caption!:
// To turn off ALL captions
// :caption:

toc::[]

== Présentation du salon

.DataOps.Rocks Summit
--
Qu'est-ce que c'est ? +
*DataOps.Rocks Summit* est l'événement dédié aux professionnels du marché Big Data & Analytics pour échanger bonnes pratiques, expériences et tendances futures du secteur, qu'ils soient décideurs, data guys ou éditeurs de logiciel ! +
Après une édition 100% virtuelle en 2021, nous aurons le plaisir de vous retrouver en présentiel le 24 mai au Ground Control !

Trois thématiques phares seront prévues lors de cette édition :

    * Souveraineté
    * Business & Stratégie
    * Tech
--

Infos pratiques :  

    * https://summit-2022.dataops.rocks/, le 24/05/2022 au https://goo.gl/maps/Xm36YP3EYFMKxN6XA[Ground Control] à Paris.
    * *Programme* : https://summit-2022.dataops.rocks/programme

== 09h30 -> 09h40 - Souveraineté : Introduction - DataOps.Rocks Summit 2022

By Jérôme Trédan (Saagie, CEO)

* Présentation de Saagie : 
    ** Les "data guys" ne travaillent pas facilement ensemble (Data scientists, data engineer, data stewart, etc.)
    ** Initialement Saagie a voulu créer une plateforme pour "fédérer" les différentes briques de la Data.

Fil rouge de la conférence : la *souveraineté*

== 09h40 -> 10h25 - Souveraineté : Les conditions de la Souveraineté Numérique

.Abstract
----
A l'ère de la transition numérique, les données sont au cœur des stratégies de développement. Dès lors, savoir garantir la protection des données (personnelles ou sensibles), savoir les maîtriser est un enjeu majeur pour les entreprises. Cependant, faut-il uniquement se reposer sur des technologies européennes ? Peut-on tirer profit de l'existant pour mieux répondre aux enjeux de demain ? Durant cette session, nous tenteront d'apporter des éléments de réponse sans tabou ! 

Cette session sera animée par Sébastien Couasnon, aux côtés de nos intervenants :
- Jérôme Trédan - CEO de Saagie
- Yann Lechelle - CEO de Scaleway
- Thomas Solignac - CEO & Co-Founder de Golem.ai
- Renaud Allioux - CTO & Co-Founder de Preligens
- Arnaud Coustillière - Président du Pôle Excellence Cyber (responsable de la cyberdéfense du ministère de la Défense)
----

* Yann : Actuellement, pas de souveraineté en Europe : "non souveraineté"
    ** On part de très très bas, on ne peut donc que progresser
    ** Donc comment passe-t-on de "rien" à "un peu de souveraineté"

* Thomas : Golem, traitement automatique de mails & docs via IA
    ** https://golem.ai/fr/
    ** domaine du traitement automatique du langage
    ** rupture technologique
    ** réflexion green / ecoconception : Golem a été pensé pour utiliser le minimum de Data (pour un impact carbone le plus bas possible)

* Arnaud : 
    ** plutôt que de souveraineté, parlons de *liberté stratégique*
    ** les lois américaines "s'exportent" à l'international (Cloud Act, Patriot Act)
        *** C'est dans ce milieu qu'il faut se débattre afin que la richesse ne soit pas captée exclusivement par ces acteurs (cite les affaires Alstom, Bad Secure)

* Renaud
    ** Preligens : 100% du business pour la Défense et le renseignement, rien dans le civil
    ** Il faut être "bon" techniquement avant tout, et on arrive à être bon en France
        *** Preligens est (bien) devant ses concurrents américains
        *** use cases : détection, classification d'objets sur imagerie satellite
    ** France et Défense : un des leaders europééns, MAIS un petit pousset à l'échelle du monde
    ** Preligens : ~30 millions € de levés
        *** Pas une si grosse levée que cela, MAIS suffisant pour le moment ("capital efficient")

* Yann : 
    ** AWS se vante "d'avoir 75% des Scale-up françaises"
        *** C'est un problème, car le "socle" de nos sociétés est déjà à l'étranger
        *** même si leurs produits sont bons, c'est un souci
    ** "coup d'accordéon" à venir dans le milieu (capital risk du fait du contexte), donc les entreprises vont plus facilement se "brader"
        *** nos entreprises doivent donc se construire sur des bases solides (et là on est déjà "vassalisé")
    ** les acteurs mondiaux achètent pour seulement 1% de techno françaises (à vérifier)
        *** quand Yann dit que "on est rien"

* Jérôme : 
    ** "low fair" (protectionnisme) très présent côté américain et chinois
        *** on a fait un peu ça aussi avec RGPD

* Arnaud : 
    ** pense qu'on a régressé sur les gros chantiers, plus rien depuis 20 ans et les gros projets franco-allemands (rechercher la nature des projets en question)
    ** *les grands acteurs américains sont établis sur le marché*

* Yann : 
    ** Bleu (Cap et Orange) travaillent sur un Cloud de confiance qui "devrait", "à terme" être SecNumCloud, alors qu'il s'appuie sur Microsoft Azure.
        *** Notre problème est que l'on préfère en France faire des plans sur Bleu plutôt que favoriser nos acteurs locaux pourtant très bons (Scaleways, OVH)
    ** *les américains maintiennent le "mythe" comme quoi nous sommes 10 ans* en retard sur le domaine de l'hébergement, c'est complètement faux 
        *** on a peut-être moins de produits, mais ceux qu'on a répondent à 80% des use cases
    ** *Le cloud est un milieu où être "établi" est un très gros avantage* pour adresser le marché
        *** Or ce sont les grands groupes américains qui sont justement établis

* Renaud : 
    ** *les ESN ne sont pas les bons acteurs pour créer un Cloud souverain.*
        *** Soyons clairs, Renaud dit à demi-mots qu'ils n'ont pas le niveau (ou pas un niveau suffisant en tout cas)
        *** Il faudrait plutôt aller voir des gens comme Scaleways, OVH dont c'est le "vrai" métier

* Thomas : 
    ** anecdote pour Golem.ai : face à un investisseur quant à Golem "Nan, je ne vous crois, Google l'aurait déjà fait...". Ben sauf que non...
    ** *On arrive à faire mieux que les américains*, et parfois avec beaucoup moins, *ce n'est pas QUE une question de moyens*
        *** Alors attention, avoir des moyens est indispensable pour passer à l'échelle
        *** Mais ne pas en avoir n'est pas une "condamnation" pour le développement d'un produit
        *** La conclusion est surtout que les américains ne sont pas les seuls qui créent les techno qui marchent.

* Yann : les acteurs américains dominants ont *"formaté la matrice"*
    ** il ne faut pas réinventer la roue (pas possible), et s'appuyer sur le socle de ces acteurs pour ensuite proposer autre chose
        *** et choisir des acteurs locaux pour vos projets

== 10h30 -> 11h00 - Tech : Focus sur les tendances technos et data 2022

by Jonathan Pivert (Saagie), Victor Leroux (Saagie), Leshanshui Yang (Saagie)

.Abstract
----
A quoi faut-il s'attendre en 2022 sur le marché technos et data ? Leshansui Yang, Data Scientist & PhD Student, Victor Leroux, Product Marketing Manager et Jonathan Pivert, Product Manager chez Saagie feront un état des lieux des tendances technologiques et data émergentes à ne pas louper en 2022 !
----

.common causes of data bias
image:20220524_dataops_01.jpg[]

.QU'est-ce qu'un biais en ML ?
image:20220524_dataops_02.jpg[]

* L'un des principaux travaux des *data scientists* consiste à *réduire ces biais*
* les humains peuvent choisir d'ignorer un biais, mais ce n'est pas le cas des data

Saagie : 

    * 4 data scientists en R&D à temps plein
    * et 3 thèses en cours

.Choix des stacks : beaucoup (trop) de choix
image:20220524_dataops_03.jpg[]

* on voit bien l'augmentation du nombre de technos de 2014 à nos jours
* On va donc utiliser de plus en plus de briques différentes qui vont devoir communiquer : le *besoin d'orchestration* devient de plus en plus critique.

.Meta-orchestration en réponse à ces problématiques
image:20220524_dataops_04.jpg[]

* Saagie s'ouvre de plus en plus à l'utilisation d'outils externe (via l'usage d'API)

Demo de la plateforme Saagie : 

    * permet d'ouvrir ses pipelines à des systèmes hostés ailleurs (sans devoir changer son code)
    * Saagie fait bien office d'orchestrateur, et permet de faire liens avec des outils tiers / externes.
        ** parmi les plateformes / techno auxquelles Saagie donne accès : AWS, Azure, Databricks et d'ici peu GCP
            *** et OVH et Scaleway sont également prévus

Techniquement très intéressant. +
Les explications de Leshanshui sont très claires.

== 11h20 -> 11h40 - Souveraineté : Souveraineté numérique et plan calcul, comment dépasser 55 ans d’échecs.

By Jérôme Lecat (Scality)

.Abstract
----
En 1966 fût inauguré le Plan Calcul avec pour vocation d’assurer l’autonomie française dans les techniques de l’information et développer une informatique européenne. Ont suivi d’autres initiatives au fil des décennies qui ont englouti des fonds français et européens colossaux sans résultat probant. Pourtant, nous avons en France et en Europe l’expertise, les ressources et l’envie de développer des solutions d’excellence. Nous avons des entreprises de toutes tailles qui sont des leaders mondiaux.
Est-il pour autant réaliste de viser une souveraineté française ou européenne dans le domaine du numérique ?
Quel en serait l’objectif ?
Que peut-on apprendre de nos échecs pour les dépasser et bâtir d’autres succès ? 
----

* souveraineté numérique en France : "ben on est à peu près nulle part..."
    ** cf le Quadrant du Gartner sur l'infra Cloud : pas une boîte européenne

* Donc situation compliqué / cornélienne : *qu'elle plateforme doit-on choisir en France ?*
    ** on a de très bonnes solutions en France, MAIS plus compliquée / longue à mettre en place
    ** où on va chez AWS
    ** Personnellement, je ne suis pas complètement convaincu que nos solutions soient plus tellement plus compliquées à mettre en place. +
    Jérôme entend peut-être par là que nos solutions françaises proposent moins de services ques les grandes américaines.

* *souveraineté numérique* : autonomie de décision et de mise en oeuvre dans le domaine du numérique (télécom, informatique et par extension technologies)
    ** notre monde (occidental) est actuellement extrêmement interdépendant.
    ** Donc une indépendance complète est complètement utopique
    ** Donc comment obtenir une indépendance décision ?
        *** sans qu'en plus un "collègue" (gouvernement américain...) ne vous force la main (comme avec l'amende de 6 milliards à la BNP pour avoir traiter en dollars avec l'Iran)

* Jérôme : *il est important de connaître l'histoire pour éviter qu'elle ne se répète*
    ** avec pour exemple la vente d'une partie de Bull à General Electrics en 1964 (dans ces eaux là)

* Jérôme : on peut pas dire que l'état et les industriels n'ont pas essayé
    ** mauvais soutien de Bull à l'époque : on l'a soutenu, plutôt que de lui passer des commandes (à la place d'en passer à IBM qui était son concurrent)
* Différence avec les USA et la Chine ?
    ** tous deux ont protégé leurs entreprises, surtout au lancement et en phase de croissance
    ** Cas *en 2013* du gouvernement américain qui a passé à AWS une commande représentant 20% de son CA (qui était de 3 milliards de $). C'est énorme pour une société dans cette phase de développement

image:20220524_dataops_05.jpg[]

* Jérôme : exemple avec les débuts de Scality et "Laniol" (???), une société américaine, qui leur avait passé un très gros contrat pour eux à l'époque. +
Scality a développé pour eux un outil / logiciel, qui n'a au final PAS été retenu par Laniol (alors que tout fonctionnait bien) +
Jérôme était alors gêné, mais Laniol lui a répondu qu'au contraire il ne fallait pas, car leur métier était justement de permettre à des sociétés de se développer. +
-> *Jérôme explique qu'il n'a jamais retrouvé ce comportement en France*, alors que cette attitude et ce contrat leur avait été extrêmement utile.
    ** *beaucoup plus que des subventions, il faut donner à nos entreprises / startups des contrats*, pour qu'elles puissent pratiquer et s'améliorer
    ** Pour cela, le cloud privé (et donc le multi cloud qui permet d'y avoir accès sans oublier le reste) est très adapté

[NOTE]
====
* Scality travaille déjà avec l'AP-HP
* Jérôme : Toucan Tocco est au top mondial en tant que dataviz
====

== 14h00 -> 14h30  - Souveraineté : Comment mettre en place une stratégie Data Mesh dans un contexte de souveraineté?

By Rayed Benbrahim (MongoDB)

.Abstract
----
Devenir Data-driven, utiliser la data comme avantage compétitif et exploiter la data à grande échelle sont des challenges que de nombreuses entreprises cherchent à relever. Le Data Mesh offre une solution alternative à l'organisation de la data, rendant son exploitation à grande échelle plus manœuvrable. Dans un contexte où la législation et la conscience des utilisateur se tourne vers la souveraineté des données et les conditions dans lesquelles elles sont exploitées, l'implémentation d'une stratégie de Data Mesh devient plus complexe

Durant cette session, venez découvrir:
- Ce qu'apporte le Data Mesh et son implémentation grâce à MongoDB
- Les contraintes qu'imposent le respect de la souveraineté des données dans une stratégie de datamesh
- Les réponses que MongoDB peut apporter pour bénéficier des bienfaits du Data Mesh, tout en étant respectueux des enjeux de souveraineté des données
----

* MongoDB est plus qu'une BDD, mais est une *data platform*

* Jusqu'à maintenant : partie opérationnelle <> ETL <> partie analytique
    ** avec des technos comme data lake, data warehouse, data lakehouse

* Et maintenant, on évolue vers le *Data mesh*, que l'on peut rapprocher du *DDD*

image:20220524_dataops_06.jpg[]

* Mettre en place un Data mesh va donc impliquer *discipline* et *gouvernance*

.MongoDB Data Mesh
image:20220524_dataops_07.jpg[]

How MongoD helps Sovereignty ?

    * Discover
    * Defend
    * Detect

image::20220524_dataops_08.jpg[]

Rayed que : 

    * GitHub avait il y a quelques années du restreindre l'accès à ces données pour plusieurs pays (Iran)
    * Les Cloud providers ont du limiter / arrêter leurs services en Russie

.Data sensibility and impact
image:20220524_dataops_09.jpg[]

* Donc, cf Rayed, il faut être capable de *remonter son infra et ses données chez un autre hébergeur*
    ** d'où l'*importance de l'IaaC*

.Solutions pour la phase Defend
image:20220524_dataops_10.jpg[]

* On connaît surtout MongoDB comme une BDD transactionnelle, mais elle fait plus que cela aujourd'hui (analytics, etc.)

== 15h10 -> 15h40 - Tech : Comment optimiser l'ingénierie de la donnée dans un écosystème où Snowflake est l'un des piliers ?

By Jean-Marc Le Gonidec (Streamsets), Stéphane Heckel (Streamsets)

.Abstract
----
Ingestion des données dans le Cloud, traitement des données in-situ dans Snowflake via Snowpark, découvrez comment la DataOps accélère votre Analytique !
----

.StreamSets : ETL de bout en bout pour Snowflake
image:20220524_dataops_11.jpg[]

* StreamSets propose une facilité de prise en main, de maintenance
    ** pas besoin de (trop) scripting côté administration, apparemment gros interfaçage graphique
* StreamSets est Snowflake Premium Partner
* StreamSets s'appuie massivement sur SnowPark : ETL / ELT natif pour Snowflake / Snowpark

.Rappel sur SnowPark
[NOTE]
====
The Snowpark library provides an intuitive API for querying and processing data in a data pipeline. Using this library, you can build applications that process data in Snowflake without moving data to the system where your application code runs.
====

.ETL / ELT natif pour Snowflake / Snowpark
image:20220524_dataops_12.jpg[]

* StreamSets met particulièrement en avant son Use Case de *CDC* (*Change Data Capture*)

* StreamSets tourne sur Kubernetes
* le control plane est en SaaS

* Version d'essai (Try) dispo sur le site de StreamSets (limitée à 5 jobs en parallèle)
* Beaucoup de docs et d'exemple dispo sur GitHub apparemment

== 15h45 -> 16h15 - Tech : Construire un cadastre solaire en combinant Airflow et les données spatiales

By Valentin Ruppli (namR), Alexandre Bacchus (namR)

.Abstract
----
namR vous présentera son process de production de données dédiées à la solarisation des bâtiments. On expliquera plus précisément comment on met à jour un pipeline de données géospatiales avec Airflow.
----

* namR existe depuis 4 ans
    ** très green, membre de Tech4Good
    ** très connecté au monde académique

* namR vend de la donnée géolocalisée
    ** des data sets qu'ils ont nettoyées et enrichies

.Comment passer d'une problématique métier à une problématique Data
image:20220524_dataops_13.jpg[]

.DAG avec Airflow
image:20220524_dataops_14.jpg[]

* *Data quality testing* : utilise la librairie Open Source "great_expectations"
    ** pour des tests côté qualité de données
* *Validation Toolkit Explorer* : avec notebook Jupyter
    ** pour aller plus dans le détail, et réaliser une analyse plus qualitative des données

== 16h20 -> 16h50 - Tech : Retour d'expérience : DataOps pour l'attrition dans les télécoms

By Julien Cabot (Lifetime Analytics)

.Abstract
----
Chez Lifetime, nous luttons contre l’attrition (“churn”) dans les télécoms en combinant de nombreuses données et surtout de nombreux modèles d’analyse, de manière industrielle, sous la forme d’un produit SaaS pour les équipes marketing.

Lors de ce retour d’expérience, je présenterai :
- Comment nous appliquons le process Data Ops pour notre produit SaaS,
- Comment nous avons tourner nos modèles “explainable AI” en tant feature produit,
- Comment nous déployons à chaud nos containers de code de pipeline sur Microsoft Azure, avec une approche “Pipeline on Demand”.

A propos de Lifetime Analytics :

Lifetime est une solution cloud de gestion de l’attrition pour les équipes marketing des opérateurs télécoms, permettant d’anticiper l’impact du churn, d’identifier les clusters de souscriptions à risque et de gérer les actions de rétention.
----

* Toute jeune boîte qui travaille surtout dans les pays de l'Europe de l'Est
* travaille surtout dans les télécoms

* Julien va nous présenter ce qu'ils font pour la problématique du churn en Slovénie.
    ** le churn est un "vieux" problème, connu, et qui pèse lourd

* Le churn (perte de clients) est un phénomène relativement discontinu. Il découle : 
    ** de périodes de réduction des concurrents
    ** d'incidents technologiques

.Churn : explainability over prediction
image:20220524_dataops_15.jpg[]

.Lifetime Analytics workflow
image:20220524_dataops_16.jpg[]

.Lifetime Analytics architecture
image:20220524_dataops_17.jpg[]

* Lifetime Analytics utilise également *Snowflake*
    ** pour la partie staging & feature store
* Sinon usage de briques Azure : 
    ** Azure Container Instances : avec un pattern Command
    ** Azurez Cosmos DB
    ** Azure WebApp Node.js

== 16h55 -> 17h40 - Souveraineté : Le Rôle du/de la CTO dans le Business - avec Tech.Rocks

By Meriem Berkane (OCTO Technology, CTO), Nicolas Baron (Yousign, VP Engineering), Mathilde Lemée (Jolimoi, Co-fondatrice & CTO), Sacha Morard (Le Monde, CTO)

* Nicolas : importance de la *mise en place d'OKR*
    ** Exemple : aligner des OKR d'entreprise avec l'effort de R&D

* De manière collective : pas de silver bullet concernant la *dette technique*
    ** il faut déjà se mettre d'accord sur ce qu'est la dette technique

* Nicolas : 1 journée par semaine chez YouSign "journée sans produit", où l'on va essayer d'améliorer l'existant (et donc de tacler la dette technique)

* Mathilde : discuter et échanger avec le CODIR / COMEX non pas avec directement la technique (la "Data" en l'occurrence), mais avec des *use cases en décrivant l'usage*.

* Nicolas : un conseil (ou une tentative de conseil) : *timeboxer l'effort de R&D*
    ** Par moment chercher quelque chose de différenciant, qui sorte de l'ordinaire, pour trouver une nouvelle valeur ajoutée
        *** Cas de MeilleurAgents qui faisait de la R&D à 3 4 ans, très prospective, avec des partenariats avec l'université, ou embauchant des élèves chercheurs.

== 18h30 -> 19h30 - Business : Meetup by Paris Data Ladies - Computer Vision, NLP & Time Series en Santé

----
1) "Diagnosis of peripheral neuropathy using Deep Learning models on 3D images" par Alexandra LORENZO DE BRIONNE, Lead Data Scientist @ Quantmetry

2) "Leveraging unstructured text from Electronic Health Records - APHP CDW Use Case" par Charline JEAN, Data Scientist et Alice CALLIGER, Machine Learning Engineer @ Assistance Publique - Hôpitaux de Paris (AP-HP)

3) "PlethoMAP: Real-time non-invasive hemodynamic monitoring for operating rooms" par Jade PERDEREAU, Data Scientist @ Hôpital Lariboisière Fernand-Widal AP-HP.
----

1) "Diagnosis of peripheral neuropathy using Deep Learning models on 3D images"

* *Quantmetry* très lié au domaine de la santé
    ** grosse équipe de Data scientist, plusieurs brevets de déposés, plusieurs publications
    ** travail régulier avec le AP-HP
* *anonymisation*, contrairement à *pseudonimisation*, on ne peut *JAMAIS* revenir au patient.

2) "Leveraging unstructured text from Electronic Health Records - APHP CDW Use Case"

* AP-HP : large volumétrie de données, de 100K jusqu'à 1 million de documents par jour
* données très sensibles, doivent être traitées sur leurs propres serveurs, et PAS dans le Cloud
    ** d'où des pannes à gérer

.Stack technique (pour déployer un modèle de NLP sur plusieurs GPUs)
image:20220524_dataops_18.jpg[]

    * cluster *Spark*
    * gestion des dépendances avec *Poetry*

3) "PlethoMAP: Real-time non-invasive hemodynamic monitoring for operating rooms"

Niveau stratosphérique de la présentation ! +
A revoir, rien que pour comprendre davantage, fantastique niveau technique

-> Prochain rdv de ce Paris Data Ladies chez Octo le mois prochain si j'ai bien compris

== 18h30 -> 22h30 - networking : 🍸🍹Cocktail de Clôture 🍸🍹

== Demos

* *Demo de Saagie* en zone Long Courrier : +
image:20220524_demo_saagie_01.jpg[width=600]
    ** Saagie : tourne n'importe où sur du Kubernetes
        *** Kubernetes réellement obligatoire actuellement, au même niveau qu'un Kafka (sauf qu'il n'y a même pas de "Pulsar" pour faire un tout petit peu de concurrence)
    ** Saagie travaille et a déjà déployé sa solution au Ministère des armées

== Networking

* Echange avec *Rayed Benbrahim* de *MongoDB*, Solutions Architect, côté "partenariat" chez MongoDB
    ** MongoDB a l'habitude et cherche à mettre en place des partenariats avec des ESN
        *** pour faire connaître leur techno chez les ITs
        *** pour être tenu au courant des besoins des clients

    ** Par contre, j'ai voulu préciser ce dont il était question par "Data platform" pour MongoDB. +
    Réponse de Rayed, c'est la partie "réplicat" de MongoDB qui est intéressante pour cela. +
    Sans déplacement / duplication de données, on peut cibler un réplicat pour des traitements coûteux *sans* impacter le reste de la BDD transactionnelle (utilisée par un frontal côté commerce par exemple)
    
    ** Rayed confirme que le principal use case pour *MongoDB* est bien d'être une *BDD transactionnelle*.
        *** Non, MongoDB, même se disant "Data platform" ne compte pas se positionner en concurrent d'un Snowflake ou autre Cloud DWH.

== Avis sur le salon

* Encore et toujours *Kubernetes* en force et présent partout
