= 2022/05/10 - Google Developer Group Cloud Paris - Soir√©e Google Cloud Workflows / BigQuery
Thomas SCHWENDER <icon:github[] https://github.com/Ardemius/[GitHub] / icon:twitter[role="aqua"] https://twitter.com/thomasschwender[@thomasschwender]>
// Handling GitHub admonition blocks icons
ifndef::env-github[:icons: font]
ifdef::env-github[]
:status:
:outfilesuffix: .adoc
:caution-caption: :fire:
:important-caption: :exclamation:
:note-caption: :paperclip:
:tip-caption: :bulb:
:warning-caption: :warning:
endif::[]
:imagesdir: ./images
:source-highlighter: highlightjs
:highlightjs-languages: asciidoc
// We must enable experimental attribute to display Keyboard, button, and menu macros
:experimental:
// Next 2 ones are to handle line breaks in some particular elements (list, footnotes, etc.)
:lb: pass:[<br> +]
:sb: pass:[<br>]
// check https://github.com/Ardemius/personal-wiki/wiki/AsciiDoctor-tips for tips on table of content in GitHub
:toc: macro
:toclevels: 4
// To number the sections of the table of contents
//:sectnums:
// Add an anchor with hyperlink before the section title
:sectanchors:
// To turn off figure caption labels and numbers
:figure-caption!:
// Same for examples
//:example-caption!:
// To turn off ALL captions
// :caption:

toc::[]

== Op√©rations asynchrones dans votre UI avec Workflows et Firestore

=== Abstract

Pr√©sent√© par Guillaume Laforge / Google

----
En combinant Google Cloud Firestore et Workflows, vous pouvez faire tourner et suivre le d√©roulement de vos longues op√©rations asynchrones. Une requ√™te HTTP n‚Äôest pas l‚Äôid√©al pour une op√©ration m√©tier qui prend du temps. Mais Workflows permet justement d‚Äô√©crire et de diriger des process m√©tiers multi-√©tapes. Un simple appel √† Workflows ou l'utilisation d'une librairie cliente lance l‚Äôex√©cution du workflow. Mais comment suivre chaque √©tape de ce process en quasi temps r√©el ? En ajoutant dans la boucle l‚Äôutilisation de Firestore, gr√¢ce √† sa fonctionnalit√© d‚Äôabonnement aux modifications de donn√©es en temps r√©el. D√®s qu‚Äôune √©tape cl√© est franchie, stockez une mise √† jour du statut de votre workflows dans Firestore. C√¥t√© client, votre UI sera notifi√©e √† chaque changement des donn√©es associ√©es, et vos utilisateurs pourront suivre clairement et facilement le statut de vos process m√©tiers. Nous verrons cela ensemble dans cette pr√©sentation, avec deux exemples concrets illustr√©s avec de vrais morceaux de code dedans !

Guillaume Laforge est Developer Advocate pour Google Cloud, et se focalise particuli√®rement sur les technologies serverless. Il est √©galement un Java Champion, co-fondateur du podcast Les Cast Codeurs, et co-cr√©ateur du langage de programmation Apache Groovy.
----

=== Notes

* C'est la 1ere de cette conf que Guillaume donnera √©galement d√®s demain √† *Google I/O*

* *Workflows* permet d'orchestrer des appels √† n'importe quelle API
    ** Workflows permet de combiner n'importe quel APIS avec des services Google CLoud, afin de construire facilement des applications reliable ainsi que des process automations.
* Ses caract√©ristiques : 
    ** *serverless*
    ** *long-running*
    ** *low-latency*
    ** boucles, branches (y compris parall√®les), pauses, callback possibles
    ** tr√®s adapt√© aux architectures microservices (dans le Cloud)
    ** syntaxe en YAML (pourrait √™tre en JSON)
    ** authentification g√©r√©e de fa√ßon transparente, se sert d'OAuth2 / OpenID Connect
    ** On ne peut pas appeler Workflows directement depuis le navigateur, il faut passer par des fonctions interm√©diaires
    ** L'ex√©cution d'1 workflow peut durer (techniquement) jusqu'√† 1 an !

* *Firestore* : simply write to a NoSQL document database and see changes reflected  in your mobile and web apps.
* Ses caract√©ristiques : 
    ** serverless
    ** offline support
    ** global scale

==== Demo avec une appli de commande de pizzas

NOTE: Guillaume fait sa demo avec *VS Code*

image:20220510_GDG-Cloud-Paris_Workflows-BigQuery_01.jpg[]
image:20220510_GDG-Cloud-Paris_Workflows-BigQuery_02.jpg[]

* usage de Cloud Functions qui vont cr√©er une ex√©cution du workflow

NOTE: On pourrait coupler cette d√©mo √† un GPS pour savoir o√π se trouve le livreur üòâ 

.Architecture de la demo
image:20220510_GDG-Cloud-Paris_Workflows-BigQuery_03.jpg[]

    * avant le "start", on commence par l'appel du *Cloud Function*
    * on peut utiliser la BDD Firestore ind√©pendamment de Firebase
        ** "Firebase static hosting" permet de faire du hosting d'√©l√©ments statiques

.Gestion de la corr√©lation
[NOTE]
====
Question Thomas : Mais *comment est g√©r√©e la corr√©lation* dans les diff√©rentes √©tapes du workflow ? (en gros, y a-t-il un Sleuth de dispo la derri√®re) +
Une question importante pour tout ce qui va √™tre *agr√©gation des logs*. 

    * Guillaume : il faut le faire √† la main...
    * Dans la demo, Guillaume se sert de "order_id", et des capacit√©s de Firestore de pouvoir notifier de ses changements d'√©tats. +
    PAR CONTRE, Guillaume g√®re "√©mule" donc manuellement l'ID de corr√©lation via l'"order_id"
        ** Il explique qu'on peut appeler via workflows des services ext√©rieurs √† Google, sur lesquels on ne pourra donc *PAS* ajouter la corr√©lation.

    * Donc, dans cette d√©mo, les logs de l'encha√Ænement des √©tapes du workflow sont finalement obtenus "apr√®s coup" via observation de la BDD Firestore (via notification de cette derni√®re)
====

* Utilisation de *Document AI* pour analyser le contenu d'une image, en l'occurrence un ticket de caisse.
    ** Le connecteur de Workflows pour Document AI va s'occuper de cette "op√©ration longue" d'analyse d'image (~1 min) +
    Donc pas la peine de coder ce traitement, Workflows s'en occupe.

.Workflow de la demo
image:20220510_GDG-Cloud-Paris_Workflows-BigQuery_04.jpg[]

*Conclusion* : reliable (Workflows) + Reactive (Firestore) -> Trusted (your app)

*Q&A :*

    * Firestore est en fait la BDD technique de Workflows, donc, on pourrait se demander pourquoi en faire des produits s√©par√©s ?
        ** Guillaume : Workflows est un produit r√©cent, et, apr√®s discussion avec Guillaume, il n'a pas √©t√© cr√©√© du fait d'un besoin pr√©cis c√¥t√© Google ou client de Google, mais car le cloud Google devait poss√©der ce type de fonctionnalit√© d√©j√† propos√© c√¥t√© AWS (AWS Step Functions) et Azure (Azure Logic Apps)
        ** Donc Workflows a √©t√© cr√©√© derni√®rement, bien apr√®s Firestore, et s'appuie grandement sur cette persistance.

    * Et si boum, comment se passe la reprise sur erreur ?
        ** Guillaume : difficilement... Toujours le m√™me probl√®me de l'ID de corr√©lation qui n'est pas nativement g√©r√© par Workflows.
            *** R√©sultat, pas de fonctionnalit√© native de reprise sur erreur
            *** Pour g√©rer ce besoin, il faut donc passer par une solution tierce, comme un pattern SAGA et donc une solution programmatique.
            *** Cette solution programmatique va selon moi √† l'encontre de la philosophie de l'outil, √† savoir la facilit√© de mise en oeuvre d'une solution de ce type dans le Cloud. +
            OK, la solution a le m√©rite d'exister et fonctionne, mais elle est incompl√®te √† mes yeux. On ne va pas en PROD sans process de reprise sur erreur.
                **** En encore moins en environnement microservices !
                **** Guillaume confirme d'ailleurs que c'est pour le moment "un peu l'enfer" en mati√®re d'agr√©gation des logs (de nouveau : pas de gestion de l'ID de corr√©lation √† la Sleuth, il faut le faire "√† la main" comme Guillaume l'a fait avec l'"order_id")

Ma conclusion : cela existe, va s√ªrement encore s'am√©liorer, mais aller actuellement en PROD avec... Dans un environnement microservices, sans ID de corr√©lation facile √† g√©rer, donc avec des gal√®res certaines c√¥t√© monitoring et agr√©gation des logs, ce n'est pas quelque chose que je ferais.

== BigQuery DeepDive : d√©cortiquons le Data Warehouse made in Google

=== Abstract

Pr√©sent√© par Cl√©ment Bosc / Stack Labs

----
OLTP ? Cubes OLAP ? Data Warehouse ? Data Lake ? base de donn√©es MPP dans le Cloud ? Ces termes vous sont √©trangers ? Pas de panique ! Reprenons les bases de la Data Analytics pour mieux explorer les entrailles de BigQuery, le Data Warehouse serverless Cloud de Google ! Fonctionnalit√©s avanc√©es, optimisations de co√ªt et de performances, bonnes pratiques, s√©curit√© : BigQuery n'aura plus de secrets pour vous !

Cl√©ment Bosc est Data Engineer @Stack Labs. GCP & Data Enthusiast
----

=== Notes

NOTE: Cl√©ment travaille √† *Stack Labs*, une soci√©t√© sp√©cialis√©e dans la Data et qui recrute üòâ 

* BigQuery : le data warehouse serverless de Google

On commence par une "bonne vieille" pr√©sentation de OLTP vs OLAP.

.The rise of the data warehouse
image:20220510_GDG-Cloud-Paris_Workflows-BigQuery_05.jpg[]

.Rappel
NOTE: *MPP* = Massively Parallel Processing

BigQuery est un DWH : 

    * serverless
    * disponible dans GCP

.2 produits en 1 : on s√©pare compute et storage
image:20220510_GDG-Cloud-Paris_Workflows-BigQuery_06.jpg[]

    * Et ces compute et storage peuvent √™tre utilis√©s ind√©pendamment
    * mais c'est ensemble que ces 2 produits fonctionnent le mieux

Toute cr√©ation d'une nouvelle requ√™te SQL : 

    * va donner lieu √† un job
    * √† un plan d'ex√©cution
    * xxx
    * BigQuery va d√©placer les petits bouts de data sur les noeuds du cluster
    * sauvegarder le r√©sultat dans une table temporaire
        ** d'o√π une notion de cache : 5 min plus tard si on refait la m√™me requ√™te on tape directement dans cette table temporaire
    * restituer le r√©sultat

.Les co√ªts
image:20220510_GDG-Cloud-Paris_Workflows-BigQuery_07.jpg[]

    * storage : 100 To pour 5$ / mois
    * compute : xxx

.Possibilit√© de *nested structures*, √† savoir des donn√©es imbriqu√©es
image:20220510_GDG-Cloud-Paris_Workflows-BigQuery_08.jpg[]

    * ajout derni√®rement : recherche sur donn√©es nested semi-structur√©es (on peut donc faire une recherche sur du nested JSON)

*Comment charger de la data ?*

    * fa√ßon de faire conseill√©e et la plus courante : un *load job* (API / CLI)
    * les *federated queries* : on d√©clare une connexion sur une BDD tierce
        ** que en mode batch
    * la m√©thode la plus avanc√©e et la plus compliqu√©e : *storage write API*
        ** pour le temps r√©el et tout ce qui est *low-latency*

*Comment acc√©der √† la data ?* (acc√®s √† la dataviz)

    * pas de frais d'ingress ici, on peut sortir de la data (du DWH) sans payer
    * acc√®s aux diff√©rentes dataviz via ODBC / JDBC

*Co√ªts et optimisation des performances*

.partition your tables !
image:20220510_GDG-Cloud-Paris_Workflows-BigQuery_09.jpg[]

    * pas d'indexe sur BigQuery, ce qui est un classique pour les outils MPP
    * pas d'indexe car trop co√ªteux pour de la lecture intensive ?!
    * ne marche sur des dates, et pas des string
        ** √† creuser, je ne comprends pas
        ** pour une explication voir https://www.quora.com/Why-do-shared-nothing-MPP-databases-like-Netezza-do-not-support-indexes +

----
I can't really comment on Netezza, but I can comment on implementing indexes for shared-nothing databases. Shared-nothing architectures typically partition data in some way based on a row identifier. Lookups based on row identifiers, therefore, are fast because the architecture knows exactly which node to fetch the data out of and manipulate it with.

To me, having an index implies writing a lookup structure based on a field other than row identifier. This breaks the fundamental concept of a shared-nothing architecture, because there is no way to uniquely organize by non-identifier fields without having to hop over to another node to retrieve the row it is pointing to. You could always do something like write a second table containing the mapping of field to the row identifier of the first table and then do client-side lookups ... but, again, that'd be cheating the purpose of using a shared-nothing architecture, in which case I'd consider using a different database.

Edit: Some shared-nothing database implementations can & do have indexes, but they implement them to the manner similar as what I described above. I‚Äôd still recommend using a different databases if the data model requires a large number of nonprimary field lookups.
----

.cluster your tables !
image:20220510_GDG-Cloud-Paris_Workflows-BigQuery_10.jpg[]

    * le *clustering* peut √™tre faire sur *plusieurs colonnes* contrairement au partitioning qui ne concerne qu'1 colonne
        ** mais gaffe √† l'ordre dans ce cas

.shard your tables ! (if necessary)
image:20220510_GDG-Cloud-Paris_Workflows-BigQuery_11.jpg[]

    * marche sur des string
        ** et si on veut sharder sur des dates, mieux vaut passer au partitionnement
    * meilleures perfs que le clustering mais seulement sur 1 colonne

.materialized views
image:20220510_GDG-Cloud-Paris_Workflows-BigQuery_12.jpg[]

    * va mat√©rialiser sur disque une requ√™te SQL : si les donn√©es √©volue, la vue est actualis√©e
        ** REX de Cl√©ment : ces mat views semblent fonctionner...
        ** par contre pas les fonctions de fen√™trage analytics (`PARTITION BY` and co)
        ** mais les jointures sont maintenant possibles
    * *smart tuning* : si on conserve sa grosse table connect√©e √† sa dataviz, MAIS qu'on a une mat view existante √† c√¥t√©, sans qu'on lui demande, BigQuery peut s'en servir pour am√©liorer les performances.

*Quelques tips* : 

    * only select the column you want : donc pas de `SELECT *`
        ** il y a un mode preview qui existe si on veut un aper√ßu de toutes les colonnes
    * use *INT64* pour les conditions de jointures : plus faciles de comparer des entiers que des cha√Ænes de caract√®res

.Use CTE (Common Table Expression)
image:20220510_GDG-Cloud-Paris_Workflows-BigQuery_13.jpg[]

    * √ßa n'am√©liore pas les perf, MAIS rend le code plus lisible
    * CTE are NOT pre compute, sometimes it's preferable to materialize results in temporary tables instead !

.Which data modeling ?
image:20220510_GDG-Cloud-Paris_Workflows-BigQuery_14.jpg[]

    * √©vitez les jointures avec BigQuery, il n'aime quand m√™me pas trop √ßa...
    * le data vault implique un grand nombre de jointures, donc pas conseill√© avec BigQuery pour une grosse volum√©trie
    * tr√®s √† la mode : le "one big table"
        ** des √©tudes indiquent qu'on peut gagner jusqu'√† 50% de perf
        ** mais cela ajoute √©norm√©ment de duplication, avec les probl√®mes de synchro associ√©s
            *** c√¥t√© co√ªt de l'espace de stockage qui augmente, cela co√ªte plus trop cher actuellement

//-

* BigQuery est tr√®s bien trait√© par *Terraform*
    ** permet la CI / CD sur son workflow

* *Security* : IAM and RLS (Record / Row Level Sharing)
    ** set permissions for the least access privilege !
    ** GCP resource hierarchy : +
    *Organisation -> Folder -> Project -> Dataset -> Table -> Row*
        *** d√®s qu'on peut, on met la s√©curit√© le plus bas possible, au niveau Table, et m√™me au niveau Row
    ** avec *Data Catalog*, on peut ajouter la *s√©curit√©* au *niveau de la colonne*.

*Q&A :*

    * Cl√©ment, philosophie de BigQuery : g√©rer la *d√©duplication au niveau de la lecture*









