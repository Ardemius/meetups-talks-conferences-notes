= Quick notes
Thomas SCHWENDER <icon:github[] https://github.com/Ardemius/[GitHub] / icon:twitter[role="aqua"] https://twitter.com/thomasschwender[@thomasschwender]>
// Handling GitHub admonition blocks icons
ifndef::env-github[:icons: font]
ifdef::env-github[]
:status:
:outfilesuffix: .adoc
:caution-caption: :fire:
:important-caption: :exclamation:
:note-caption: :paperclip:
:tip-caption: :bulb:
:warning-caption: :warning:
endif::[]
:imagesdir: ./images
:source-highlighter: highlightjs
:highlightjs-languages: asciidoc
// We must enable experimental attribute to display Keyboard, button, and menu macros
:experimental:
// Next 2 ones are to handle line breaks in some particular elements (list, footnotes, etc.)
:lb: pass:[<br> +]
:sb: pass:[<br>]
// check https://github.com/Ardemius/personal-wiki/wiki/AsciiDoctor-tips for tips on table of content in GitHub
:toc: macro
:toclevels: 4
// To number the sections of the table of contents
//:sectnums:
// Add an anchor with hyperlink before the section title
:sectanchors:
// To turn off figure caption labels and numbers
// :figure-caption!:
// Same for examples
//:example-caption!:
// To turn off ALL captions
:caption:

toc::[]

Un bloc-notes permettant de persister des notes et rÃ©flexions prises trÃ¨s rapidement en suivant talk, conf, Ã©mission ou autre.

== 2022/05/11 - VidÃ©o "Dev senior avec 6 ans d'XP, et aprÃ¨s?" (gestion de carriÃ¨re)

J'ai regardÃ© derniÃ¨rement le MeetUp Tech Rocks *"Dev senior avec 6 ans d'XP, et aprÃ¨s ?"* qui aborde le sujet de la gestion de carriÃ¨re chez les ITs, et met bien en avant *2 types de carriÃ¨re* : la *voie managÃ©riale* ("*Engineering Management*") et la voie appelÃ©e ici "leadership's path" (ou *Individual Contributor*), correspondant Ã  une *orientation plus technique*, dans laquelle on va chercher Ã  avoir de plus en plus d'impact via sa contribution individuelle (contribution qui va elle impacter un nombre croissant de personnes dans l'entreprise)

Si vous avez ~1h (ou 45 min en x1.5 ðŸ˜‰ ), je ne saurais que trop vous conseiller de regarder le talk, rÃ©ellement trÃ¨s intÃ©ressant et faisant intervenir des CxO et leaders seniors dans des boÃ®tes de la Tech : https://www.youtube.com/watch?v=WIW3ow6jL98

video::WIW3ow6jL98[youtube]

J'ai beaucoup aimÃ© la *description faite du "Y" de nos carriÃ¨res* (entre management et contribution individuelle), tout particuliÃ¨rement celle de la branche du contributeur individuel. +
Les intervenants expliquent bien la prise de conscience actuelle et grandissante qu'un IT n'a pas "ratÃ© sa vie parce qu'il n'est pas manager Ã  30 ans", et que sa vie ne s'arrÃªtait pas non plus Ã  l'obtention du *poste "Senior developer / consultant"*. +
*Ce dernier est tout sauf la fin du parcours*, et va se poursuivre dans des rÃ´les oÃ¹ sa contribution individuelle va avoir de plus en plus d'impact sur un grand nombre de personnes dans la sociÃ©tÃ©.

La progression proposÃ©e est celle que l'on retrouve de plus en plus dans les boÃ®tes anglo-saxonnes (bien en avance sur nous Ã  ce niveau), Ã  savoir : +
*senior software engineer >> staff engineer >> principal engineer >> distinguished engineer >> fellow engineer >> CTO*

Dans un 1er temps, on va avoir un impact sur soi uniquement, puis il faudra chercher Ã  accroÃ®tre son scope : +
*Soi >> team / squad >> chapter / guild >> product line >> company >> industry*

image:20220511_Tech-Rocks_dev-senior-et-apres_01.png[]
image:20220511_Tech-Rocks_dev-senior-et-apres_02.png[]

En passant, si vous voulez un exemple "proche de nous" de ce systÃ¨me, Ã©coutez comment *Emmanuel Bernard*, notre Cast Codeurs bien connu ðŸ˜‰, se prÃ©sente : *"Distinguished Engineer"* +
Pour info, cela fait 17 ans qu'il travaille chez Red Hat. +
Un exemple de plus qu'il est possible de progresser SANS devenir "manager" ðŸ˜‰ +
(et si vous prenez son collÃ¨gue *ClÃ©ment Escoffier* cÃ´tÃ© Quarkus / Kubernetes chez Red Hat, c'est *"Principal Engineer"* ðŸ˜‰ )

== 2022/06/28 - Artisan DÃ©veloppeur : Interview de Thomas PIERRAIN

Thomas PIERRAIN est VP of engineering chez Agicap, et est un ancien archi de la SGCIB

* Thomas Pierrain : on justifie le *passage aux microservices* principalement pour des raisons de *vÃ©locitÃ© du delivery* et *Ã©viter les bottle neck*.
* De plus en plus on parle d'ailleurs de *macro service* plutÃ´t que de micro service (on revient du buzz des premiÃ¨res annÃ©es des microservices)

* Thomas P chez Agicap : mise en place (Ã  vÃ©rifier) d'une architecture dite "la ruche" pour monolithe 

* *Living doc* trÃ¨s avancÃ©e chez Thomas : gÃ©nÃ©ration automatique depuis le build vers markdown 
* Environnement technique hexagonale et CQRS trÃ¨s avancÃ©, Ã  regarder 

* Conseil : *ne dÃ©coupe pas trop tÃ´t ! Le rÃ©seau va te tuer...*
* Exemple Doctolib : the boring architecture et 400 dev sur 1 monolithe : 
*"La qualitÃ© d'aujourd'hui c'est la productivitÃ© de demain"*

1. on *modularise son code dans le monolith*, on l'aligne sur le mÃ©tier
    ** -> TSC : De nombreux architectes connus donnent Ã©galement ce conseil ("proprifier AVANT de migrer en microservices")
	** en gros, modular monolith : on crÃ©e des modules indÃ©pendants pour chaque feature
	** This combined the advantages of a monolith, such a single test and deployment pipeline, with the advantages of microservices, such as code modularity and decoupling.
+
-> Il faut bien se dire que les microservices nÃ©cessitent une grande maturitÃ© d'Ã©quipeS (oui, au pluriel) surtout cÃ´tÃ© de la chaÃ®ne de CI/CdD

2. *DDD* pour une meilleure sÃ©paration et un meilleur contrÃ´le de la logique mÃ©tier
	** le concept clÃ© : les *bounded contexts*
+
Mise en place de l'architecture hexagonale pour isoler le mÃ©tier, et forcer le passage par les ports et adapters

== 2022/10/21 - Demo de Couchbase Capella

J'ai suivi la dÃ©mo de Couchbase Capella via leur offre d'essai (trial de 30 jours) de la solution.

VidÃ©o explicative : https://www.youtube.com/watch?v=46715VbaHvk

.Comparaison des concepts entre une BDDR et Couchbase
[cols="1,1", options="header"] 
|===
|Relationel model 			|Couchbase
|Server	                    |Cluster
|Database	                |Bucket
|Schema		                |Scope
|Table		                |Collection
|Row		                |Document (JSON or BLOB)
|===

.Exemple
image:20221021_couchbase-capella-demo_01.jpg[]

Why the creation of the index is not done automatically ?

    * Because *manipulating the document using only the ID* is *faster* because using internally the *key / value engine*, which *does NOT require any indexes*.
        ** This works pretty well when you can get the ID of the document

[source,java]
----
// guessing the UserHistory ID using the user's id ('123-hist')
UserHistory hist = userHistoryCollection.get(user.getId() + "-hist")
----


== 2022/05/12 - Le Comptoir OCTO x Dataiku x Snowflake - Comment crÃ©er plus de valeur et developper la collaboration a partir de donnÃ©es enrichies ?

https://fr.slideshare.net/OCTOTechnology/le-comptoir-octo-x-dataiku-x-snowflake-comment-crer-plus-de-valeur-et-developper-la-collaboration-a-partir-de-donnes-enrichies/OCTOTechnology/le-comptoir-octo-x-dataiku-x-snowflake-comment-crer-plus-de-valeur-et-developper-la-collaboration-a-partir-de-donnes-enrichies

* PrÃ©sentation d'une architecture de solution basÃ©e sur Snowflake et DataÃ¯ku, avec le soutien d'OCTO Technology

== 2023/01/09 - Rapport tendances 2023 par Didier Girard

* https://www.linkedin.com/pulse/rapport-tendances-2023-didier-girard

* Didier met lui aussi en avant le succÃ¨s de Team Topologies et du DDD
* Il insiste sur le besoin de dÃ©couplage des Ã©quipes, dans le but d'en augmenter l'autonomie et la productivitÃ©.
    ** L'Ã©quipe doit Ãªtre responsable de bout en bout d'un domaine, et ne doit pas avoir Ã  se reposer sur la synchronisation avec n Ã©quipes pour dÃ©livrer de la valeur.

.Produit vs Projet
--
Un *produit* est une offre matÃ©rielle ou immatÃ©rielle qui rÃ©pond Ã  un besoin ou satisfait une envie. +
Il est le rÃ©sultat de la stratÃ©gie commerciale d'une entreprise et doit Ãªtre conÃ§u, dÃ©veloppÃ© et gÃ©rÃ© afin d'apporter de la valeur au client. Il est ensuite mis au catalogue, et est rÃ©guliÃ¨rement mis Ã  jour dans le cadre de son cycle de vie - jusqu'Ã  ce qu'il soit retirÃ© du marchÃ© - en fonction d'une roadmap Ã©tablie pour rÃ©pondre aux besoins des clients, qui Ã©voluent au fil du temps. +
Le produit vise un objectif, et chaque itÃ©ration s'en rapprochera.

De son cÃ´tÃ©, un *projet* est un effort temporaire qui a pour but de rÃ©pondre Ã  un besoin unique : il s'agit de crÃ©er un livrable spÃ©cifique, pour une date prÃ©cise et un budget fixÃ© Ã  l'avance. Ce qui ne laisse pas de place Ã  l'imprÃ©vu, et va donc Ã  l'encontre des principes agiles ; cette faÃ§on de faire est une source Ã©vidente de frustration lorsque cet imprÃ©vu arrive (ce qu'il fait immanquablement).
--

**MVP vs MLP* : Minimum Valuable Product vs Minimum Lovable Product

    ** Un MVP est une version d'un produit qui possÃ¨de l'ensemble minimal de fonctionnalitÃ©s nÃ©cessaires pour Ãªtre utilisable par les clients.
    ** Un MLP, en revanche, est une version d'un produit qui possÃ¨de l'ensemble minimum de fonctionnalitÃ©s nÃ©cessaires pour Ãªtre aimÃ©e des clients.

    ** En rÃ©sumÃ©, la principale diffÃ©rence entre MVP et MLP est l'accent mis sur le retour d'information des clients et l'engagement Ã©motionnel. +
    Un MVP se concentre sur la collecte de commentaires et l'itÃ©ration sur le produit, tandis qu'un MLP se concentre sur la crÃ©ation d'un lien Ã©motionnel positif avec les clients du produit.

* *Nouveau rÃ´le de l'architecte* : 
    ** concevoir et de mettre en Å“uvre la structure globale du systÃ¨me, en veillant Ã  ce qu'il soit Ã©volutif, maintenable et capable de s'adapter Ã  l'Ã©volution des besoins de l'entreprise.
    ** L'architecte est responsable de la conception de l'architecture des donnÃ©es, y compris le stockage, l'accÃ¨s et la sÃ©curitÃ© des donnÃ©es.
    ** L'architecte doit s'assurer que le systÃ¨me d'information est sÃ©curisÃ©, Ã  la fois contre les menaces externes et contre les accÃ¨s non autorisÃ©s par les utilisateurs internes.

* *SI Cloud Native :*
    ** Un SI Cloud Native mixe des applications SaaS et des services managÃ©s avec des applications ou micro-services maison conteneurisÃ©s, dÃ©ployÃ©s dans le cloud de son choix.

* *WebAssembly* (WASM)
    ** solution permettant d'exÃ©cuter du code bas niveau directement dans le navigateur, offrant des *amÃ©liorations spectaculaires des performances*.
    ** solution pour l'exÃ©cution, dans le navigateur, d'applications Ã©crites en C++, Rust ou Go.
    ** WebAssembly va aussi bien au-delÃ  du navigateur. +
    Cette technologie peut aussi Ãªtre utilisÃ©e dans les applications de cloud computing et d'Internet des objets (IoT) : *WebAssembly fournit un environnement de sandboxing sÃ©curisÃ© dans lequel le code peut s'exÃ©cuter sans avoir d'impact sur les autres programmes*.
        *** Donc une notion proche de celle des conteneurs.

* *Cloud, la plateforme de choix*
    ** importance de l'Infra as Code (IaC), qui est au coeur des architectures cloud-natives
        *** Importance des outils de type *Terraform* ou *Pulumi*
        *** Pulumi : Ce framework de l'Ã©cosystÃ¨me Terraform, dÃ©veloppÃ© par HashiCorp, permet de dÃ©crire l'infrastructure dÃ©sirÃ©e en utilisant un langage de programmation tel que TypeScript, Python ou Go plutÃ´t que d'utiliser le DSL spÃ©cifique Ã  Terraform (HCL).

* Repenser le *rÃ©seau Ã©tendu dans une perspective Cloud*, un concept auquel Gartner a donnÃ© le nom de *Secure Access Service Edge*, ou *SASE* (prononcer sassy).
    ** Dans une architecture SASE, les services Cloud gÃ¨rent lâ€™authentification et plus largement toute la sÃ©curitÃ© du rÃ©seau, et une *couche dâ€™abstraction logicielle permet de gÃ©rer lâ€™infrastructure rÃ©seau* : le *SD-WAN*, *Software-Defined Wide Area Network*. Les services de SD-WAN permettent dâ€™agrÃ©ger plusieurs types dâ€™infrastructures dâ€™un ou plusieurs fournisseurs (MPLS, fibre, SDSL, 4Gâ€¦) et de gÃ©rer ainsi des rÃ©seaux complexes de maniÃ¨re centralisÃ©e, industrialisÃ©e et simple.

* *Plateformes Back*
    ** *MACH* est un acronyme qui signifie Microservices (ou Modules-based), API-first, Cloud native et Headless.
        *** *API-First* : +
        L'application est conÃ§ue et construite autour des API, qu'elles soient REST ou GraphQL. Cette approche met l'accent sur les *API comme principal moyen d'accÃ©der et d'interagir avec l'application*, plutÃ´t que sur l'interface utilisateur.
        *** *Cloud-native* : +
        Applications construites Ã  l'aide de containers, serverless (fonctions dÃ©clenchables avec des Ã©vÃ©nements) ou autre capacitÃ©s PaaS
        *** *Headless* : +
        Headless signifie que l'application n'a pas d'interface utilisateur, et qu'on y accÃ¨de et la *contrÃ´le exclusivement par le biais d'API*. Cette approche permet une plus grande flexibilitÃ© et personnalisation, car l'interface utilisateur peut Ãªtre construite et modifiÃ©e indÃ©pendamment de l'application sous-jacente.

* *REST vs GraphQL*

TO BE COMPLETED

== 2023/03/30 : Les 3 grands facteurs clÃ©s de succÃ¨s dâ€™une entreprise data driven

* https://www.wenvision.com/les-facteurs-cles-de-succes-dune-entreprise-data-driven/

* L'organisation data par domaine permet de dÃ©sengorger la gestion des donnÃ©es d'une Ã©quipe centralisÃ©e et valoriser la connaissance. Elle dÃ©place la responsabilitÃ© auprÃ¨s des domaines ce qui offre en plus d'une expertise technique une expertise mÃ©tier. La crÃ©ation d'Ã©quipes pluridisciplinaires doit favoriser cette innovation. On parle souvent de *Data Mesh*, pour Ã©voquer cette dÃ©centralisation des donnÃ©es.

== 2023/04/26 : ma rÃ©action Ã  l'article de Didier Girard "L'IA gÃ©nÃ©rative sera au data catalogue ce que Google a Ã©tÃ© Ã  Yahoo"

L'article de Didier est disponible sur le blog de WEnvision : https://www.wenvision.com/lia-generative-sera-au-data-catalogue-ce-que-google-a-ete-a-yahoo/

Un article trÃ¨s intÃ©ressant de Didier, dont je partage pleinement les conclusions, avec beaucoup de curiositÃ© sur l'Ã©volution de ce domaine Ã  (trÃ¨s) court terme ðŸ˜‰ 

A l'heure actuelle, la "vraie" "big" data a lieu quand les metadata elles-mÃªmes doivent Ãªtre traitÃ©es comme de la "big data". +
Depuis quelques temps, nous sommes passÃ©s d'une gestion "passive" des metadata (les plateformes de metadata / data catalog Ã©taient dans l'attente d'une action humaine pour la saisie de metadata et / ou leur catÃ©gorisation) Ã  des "active metadata platforms" comme les appelle le Gartner. +
Ces derniÃ¨res collectent en continu toutes les metadata qu'elles peuvent trouver sur le SI, d'oÃ¹ une explosion de la volumÃ©trie associÃ©e.

RÃ©sultat : il devient trÃ¨s difficile (voire impossible) de cataloguer cette derniÃ¨re en amont de la crÃ©ation / ingestion des metadata. +
Il nous faut donc un moyen de le faire soit au moment de la crÃ©ation de la metadonnÃ©e, soit plus tard, Ã  la demande, au moment ou on a besoin de se servir des metadata. +
Dans le 1er cas, le problÃ¨me est de trouver sur quelle base il est possible d'identifier / catÃ©goriser cette metadata ? +
Fasse Ã  des volumes de metadata trÃ¨s consÃ©quents et trÃ¨s variables, une catÃ©gorisation "statique" prÃ©dÃ©finie en amont n'est plus possible ou adÃ©quate, il faut donc se baser sur un ensemble de rÃ¨gles dont le but est d'aboutir par calcul Ã  une catÃ©gorisation. +
Souci : ce "calcul de catÃ©gorisation" est seulement valable Ã  un instant "t", car forcÃ©ment dÃ©pendant du volume de meta-donnÃ©e. +
Avec l'avÃ¨nement des "active metadata", la catÃ©gorisation dÃ©terminÃ©e Ã  un instant "t" ne sera probablement plus correct Ã  un instant "t + x" synonyme d'un pourcentage (consÃ©quent) de metadata supplÃ©mentaires. +
DÃ¨s lors, c'est la 2e solution qui paraÃ®t la plus pertinente : une catÃ©gorisation Ã  la demande.

Et lÃ  je rejoins complÃ¨tement l'avis de Didier, le catalogage "statique" n'est plus possible et doit Ãªtre remplacÃ© par un moyen efficace d'aboutir Ã  cette catÃ©gorisation Ã  la demande : un algorithme rappelant le fonctionnement d'un moteur de recherche. +
C'est Ã  ce moment qu'on voit l'IA gÃ©nÃ©rative entrer en scÃ¨ne.

Les grandes Ã©tapes d'Ã©volution des data catalog ont Ã©tÃ© : 

    * Data Catalog 1.0: la gestion des metadata (identification, catÃ©gorisation, etc.) est directement l'affaire des Ã©quipes techniques
    * Data Catalog 2.0: on passe Ã  une gestion pilotÃ©e par des Ã©quipes dÃ©diÃ©es (nos data stewards) en lien Ã©troit avec le mÃ©tier
    * Data Catalog 3.0: Devant le nombre toujours croissant de metadata, on donne les moyens Ã  une communautÃ© Ã©tendue d'utilisateurs d'analyser les metadata.

Aujourd'hui, nous arrivons Ã  l'aube du Data Catalog "4.0" : les metadata deviennent tout simplement trop nombreuses pour un traitement "humain" ou crÃ©Ã© par des humains (les rÃ¨gles changeraient trop vites), nous avons besoin d'une aide, d'une "prÃ©-catÃ©gorisation" effectuÃ©e par la machine, c'est lÃ  que l'IA gÃ©nÃ©rative intervient : nous crÃ©er / suggÃ©rer les catÃ©gories les plus pertinentes (entre autres), mais Ã  la demande. +
Mais est-ce encore un data "catalog" ? Comme le dit Didier, on se trouve davantage face Ã  un "metadata search engine".

DÃ¨s lors, la question que je me pose est : comment valider cette catÃ©gorisation effectuÃ©e Ã  la demande, sachant qu'elle est susceptible de changer trÃ¨s rapidement, avec la prochaine ingestion d'un +x0% de metadata d'un coup (ou plus encore) qui viendra modifier toutes les catÃ©gories prÃ©cÃ©demment calculÃ©es par l'algo ? +
Une interventation de validation serait impossible ou trÃ¨s compliquÃ©e car trÃ¨s (trop) limitÃ©e dans le temps : valider une catÃ©gorisation stable sur 1 mois soit, 1 semaine pourquoi pas, mais si cela doit passer Ã  plusieurs fois par jour ? +
DÃ¨s lors, accepterait-on de croire la catÃ©gorisation rÃ©alisÃ©e par la machine "sur parole", sans contrÃ´le humain ? +
Contrairement Ã  une "recherche Google classique", qui est avant tout "indicative", les metadata sont Ã  la base de process opÃ©rationnels et mÃ©tier : une information "indicative" n'est pas suffisante, il faut une information "validÃ©e". +
Comment valider cette information, son "sens mÃ©tier" ? +
Pourrait-on imaginer des "Tests Unitaires de catÃ©gorisation de donnÃ©es" ? Mais, ne connaissant ni le rÃ©sultat Ã  l'avance (la catÃ©gorie !) ni la mÃ©canique de rÃ©solution de l'algo, l'Ã©criture de ces derniers me semble difficile.

J'ai hÃ¢te de voir comment va Ã©voluer ce milieu dans les mois Ã  venir, et Ã  quoi vont ressembler les prochains data catalog.

== 2023/02/07 - Jordan TIGANI (MotherDuck, l'Ã©diteur de DuckDB) : Big Data is dead

URL de l'article : https://motherduck.com/blog/big-data-is-dead/

* Jordan utilise / cite le comparateur bien connu "DB Engines" pour comparer les perfs de certaines BDDs.

* Customer data sizes followed a power-law distribution. The largest customer had double the storage of the next largest customer, the next largest customer had half of that, etc. So while there were customers with hundreds of petabytes of data, the sizes trailed off very quickly. There were *many thousands of customers* who paid *less than $10 a month for storage*, which is *half a terabyte*. Among customers who were using the service heavily, the *median data storage size* was much less than *100 GB*.

* He (GCP investissor ?) found that the *largest B2B companies* in his portfolio had around *a terabyte of data*, while the *largest B2C companies* had around *10 Terabytes of data*. +
-> Most, however, had *far less data*.

* *Modern cloud data platforms all separate storage and compute*, which means that customers are not tied to a single form factor. This, more than scale out, is likely the single *most important change in data architectures* in the last 20 years.
    ** *Instead of â€œshared nothingâ€ architectures* which are hard to manage in real world conditions, *shared disk architectures* let you grow your storage and your compute independently. +
    The rise of scalable and reasonably fast object storage like S3 and GCS meant that you could relax a lot of the constraints on how you built a database.

* *The amount of data processed for analytics workloads is almost certainly smaller than you think*. Dashboards, for example, very often are built from aggregated data. People look at the last hour, or the last day, or the last week's worth of data. Smaller tables tend to be queried more frequently, giant tables more selectively.

* A couple of years ago I did an analysis of BigQuery queries, looking at customers spending more than $1000 / year. *90% of queries processed less than 100 MB of data*.

* A huge percentage of the data that gets processed is less than 24 hours old. By the time data gets to be a week old, it is probably 20 times less likely to be queried than from the most recent day.

* One definition of *â€œBig Dataâ€ is â€œwhatever doesnâ€™t fit on a single machine*.. By that definition, the number of workloads that qualify has been decreasing every year.

* An alternate definition of *Big Data is â€œwhen the cost of keeping data around is less than the cost of figuring out what to throw away.â€* 
    ** I like this definition because it encapsulates why people end up with Big Data. It isnâ€™t because they need it; they just havenâ€™t bothered to delete it. +
    If you think about many data lakes that organizations collect, they fit this bill entirely: giant, messy swamps where no one really knows what they hold or whether it is safe to clean them up.

* Some questions that you can ask to *figure out if youâ€™re a â€œBig Data One-Percenterâ€*:
    ** Are you really generating a huge amount of data?
    ** If so, do you really need to use a huge amount of data at once?
    ** If so, is the data really too big to fit on one machine?
    ** If so, are you sure youâ€™re not just a data hoarder?
    ** If so, are you sure you wouldnâ€™t be better off summarizing?

== 2023/01/24 - Ryan BOYD (MotherDuck, l'Ã©diteur de DuckDB) : How to analyse SQLite databases in DuckDB

* https://motherduck.com/blog/analyze-sqlite-databases-duckdb/

* *DuckDB* is often referred to as the *'SQLite for analytics.'* +
This analogy helps us understand several key properties of DuckDB: 
    ** it's for analytics (OLAP), 
    ** it's embeddable, 
    ** it's lightweight, 
    ** it's self-contained 
    ** and it's widely deployed. +
-> Okay, the latter may not be a given yet for DuckDB, but SQLite says it's likely the most widely used and deployed database engine and, with the rising popularity of analytics, it's quite possible DuckDB will eventually be competitive.

* There are some noticeable differences between SQLite and DuckDB in how data is stored. 
    ** *SQLite*, as a data store *focused on transactions*, *stores data row-by-row* while *DuckDB*, as a *database engine for analytics*, stores *data by columns*. 
    ** Additionally, SQLite doesn't strictly enforce types in the data -- this is known as being weakly typed (or flexibly typed).

== 2023/05/11 - Tech Rocks - Modern Data Stack

A REVOIR !

image:20230511_tech-rocks_modern-data-stack_01.jpg[]








