= Quick notes
Thomas SCHWENDER <icon:github[] https://github.com/Ardemius/[GitHub] / icon:twitter[role="aqua"] https://twitter.com/thomasschwender[@thomasschwender]>
// Handling GitHub admonition blocks icons
ifndef::env-github[:icons: font]
ifdef::env-github[]
:status:
:outfilesuffix: .adoc
:caution-caption: :fire:
:important-caption: :exclamation:
:note-caption: :paperclip:
:tip-caption: :bulb:
:warning-caption: :warning:
endif::[]
:imagesdir: ./images
:source-highlighter: highlightjs
:highlightjs-languages: asciidoc
// We must enable experimental attribute to display Keyboard, button, and menu macros
:experimental:
// Next 2 ones are to handle line breaks in some particular elements (list, footnotes, etc.)
:lb: pass:[<br> +]
:sb: pass:[<br>]
// check https://github.com/Ardemius/personal-wiki/wiki/AsciiDoctor-tips for tips on table of content in GitHub
:toc: macro
:toclevels: 4
// To number the sections of the table of contents
//:sectnums:
// Add an anchor with hyperlink before the section title
:sectanchors:
// To turn off figure caption labels and numbers
// :figure-caption!:
// Same for examples
//:example-caption!:
// To turn off ALL captions
:caption:

toc::[]

Un bloc-notes permettant de persister des notes et r√©flexions prises tr√®s rapidement en suivant talk, conf, √©mission ou autre.

== 2022/05/11 - Vid√©o "Dev senior avec 6 ans d'XP, et apr√®s?" (gestion de carri√®re)

J'ai regard√© derni√®rement le MeetUp Tech Rocks *"Dev senior avec 6 ans d'XP, et apr√®s ?"* qui aborde le sujet de la gestion de carri√®re chez les ITs, et met bien en avant *2 types de carri√®re* : la *voie manag√©riale* ("*Engineering Management*") et la voie appel√©e ici "leadership's path" (ou *Individual Contributor*), correspondant √† une *orientation plus technique*, dans laquelle on va chercher √† avoir de plus en plus d'impact via sa contribution individuelle (contribution qui va elle impacter un nombre croissant de personnes dans l'entreprise)

Si vous avez ~1h (ou 45 min en x1.5 üòâ ), je ne saurais que trop vous conseiller de regarder le talk, r√©ellement tr√®s int√©ressant et faisant intervenir des CxO et leaders seniors dans des bo√Ætes de la Tech : https://www.youtube.com/watch?v=WIW3ow6jL98

video::WIW3ow6jL98[youtube]

J'ai beaucoup aim√© la *description faite du "Y" de nos carri√®res* (entre management et contribution individuelle), tout particuli√®rement celle de la branche du contributeur individuel. +
Les intervenants expliquent bien la prise de conscience actuelle et grandissante qu'un IT n'a pas "rat√© sa vie parce qu'il n'est pas manager √† 30 ans", et que sa vie ne s'arr√™tait pas non plus √† l'obtention du *poste "Senior developer / consultant"*. +
*Ce dernier est tout sauf la fin du parcours*, et va se poursuivre dans des r√¥les o√π sa contribution individuelle va avoir de plus en plus d'impact sur un grand nombre de personnes dans la soci√©t√©.

La progression propos√©e est celle que l'on retrouve de plus en plus dans les bo√Ætes anglo-saxonnes (bien en avance sur nous √† ce niveau), √† savoir : +
*senior software engineer >> staff engineer >> principal engineer >> distinguished engineer >> fellow engineer >> CTO*

Dans un 1er temps, on va avoir un impact sur soi uniquement, puis il faudra chercher √† accro√Ætre son scope : +
*Soi >> team / squad >> chapter / guild >> product line >> company >> industry*

image:20220511_Tech-Rocks_dev-senior-et-apres_01.png[]
image:20220511_Tech-Rocks_dev-senior-et-apres_02.png[]

En passant, si vous voulez un exemple "proche de nous" de ce syst√®me, √©coutez comment *Emmanuel Bernard*, notre Cast Codeurs bien connu üòâ, se pr√©sente : *"Distinguished Engineer"* +
Pour info, cela fait 17 ans qu'il travaille chez Red Hat. +
Un exemple de plus qu'il est possible de progresser SANS devenir "manager" üòâ +
(et si vous prenez son coll√®gue *Cl√©ment Escoffier* c√¥t√© Quarkus / Kubernetes chez Red Hat, c'est *"Principal Engineer"* üòâ )

== 2022/06/28 - Artisan D√©veloppeur : Interview de Thomas PIERRAIN

Thomas PIERRAIN est VP of engineering chez Agicap, et est un ancien archi de la SGCIB

* Thomas Pierrain : on justifie le *passage aux microservices* principalement pour des raisons de *v√©locit√© du delivery* et *√©viter les bottle neck*.
* De plus en plus on parle d'ailleurs de *macro service* plut√¥t que de micro service (on revient du buzz des premi√®res ann√©es des microservices)

* Thomas P chez Agicap : mise en place (√† v√©rifier) d'une architecture dite "la ruche" pour monolithe 

* *Living doc* tr√®s avanc√©e chez Thomas : g√©n√©ration automatique depuis le build vers markdown 
* Environnement technique hexagonale et CQRS tr√®s avanc√©, √† regarder 

* Conseil : *ne d√©coupe pas trop t√¥t ! Le r√©seau va te tuer...*
* Exemple Doctolib : the boring architecture et 400 dev sur 1 monolithe : 
*"La qualit√© d'aujourd'hui c'est la productivit√© de demain"*

1. on *modularise son code dans le monolith*, on l'aligne sur le m√©tier
    ** -> TSC : De nombreux architectes connus donnent √©galement ce conseil ("proprifier AVANT de migrer en microservices")
	** en gros, modular monolith : on cr√©e des modules ind√©pendants pour chaque feature
	** This combined the advantages of a monolith, such a single test and deployment pipeline, with the advantages of microservices, such as code modularity and decoupling.
+
-> Il faut bien se dire que les microservices n√©cessitent une grande maturit√© d'√©quipeS (oui, au pluriel) surtout c√¥t√© de la cha√Æne de CI/CdD

2. *DDD* pour une meilleure s√©paration et un meilleur contr√¥le de la logique m√©tier
	** le concept cl√© : les *bounded contexts*
+
Mise en place de l'architecture hexagonale pour isoler le m√©tier, et forcer le passage par les ports et adapters

== 2022/10/21 - Demo de Couchbase Capella

J'ai suivi la d√©mo de Couchbase Capella via leur offre d'essai (trial de 30 jours) de la solution.

Vid√©o explicative : https://www.youtube.com/watch?v=46715VbaHvk

.Comparaison des concepts entre une BDDR et Couchbase
[cols="1,1", options="header"] 
|===
|Relationel model 			|Couchbase
|Server	                    |Cluster
|Database	                |Bucket
|Schema		                |Scope
|Table		                |Collection
|Row		                |Document (JSON or BLOB)
|===

.Exemple
image:20221021_couchbase-capella-demo_01.jpg[]

Why the creation of the index is not done automatically ?

    * Because *manipulating the document using only the ID* is *faster* because using internally the *key / value engine*, which *does NOT require any indexes*.
        ** This works pretty well when you can get the ID of the document

[source,java]
----
// guessing the UserHistory ID using the user's id ('123-hist')
UserHistory hist = userHistoryCollection.get(user.getId() + "-hist")
----


== 2022/05/12 - Le Comptoir OCTO x Dataiku x Snowflake - Comment cr√©er plus de valeur et developper la collaboration a partir de donn√©es enrichies ?

https://fr.slideshare.net/OCTOTechnology/le-comptoir-octo-x-dataiku-x-snowflake-comment-crer-plus-de-valeur-et-developper-la-collaboration-a-partir-de-donnes-enrichies/OCTOTechnology/le-comptoir-octo-x-dataiku-x-snowflake-comment-crer-plus-de-valeur-et-developper-la-collaboration-a-partir-de-donnes-enrichies

* Pr√©sentation d'une architecture de solution bas√©e sur Snowflake et Data√Øku, avec le soutien d'OCTO Technology

== 2023/01/09 - Rapport tendances 2023 par Didier Girard

* https://www.linkedin.com/pulse/rapport-tendances-2023-didier-girard

* Didier met lui aussi en avant le succ√®s de Team Topologies et du DDD
* Il insiste sur le besoin de d√©couplage des √©quipes, dans le but d'en augmenter l'autonomie et la productivit√©.
    ** L'√©quipe doit √™tre responsable de bout en bout d'un domaine, et ne doit pas avoir √† se reposer sur la synchronisation avec n √©quipes pour d√©livrer de la valeur.

.Produit vs Projet
--
Un *produit* est une offre mat√©rielle ou immat√©rielle qui r√©pond √† un besoin ou satisfait une envie. +
Il est le r√©sultat de la strat√©gie commerciale d'une entreprise et doit √™tre con√ßu, d√©velopp√© et g√©r√© afin d'apporter de la valeur au client. Il est ensuite mis au catalogue, et est r√©guli√®rement mis √† jour dans le cadre de son cycle de vie - jusqu'√† ce qu'il soit retir√© du march√© - en fonction d'une roadmap √©tablie pour r√©pondre aux besoins des clients, qui √©voluent au fil du temps. +
Le produit vise un objectif, et chaque it√©ration s'en rapprochera.

De son c√¥t√©, un *projet* est un effort temporaire qui a pour but de r√©pondre √† un besoin unique : il s'agit de cr√©er un livrable sp√©cifique, pour une date pr√©cise et un budget fix√© √† l'avance. Ce qui ne laisse pas de place √† l'impr√©vu, et va donc √† l'encontre des principes agiles ; cette fa√ßon de faire est une source √©vidente de frustration lorsque cet impr√©vu arrive (ce qu'il fait immanquablement).
--

**MVP vs MLP* : Minimum Valuable Product vs Minimum Lovable Product

    ** Un MVP est une version d'un produit qui poss√®de l'ensemble minimal de fonctionnalit√©s n√©cessaires pour √™tre utilisable par les clients.
    ** Un MLP, en revanche, est une version d'un produit qui poss√®de l'ensemble minimum de fonctionnalit√©s n√©cessaires pour √™tre aim√©e des clients.

    ** En r√©sum√©, la principale diff√©rence entre MVP et MLP est l'accent mis sur le retour d'information des clients et l'engagement √©motionnel. +
    Un MVP se concentre sur la collecte de commentaires et l'it√©ration sur le produit, tandis qu'un MLP se concentre sur la cr√©ation d'un lien √©motionnel positif avec les clients du produit.

* *Nouveau r√¥le de l'architecte* : 
    ** concevoir et de mettre en ≈ìuvre la structure globale du syst√®me, en veillant √† ce qu'il soit √©volutif, maintenable et capable de s'adapter √† l'√©volution des besoins de l'entreprise.
    ** L'architecte est responsable de la conception de l'architecture des donn√©es, y compris le stockage, l'acc√®s et la s√©curit√© des donn√©es.
    ** L'architecte doit s'assurer que le syst√®me d'information est s√©curis√©, √† la fois contre les menaces externes et contre les acc√®s non autoris√©s par les utilisateurs internes.

* *SI Cloud Native :*
    ** Un SI Cloud Native mixe des applications SaaS et des services manag√©s avec des applications ou micro-services maison conteneuris√©s, d√©ploy√©s dans le cloud de son choix.

* *WebAssembly* (WASM)
    ** solution permettant d'ex√©cuter du code bas niveau directement dans le navigateur, offrant des *am√©liorations spectaculaires des performances*.
    ** solution pour l'ex√©cution, dans le navigateur, d'applications √©crites en C++, Rust ou Go.
    ** WebAssembly va aussi bien au-del√† du navigateur. +
    Cette technologie peut aussi √™tre utilis√©e dans les applications de cloud computing et d'Internet des objets (IoT) : *WebAssembly fournit un environnement de sandboxing s√©curis√© dans lequel le code peut s'ex√©cuter sans avoir d'impact sur les autres programmes*.
        *** Donc une notion proche de celle des conteneurs.

* *Cloud, la plateforme de choix*
    ** importance de l'Infra as Code (IaC), qui est au coeur des architectures cloud-natives
        *** Importance des outils de type *Terraform* ou *Pulumi*
        *** Pulumi : Ce framework de l'√©cosyst√®me Terraform, d√©velopp√© par HashiCorp, permet de d√©crire l'infrastructure d√©sir√©e en utilisant un langage de programmation tel que TypeScript, Python ou Go plut√¥t que d'utiliser le DSL sp√©cifique √† Terraform (HCL).

* Repenser le *r√©seau √©tendu dans une perspective Cloud*, un concept auquel Gartner a donn√© le nom de *Secure Access Service Edge*, ou *SASE* (prononcer sassy).
    ** Dans une architecture SASE, les services Cloud g√®rent l‚Äôauthentification et plus largement toute la s√©curit√© du r√©seau, et une *couche d‚Äôabstraction logicielle permet de g√©rer l‚Äôinfrastructure r√©seau* : le *SD-WAN*, *Software-Defined Wide Area Network*. Les services de SD-WAN permettent d‚Äôagr√©ger plusieurs types d‚Äôinfrastructures d‚Äôun ou plusieurs fournisseurs (MPLS, fibre, SDSL, 4G‚Ä¶) et de g√©rer ainsi des r√©seaux complexes de mani√®re centralis√©e, industrialis√©e et simple.

* *Plateformes Back*
    ** *MACH* est un acronyme qui signifie Microservices (ou Modules-based), API-first, Cloud native et Headless.
        *** *API-First* : +
        L'application est con√ßue et construite autour des API, qu'elles soient REST ou GraphQL. Cette approche met l'accent sur les *API comme principal moyen d'acc√©der et d'interagir avec l'application*, plut√¥t que sur l'interface utilisateur.
        *** *Cloud-native* : +
        Applications construites √† l'aide de containers, serverless (fonctions d√©clenchables avec des √©v√©nements) ou autre capacit√©s PaaS
        *** *Headless* : +
        Headless signifie que l'application n'a pas d'interface utilisateur, et qu'on y acc√®de et la *contr√¥le exclusivement par le biais d'API*. Cette approche permet une plus grande flexibilit√© et personnalisation, car l'interface utilisateur peut √™tre construite et modifi√©e ind√©pendamment de l'application sous-jacente.

* *REST vs GraphQL*

TO BE COMPLETED

== 2023/03/30 : Les 3 grands facteurs cl√©s de succ√®s d‚Äôune entreprise data driven

* https://www.wenvision.com/les-facteurs-cles-de-succes-dune-entreprise-data-driven/

* L'organisation data par domaine permet de d√©sengorger la gestion des donn√©es d'une √©quipe centralis√©e et valoriser la connaissance. Elle d√©place la responsabilit√© aupr√®s des domaines ce qui offre en plus d'une expertise technique une expertise m√©tier. La cr√©ation d'√©quipes pluridisciplinaires doit favoriser cette innovation. On parle souvent de *Data Mesh*, pour √©voquer cette d√©centralisation des donn√©es.

== 2023/04/26 : ma r√©action √† l'article de Didier Girard "L'IA g√©n√©rative sera au data catalogue ce que Google a √©t√© √† Yahoo"

L'article de Didier est disponible sur le blog de WEnvision : https://www.wenvision.com/lia-generative-sera-au-data-catalogue-ce-que-google-a-ete-a-yahoo/

Un article tr√®s int√©ressant de Didier, dont je partage pleinement les conclusions, avec beaucoup de curiosit√© sur l'√©volution de ce domaine √† (tr√®s) court terme üòâ 

A l'heure actuelle, la "vraie" "big" data a lieu quand les metadata elles-m√™mes doivent √™tre trait√©es comme de la "big data". +
Depuis quelques temps, nous sommes pass√©s d'une gestion "passive" des metadata (les plateformes de metadata / data catalog √©taient dans l'attente d'une action humaine pour la saisie de metadata et / ou leur cat√©gorisation) √† des "active metadata platforms" comme les appelle le Gartner. +
Ces derni√®res collectent en continu toutes les metadata qu'elles peuvent trouver sur le SI, d'o√π une explosion de la volum√©trie associ√©e.

R√©sultat : il devient tr√®s difficile (voire impossible) de cataloguer cette derni√®re en amont de la cr√©ation / ingestion des metadata. +
Il nous faut donc un moyen de le faire soit au moment de la cr√©ation de la metadonn√©e, soit plus tard, √† la demande, au moment ou on a besoin de se servir des metadata. +
Dans le 1er cas, le probl√®me est de trouver sur quelle base il est possible d'identifier / cat√©goriser cette metadata ? +
Fasse √† des volumes de metadata tr√®s cons√©quents et tr√®s variables, une cat√©gorisation "statique" pr√©d√©finie en amont n'est plus possible ou ad√©quate, il faut donc se baser sur un ensemble de r√®gles dont le but est d'aboutir par calcul √† une cat√©gorisation. +
Souci : ce "calcul de cat√©gorisation" est seulement valable √† un instant "t", car forc√©ment d√©pendant du volume de meta-donn√©e. +
Avec l'av√®nement des "active metadata", la cat√©gorisation d√©termin√©e √† un instant "t" ne sera probablement plus correct √† un instant "t + x" synonyme d'un pourcentage (cons√©quent) de metadata suppl√©mentaires. +
D√®s lors, c'est la 2e solution qui para√Æt la plus pertinente : une cat√©gorisation √† la demande.

Et l√† je rejoins compl√®tement l'avis de Didier, le catalogage "statique" n'est plus possible et doit √™tre remplac√© par un moyen efficace d'aboutir √† cette cat√©gorisation √† la demande : un algorithme rappelant le fonctionnement d'un moteur de recherche. +
C'est √† ce moment qu'on voit l'IA g√©n√©rative entrer en sc√®ne.

Les grandes √©tapes d'√©volution des data catalog ont √©t√© : 

    * Data Catalog 1.0: la gestion des metadata (identification, cat√©gorisation, etc.) est directement l'affaire des √©quipes techniques
    * Data Catalog 2.0: on passe √† une gestion pilot√©e par des √©quipes d√©di√©es (nos data stewards) en lien √©troit avec le m√©tier
    * Data Catalog 3.0: Devant le nombre toujours croissant de metadata, on donne les moyens √† une communaut√© √©tendue d'utilisateurs d'analyser les metadata.

Aujourd'hui, nous arrivons √† l'aube du Data Catalog "4.0" : les metadata deviennent tout simplement trop nombreuses pour un traitement "humain" ou cr√©√© par des humains (les r√®gles changeraient trop vites), nous avons besoin d'une aide, d'une "pr√©-cat√©gorisation" effectu√©e par la machine, c'est l√† que l'IA g√©n√©rative intervient : nous cr√©er / sugg√©rer les cat√©gories les plus pertinentes (entre autres), mais √† la demande. +
Mais est-ce encore un data "catalog" ? Comme le dit Didier, on se trouve davantage face √† un "metadata search engine".

D√®s lors, la question que je me pose est : comment valider cette cat√©gorisation effectu√©e √† la demande, sachant qu'elle est susceptible de changer tr√®s rapidement, avec la prochaine ingestion d'un +x0% de metadata d'un coup (ou plus encore) qui viendra modifier toutes les cat√©gories pr√©c√©demment calcul√©es par l'algo ? +
Une interventation de validation serait impossible ou tr√®s compliqu√©e car tr√®s (trop) limit√©e dans le temps : valider une cat√©gorisation stable sur 1 mois soit, 1 semaine pourquoi pas, mais si cela doit passer √† plusieurs fois par jour ? +
D√®s lors, accepterait-on de croire la cat√©gorisation r√©alis√©e par la machine "sur parole", sans contr√¥le humain ? +
Contrairement √† une "recherche Google classique", qui est avant tout "indicative", les metadata sont √† la base de process op√©rationnels et m√©tier : une information "indicative" n'est pas suffisante, il faut une information "valid√©e". +
Comment valider cette information, son "sens m√©tier" ? +
Pourrait-on imaginer des "Tests Unitaires de cat√©gorisation de donn√©es" ? Mais, ne connaissant ni le r√©sultat √† l'avance (la cat√©gorie !) ni la m√©canique de r√©solution de l'algo, l'√©criture de ces derniers me semble difficile.

J'ai h√¢te de voir comment va √©voluer ce milieu dans les mois √† venir, et √† quoi vont ressembler les prochains data catalog.

== 2023/02/07 - Jordan TIGANI (MotherDuck, l'√©diteur de DuckDB) : Big Data is dead

URL de l'article : https://motherduck.com/blog/big-data-is-dead/

* Jordan utilise / cite le comparateur bien connu "DB Engines" pour comparer les perfs de certaines BDDs.

* Customer data sizes followed a power-law distribution. The largest customer had double the storage of the next largest customer, the next largest customer had half of that, etc. So while there were customers with hundreds of petabytes of data, the sizes trailed off very quickly. There were *many thousands of customers* who paid *less than $10 a month for storage*, which is *half a terabyte*. Among customers who were using the service heavily, the *median data storage size* was much less than *100 GB*.

* He (GCP investissor ?) found that the *largest B2B companies* in his portfolio had around *a terabyte of data*, while the *largest B2C companies* had around *10 Terabytes of data*. +
-> Most, however, had *far less data*.

* *Modern cloud data platforms all separate storage and compute*, which means that customers are not tied to a single form factor. This, more than scale out, is likely the single *most important change in data architectures* in the last 20 years.
    ** *Instead of ‚Äúshared nothing‚Äù architectures* which are hard to manage in real world conditions, *shared disk architectures* let you grow your storage and your compute independently. +
    The rise of scalable and reasonably fast object storage like S3 and GCS meant that you could relax a lot of the constraints on how you built a database.

* *The amount of data processed for analytics workloads is almost certainly smaller than you think*. Dashboards, for example, very often are built from aggregated data. People look at the last hour, or the last day, or the last week's worth of data. Smaller tables tend to be queried more frequently, giant tables more selectively.

* A couple of years ago I did an analysis of BigQuery queries, looking at customers spending more than $1000 / year. *90% of queries processed less than 100 MB of data*.

* A huge percentage of the data that gets processed is less than 24 hours old. By the time data gets to be a week old, it is probably 20 times less likely to be queried than from the most recent day.

* One definition of *‚ÄúBig Data‚Äù is ‚Äúwhatever doesn‚Äôt fit on a single machine*.. By that definition, the number of workloads that qualify has been decreasing every year.

* An alternate definition of *Big Data is ‚Äúwhen the cost of keeping data around is less than the cost of figuring out what to throw away.‚Äù* 
    ** I like this definition because it encapsulates why people end up with Big Data. It isn‚Äôt because they need it; they just haven‚Äôt bothered to delete it. +
    If you think about many data lakes that organizations collect, they fit this bill entirely: giant, messy swamps where no one really knows what they hold or whether it is safe to clean them up.

* Some questions that you can ask to *figure out if you‚Äôre a ‚ÄúBig Data One-Percenter‚Äù*:
    ** Are you really generating a huge amount of data?
    ** If so, do you really need to use a huge amount of data at once?
    ** If so, is the data really too big to fit on one machine?
    ** If so, are you sure you‚Äôre not just a data hoarder?
    ** If so, are you sure you wouldn‚Äôt be better off summarizing?

== 2023/01/24 - Ryan BOYD (MotherDuck, l'√©diteur de DuckDB) : How to analyse SQLite databases in DuckDB

* https://motherduck.com/blog/analyze-sqlite-databases-duckdb/

* *DuckDB* is often referred to as the *'SQLite for analytics.'* +
This analogy helps us understand several key properties of DuckDB: 
    ** it's for analytics (OLAP), 
    ** it's embeddable, 
    ** it's lightweight, 
    ** it's self-contained 
    ** and it's widely deployed. +
-> Okay, the latter may not be a given yet for DuckDB, but SQLite says it's likely the most widely used and deployed database engine and, with the rising popularity of analytics, it's quite possible DuckDB will eventually be competitive.

* There are some noticeable differences between SQLite and DuckDB in how data is stored. 
    ** *SQLite*, as a data store *focused on transactions*, *stores data row-by-row* while *DuckDB*, as a *database engine for analytics*, stores *data by columns*. 
    ** Additionally, SQLite doesn't strictly enforce types in the data -- this is known as being weakly typed (or flexibly typed).

== 2023/05/11 - Tech Rocks - Modern Data Stack

A REVOIR !

image:20230511_tech-rocks_modern-data-stack_01.jpg[]








